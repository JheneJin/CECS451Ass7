{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a toy dataset.\n",
    "# DO NOT MODIFY THIS PART\n",
    "import numpy as np\n",
    "import math\n",
    "import random as rand\n",
    "\n",
    "paras = list((rand.random() - 0.5 for _ in range(13)))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def y_gen(x):\n",
    "    h_11 = sigmoid(paras[0] * x[0] + paras[1] * x[1] + paras[2])\n",
    "    h_12 = sigmoid(paras[3] * x[0] + paras[4] * x[1] + paras[5])\n",
    "    h_13 = sigmoid(paras[6] * x[0] + paras[7] * x[1] + paras[8])\n",
    "    h_21 = sigmoid(paras[9] * h_11 + paras[10] * h_12 + paras[11] * h_13 + paras[12])\n",
    "    return h_21 + ((rand.random()-0.5)/100 if rand.random()>0.6 else 0)\n",
    "\n",
    "n = 300\n",
    "x = list(zip((rand.random() - 0.5 for _ in range(n)), (rand.random() - 0.5 for _ in range(n))))\n",
    "y = list(map(y_gen, x))\n",
    "y = [(i-min(y))/(max(y)-min(y)) for i in y]\n",
    "\n",
    "#part a\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "r = 0.2\n",
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(x, y, test_size=r)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid, test_size=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part b\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gradient(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def getLoss(y, yPred):\n",
    "    return np.mean(0.5 * (y- yPred) ** 2)\n",
    "\n",
    "#part c\n",
    "class NN:\n",
    "    def __init__(self):\n",
    "        # Initialize parameters and biases\n",
    "        self.w1 = np.random.uniform(-1, 1, size = (2, 3))  # Layer 1 weights\n",
    "        self.b1 = np.array([1, 1, 1], dtype = float)\n",
    "        self.w2 = np.random.uniform(-1, 1, size = (3, 1))  # Layer 2 weights\n",
    "        self.b2 = np.array([1], dtype = float)  # Layer 2 biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        self.h0 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(self.h0)\n",
    "        self.h1 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(self.h1)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, x, y, yPred, learning_rate):\n",
    "        x = np.array(x)\n",
    "        loss = yPred - y\n",
    "        dh2 = loss * gradient(self.h1)\n",
    "        dw2 = np.dot(self.a1.T, dh2)\n",
    "        db2 = np.sum(dh2)\n",
    "        da1 = np.dot(dh2, self.w2.T)\n",
    "        dh1 = da1 * gradient(self.h0)\n",
    "        dw1 = np.dot(x.T, dh1)\n",
    "        db1 = np.sum(dh1)\n",
    "        self.w1 -= learning_rate * dw1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.w2 -= learning_rate * dw2\n",
    "        self.b2 -= learning_rate * db2\n",
    "\n",
    "    #part d\n",
    "    def train(self, x_train, y_train, x_valid, y_valid, epochs, learning_rate):\n",
    "        # Lists to store training and validation costs\n",
    "        trainCosts = []\n",
    "        validCosts = []\n",
    "\n",
    "        #part e\n",
    "        for epoch in range(epochs):\n",
    "            yPred = self.forward(x_train)\n",
    "            loss = getLoss(y_train, yPred)\n",
    "            trainCosts.append(loss)\n",
    "\n",
    "            self.backward(x_train, y_train, yPred, learning_rate)\n",
    "            yTrue = self.forward(x_valid)\n",
    "            trueLoss = getLoss(y_valid, yTrue)\n",
    "            validCosts.append(trueLoss)\n",
    "\n",
    "            print(f\"Epoch: {epoch + 1}, Train Loss: {loss}, Valid Loss: {trueLoss}\")\n",
    "        plt.plot(range(len(trainCosts)), trainCosts, label='Training Loss')\n",
    "        plt.plot(range(len(validCosts)), validCosts, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # return trainCosts, validCosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRate(x_train, y_train, x_valid, y_valid, epochs):\n",
    "    learningRates = np.logspace(-3, np.log10(0.009), num = 250)\n",
    "    \n",
    "    learningRateDict = {}\n",
    "\n",
    "    for lr in learningRates:\n",
    "        model = NN()\n",
    "        trainCosts = []\n",
    "        validCosts = []\n",
    "\n",
    "        #part e\n",
    "        for _ in range(epochs):\n",
    "            yPred = model.forward(x_train)\n",
    "            loss = getLoss(y_train, yPred)\n",
    "            trainCosts.append(loss)\n",
    "\n",
    "            model.backward(x_train, y_train, yPred, lr)\n",
    "            yTrue = model.forward(x_valid)\n",
    "            trueLoss = getLoss(y_valid, yTrue)\n",
    "            validCosts.append(trueLoss)\n",
    "        print(f\"Learning Rate {lr}, Train Loss: {loss}, Valid Loss: {trueLoss}\")\n",
    "        # Store the validation costs for this learning rate\n",
    "        learningRateDict[lr] = validCosts[-1]  # Only store the final validation cost\n",
    "    \n",
    "    # Find the optimal learning rate based on the lowest validation cost\n",
    "    rate = min(learningRateDict, key = learningRateDict.get)\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.0761567013436963, Valid Loss: 0.08119345105579708\n",
      "Epoch: 2, Train Loss: 0.06924178771260804, Valid Loss: 0.0728386337371861\n",
      "Epoch: 3, Train Loss: 0.06197652384352712, Valid Loss: 0.06426457429360567\n",
      "Epoch: 4, Train Loss: 0.05460131642774824, Valid Loss: 0.055805099279575915\n",
      "Epoch: 5, Train Loss: 0.04742549358259667, Valid Loss: 0.04782875718772652\n",
      "Epoch: 6, Train Loss: 0.04077911363922811, Valid Loss: 0.04066504471178342\n",
      "Epoch: 7, Train Loss: 0.034943565542645716, Valid Loss: 0.034534053435778665\n",
      "Epoch: 8, Train Loss: 0.03008944405539186, Valid Loss: 0.029512366858992906\n",
      "Epoch: 9, Train Loss: 0.026251503300092887, Valid Loss: 0.02554697616209085\n",
      "Epoch: 10, Train Loss: 0.0233487432377555, Valid Loss: 0.022501082899357306\n",
      "Epoch: 11, Train Loss: 0.02123165570708574, Valid Loss: 0.020204719212302474\n",
      "Epoch: 12, Train Loss: 0.01973038906405103, Valid Loss: 0.018491818526713555\n",
      "Epoch: 13, Train Loss: 0.01868763830921939, Valid Loss: 0.01721949968688197\n",
      "Epoch: 14, Train Loss: 0.017973887792144122, Valid Loss: 0.01627382430653737\n",
      "Epoch: 15, Train Loss: 0.017490155290903028, Valid Loss: 0.015568067838997264\n",
      "Epoch: 16, Train Loss: 0.017164388320761084, Valid Loss: 0.015038033702612806\n",
      "Epoch: 17, Train Loss: 0.016945796567728922, Valid Loss: 0.01463692890724616\n",
      "Epoch: 18, Train Loss: 0.01679933076543871, Valid Loss: 0.014330882837560151\n",
      "Epoch: 19, Train Loss: 0.01670114157068682, Valid Loss: 0.014095406632344681\n",
      "Epoch: 20, Train Loss: 0.016635150207622976, Valid Loss: 0.0139127435002346\n",
      "Epoch: 21, Train Loss: 0.016590582425926734, Valid Loss: 0.013769945363999657\n",
      "Epoch: 22, Train Loss: 0.016560247204435604, Valid Loss: 0.013657500028856366\n",
      "Epoch: 23, Train Loss: 0.016539357520447998, Valid Loss: 0.013568359369943583\n",
      "Epoch: 24, Train Loss: 0.01652473204635269, Valid Loss: 0.013497253181442515\n",
      "Epoch: 25, Train Loss: 0.016514258849743748, Valid Loss: 0.013440204066224426\n",
      "Epoch: 26, Train Loss: 0.016506536887663324, Valid Loss: 0.013394183025105755\n",
      "Epoch: 27, Train Loss: 0.01650063711909946, Valid Loss: 0.013356863401961344\n",
      "Epoch: 28, Train Loss: 0.016495943652920644, Valid Loss: 0.013326443722470145\n",
      "Epoch: 29, Train Loss: 0.016492048256878267, Valid Loss: 0.01330151900097462\n",
      "Epoch: 30, Train Loss: 0.016488680362128468, Valid Loss: 0.013280986357481204\n",
      "Epoch: 31, Train Loss: 0.016485660644580413, Valid Loss: 0.013263975108036724\n",
      "Epoch: 32, Train Loss: 0.01648287025180216, Valid Loss: 0.013249794464333399\n",
      "Epoch: 33, Train Loss: 0.01648023040618122, Valid Loss: 0.013237894024169456\n",
      "Epoch: 34, Train Loss: 0.016477688887180052, Valid Loss: 0.013227833645796333\n",
      "Epoch: 35, Train Loss: 0.01647521107318146, Valid Loss: 0.013219260276969567\n",
      "Epoch: 36, Train Loss: 0.016472774005124872, Valid Loss: 0.013211889990682174\n",
      "Epoch: 37, Train Loss: 0.016470362452643734, Valid Loss: 0.013205493957315004\n",
      "Epoch: 38, Train Loss: 0.01646796630719129, Valid Loss: 0.013199887420673012\n",
      "Epoch: 39, Train Loss: 0.016465578854507487, Valid Loss: 0.013194920986231198\n",
      "Epoch: 40, Train Loss: 0.01646319562979223, Valid Loss: 0.013190473703317288\n",
      "Epoch: 41, Train Loss: 0.016460813659021287, Valid Loss: 0.013186447549058037\n",
      "Epoch: 42, Train Loss: 0.016458430956152143, Valid Loss: 0.013182763014565516\n",
      "Epoch: 43, Train Loss: 0.016456046189906936, Valid Loss: 0.013179355562622822\n",
      "Epoch: 44, Train Loss: 0.0164536584629357, Valid Loss: 0.013176172777715585\n",
      "Epoch: 45, Train Loss: 0.016451267165456463, Valid Loss: 0.013173172068327224\n",
      "Epoch: 46, Train Loss: 0.01644887187825375, Valid Loss: 0.013170318811283282\n",
      "Epoch: 47, Train Loss: 0.016446472308389196, Valid Loss: 0.013167584850957481\n",
      "Epoch: 48, Train Loss: 0.01644406824659231, Valid Loss: 0.013164947284044841\n",
      "Epoch: 49, Train Loss: 0.016441659539020156, Valid Loss: 0.013162387474606732\n",
      "Epoch: 50, Train Loss: 0.016439246068540313, Valid Loss: 0.013159890255114043\n",
      "Epoch: 51, Train Loss: 0.016436827742325702, Valid Loss: 0.013157443277937648\n",
      "Epoch: 52, Train Loss: 0.016434404483632835, Valid Loss: 0.013155036488671182\n",
      "Epoch: 53, Train Loss: 0.016431976226352677, Valid Loss: 0.013152661698207882\n",
      "Epoch: 54, Train Loss: 0.01642954291139924, Valid Loss: 0.013150312234927658\n",
      "Epoch: 55, Train Loss: 0.016427104484316103, Valid Loss: 0.013147982661912314\n",
      "Epoch: 56, Train Loss: 0.01642466089369021, Valid Loss: 0.013145668546974312\n",
      "Epoch: 57, Train Loss: 0.016422212090100544, Valid Loss: 0.013143366275597446\n",
      "Epoch: 58, Train Loss: 0.01641975802542144, Valid Loss: 0.013141072898756675\n",
      "Epoch: 59, Train Loss: 0.01641729865236081, Valid Loss: 0.013138786009096362\n",
      "Epoch: 60, Train Loss: 0.016414833924154017, Valid Loss: 0.013136503640170827\n",
      "Epoch: 61, Train Loss: 0.01641236379436096, Valid Loss: 0.013134224184443877\n",
      "Epoch: 62, Train Loss: 0.01640988821673146, Valid Loss: 0.013131946326549552\n",
      "Epoch: 63, Train Loss: 0.01640740714511592, Valid Loss: 0.013129668988970123\n",
      "Epoch: 64, Train Loss: 0.016404920533405976, Valid Loss: 0.013127391287818521\n",
      "Epoch: 65, Train Loss: 0.016402428335494972, Valid Loss: 0.013125112496843944\n",
      "Epoch: 66, Train Loss: 0.016399930505251608, Valid Loss: 0.013122832018130125\n",
      "Epoch: 67, Train Loss: 0.016397426996502262, Valid Loss: 0.01312054935824103\n",
      "Epoch: 68, Train Loss: 0.016394917763019063, Valid Loss: 0.01311826410880062\n",
      "Epoch: 69, Train Loss: 0.016392402758511754, Valid Loss: 0.013115975930682007\n",
      "Epoch: 70, Train Loss: 0.01638988193662211, Valid Loss: 0.013113684541134893\n",
      "Epoch: 71, Train Loss: 0.016387355250919947, Valid Loss: 0.01311138970330493\n",
      "Epoch: 72, Train Loss: 0.016384822654900294, Valid Loss: 0.013109091217700443\n",
      "Epoch: 73, Train Loss: 0.016382284101981216, Valid Loss: 0.013106788915244444\n",
      "Epoch: 74, Train Loss: 0.01637973954550219, Valid Loss: 0.013104482651617412\n",
      "Epoch: 75, Train Loss: 0.0163771889387227, Valid Loss: 0.013102172302650858\n",
      "Epoch: 76, Train Loss: 0.01637463223482113, Valid Loss: 0.013099857760576516\n",
      "Epoch: 77, Train Loss: 0.016372069386893732, Valid Loss: 0.01309753893097211\n",
      "Epoch: 78, Train Loss: 0.016369500347953675, Valid Loss: 0.013095215730274312\n",
      "Epoch: 79, Train Loss: 0.01636692507093021, Valid Loss: 0.013092888083753492\n",
      "Epoch: 80, Train Loss: 0.01636434350866782, Valid Loss: 0.013090555923864508\n",
      "Epoch: 81, Train Loss: 0.016361755613925406, Valid Loss: 0.01308821918890366\n",
      "Epoch: 82, Train Loss: 0.016359161339375514, Valid Loss: 0.01308587782191494\n",
      "Epoch: 83, Train Loss: 0.01635656063760355, Valid Loss: 0.013083531769799275\n",
      "Epoch: 84, Train Loss: 0.016353953461106994, Valid Loss: 0.0130811809825891\n",
      "Epoch: 85, Train Loss: 0.01635133976229467, Valid Loss: 0.013078825412857506\n",
      "Epoch: 86, Train Loss: 0.016348719493485955, Valid Loss: 0.01307646501523696\n",
      "Epoch: 87, Train Loss: 0.01634609260691004, Valid Loss: 0.013074099746027362\n",
      "Epoch: 88, Train Loss: 0.016343459054705186, Valid Loss: 0.013071729562876699\n",
      "Epoch: 89, Train Loss: 0.016340818788917962, Valid Loss: 0.013069354424520938\n",
      "Epoch: 90, Train Loss: 0.016338171761502512, Valid Loss: 0.013066974290572098\n",
      "Epoch: 91, Train Loss: 0.01633551792431982, Valid Loss: 0.01306458912134556\n",
      "Epoch: 92, Train Loss: 0.016332857229136955, Valid Loss: 0.013062198877719373\n",
      "Epoch: 93, Train Loss: 0.016330189627626373, Valid Loss: 0.013059803521019589\n",
      "Epoch: 94, Train Loss: 0.016327515071365137, Valid Loss: 0.013057403012926733\n",
      "Epoch: 95, Train Loss: 0.01632483351183425, Valid Loss: 0.013054997315399669\n",
      "Epoch: 96, Train Loss: 0.016322144900417886, Valid Loss: 0.013052586390613385\n",
      "Epoch: 97, Train Loss: 0.016319449188402713, Valid Loss: 0.013050170200908326\n",
      "Epoch: 98, Train Loss: 0.016316746326977154, Valid Loss: 0.013047748708749045\n",
      "Epoch: 99, Train Loss: 0.016314036267230683, Valid Loss: 0.0130453218766904\n",
      "Epoch: 100, Train Loss: 0.01631131896015312, Valid Loss: 0.01304288966735001\n",
      "Epoch: 101, Train Loss: 0.01630859435663395, Valid Loss: 0.013040452043385687\n",
      "Epoch: 102, Train Loss: 0.0163058624074616, Valid Loss: 0.013038008967477038\n",
      "Epoch: 103, Train Loss: 0.01630312306332277, Valid Loss: 0.01303556040231036\n",
      "Epoch: 104, Train Loss: 0.016300376274801725, Valid Loss: 0.013033106310566298\n",
      "Epoch: 105, Train Loss: 0.01629762199237963, Valid Loss: 0.013030646654909694\n",
      "Epoch: 106, Train Loss: 0.016294860166433858, Valid Loss: 0.013028181397981273\n",
      "Epoch: 107, Train Loss: 0.016292090747237344, Valid Loss: 0.01302571050239079\n",
      "Epoch: 108, Train Loss: 0.01628931368495787, Valid Loss: 0.013023233930711392\n",
      "Epoch: 109, Train Loss: 0.016286528929657457, Valid Loss: 0.01302075164547493\n",
      "Epoch: 110, Train Loss: 0.01628373643129166, Valid Loss: 0.013018263609168116\n",
      "Epoch: 111, Train Loss: 0.016280936139708924, Valid Loss: 0.013015769784229287\n",
      "Epoch: 112, Train Loss: 0.016278128004649967, Valid Loss: 0.013013270133045743\n",
      "Epoch: 113, Train Loss: 0.016275311975747102, Valid Loss: 0.013010764617951484\n",
      "Epoch: 114, Train Loss: 0.01627248800252359, Valid Loss: 0.013008253201225317\n",
      "Epoch: 115, Train Loss: 0.016269656034393044, Valid Loss: 0.013005735845089258\n",
      "Epoch: 116, Train Loss: 0.01626681602065877, Valid Loss: 0.013003212511707182\n",
      "Epoch: 117, Train Loss: 0.016263967910513155, Valid Loss: 0.013000683163183613\n",
      "Epoch: 118, Train Loss: 0.01626111165303704, Valid Loss: 0.012998147761562757\n",
      "Epoch: 119, Train Loss: 0.016258247197199125, Valid Loss: 0.012995606268827587\n",
      "Epoch: 120, Train Loss: 0.01625537449185534, Valid Loss: 0.01299305864689909\n",
      "Epoch: 121, Train Loss: 0.016252493485748257, Valid Loss: 0.012990504857635568\n",
      "Epoch: 122, Train Loss: 0.01624960412750648, Valid Loss: 0.012987944862832043\n",
      "Epoch: 123, Train Loss: 0.016246706365644067, Valid Loss: 0.01298537862421969\n",
      "Epoch: 124, Train Loss: 0.016243800148559945, Valid Loss: 0.012982806103465354\n",
      "Epoch: 125, Train Loss: 0.01624088542453732, Valid Loss: 0.012980227262171072\n",
      "Epoch: 126, Train Loss: 0.01623796214174311, Valid Loss: 0.012977642061873679\n",
      "Epoch: 127, Train Loss: 0.016235030248227367, Valid Loss: 0.012975050464044395\n",
      "Epoch: 128, Train Loss: 0.016232089691922746, Valid Loss: 0.012972452430088465\n",
      "Epoch: 129, Train Loss: 0.016229140420643905, Valid Loss: 0.012969847921344804\n",
      "Epoch: 130, Train Loss: 0.016226182382086975, Valid Loss: 0.012967236899085716\n",
      "Epoch: 131, Train Loss: 0.01622321552382904, Valid Loss: 0.01296461932451652\n",
      "Epoch: 132, Train Loss: 0.016220239793327554, Valid Loss: 0.012961995158775315\n",
      "Epoch: 133, Train Loss: 0.016217255137919842, Valid Loss: 0.01295936436293267\n",
      "Epoch: 134, Train Loss: 0.01621426150482257, Valid Loss: 0.012956726897991357\n",
      "Epoch: 135, Train Loss: 0.016211258841131223, Valid Loss: 0.012954082724886117\n",
      "Epoch: 136, Train Loss: 0.016208247093819586, Valid Loss: 0.012951431804483384\n",
      "Epoch: 137, Train Loss: 0.016205226209739246, Valid Loss: 0.01294877409758107\n",
      "Epoch: 138, Train Loss: 0.01620219613561911, Valid Loss: 0.01294610956490832\n",
      "Epoch: 139, Train Loss: 0.016199156818064882, Valid Loss: 0.012943438167125317\n",
      "Epoch: 140, Train Loss: 0.016196108203558598, Valid Loss: 0.012940759864823043\n",
      "Epoch: 141, Train Loss: 0.016193050238458146, Valid Loss: 0.012938074618523103\n",
      "Epoch: 142, Train Loss: 0.0161899828689968, Valid Loss: 0.012935382388677507\n",
      "Epoch: 143, Train Loss: 0.01618690604128274, Valid Loss: 0.01293268313566849\n",
      "Epoch: 144, Train Loss: 0.016183819701298608, Valid Loss: 0.01292997681980835\n",
      "Epoch: 145, Train Loss: 0.016180723794901077, Valid Loss: 0.012927263401339262\n",
      "Epoch: 146, Train Loss: 0.016177618267820364, Valid Loss: 0.0129245428404331\n",
      "Epoch: 147, Train Loss: 0.01617450306565985, Valid Loss: 0.0129218150971913\n",
      "Epoch: 148, Train Loss: 0.0161713781338956, Valid Loss: 0.012919080131644717\n",
      "Epoch: 149, Train Loss: 0.016168243417875993, Valid Loss: 0.012916337903753468\n",
      "Epoch: 150, Train Loss: 0.01616509886282128, Valid Loss: 0.012913588373406795\n",
      "Epoch: 151, Train Loss: 0.01616194441382321, Valid Loss: 0.012910831500422952\n",
      "Epoch: 152, Train Loss: 0.01615878001584459, Valid Loss: 0.01290806724454909\n",
      "Epoch: 153, Train Loss: 0.01615560561371895, Valid Loss: 0.012905295565461125\n",
      "Epoch: 154, Train Loss: 0.016152421152150136, Valid Loss: 0.012902516422763655\n",
      "Epoch: 155, Train Loss: 0.016149226575711936, Valid Loss: 0.012899729775989863\n",
      "Epoch: 156, Train Loss: 0.016146021828847744, Valid Loss: 0.012896935584601412\n",
      "Epoch: 157, Train Loss: 0.016142806855870186, Valid Loss: 0.012894133807988395\n",
      "Epoch: 158, Train Loss: 0.016139581600960778, Valid Loss: 0.012891324405469246\n",
      "Epoch: 159, Train Loss: 0.016136346008169603, Valid Loss: 0.012888507336290668\n",
      "Epoch: 160, Train Loss: 0.016133100021414968, Valid Loss: 0.012885682559627612\n",
      "Epoch: 161, Train Loss: 0.01612984358448311, Valid Loss: 0.012882850034583192\n",
      "Epoch: 162, Train Loss: 0.01612657664102786, Valid Loss: 0.012880009720188669\n",
      "Epoch: 163, Train Loss: 0.016123299134570366, Valid Loss: 0.012877161575403433\n",
      "Epoch: 164, Train Loss: 0.0161200110084988, Valid Loss: 0.012874305559114958\n",
      "Epoch: 165, Train Loss: 0.016116712206068053, Valid Loss: 0.0128714416301388\n",
      "Epoch: 166, Train Loss: 0.016113402670399513, Valid Loss: 0.012868569747218596\n",
      "Epoch: 167, Train Loss: 0.016110082344480758, Valid Loss: 0.012865689869026078\n",
      "Epoch: 168, Train Loss: 0.01610675117116533, Valid Loss: 0.012862801954161077\n",
      "Epoch: 169, Train Loss: 0.016103409093172493, Valid Loss: 0.01285990596115154\n",
      "Epoch: 170, Train Loss: 0.016100056053086984, Valid Loss: 0.01285700184845359\n",
      "Epoch: 171, Train Loss: 0.016096691993358836, Valid Loss: 0.012854089574451536\n",
      "Epoch: 172, Train Loss: 0.016093316856303105, Valid Loss: 0.012851169097457966\n",
      "Epoch: 173, Train Loss: 0.016089930584099712, Valid Loss: 0.012848240375713763\n",
      "Epoch: 174, Train Loss: 0.016086533118793264, Valid Loss: 0.0128453033673882\n",
      "Epoch: 175, Train Loss: 0.01608312440229284, Valid Loss: 0.012842358030579043\n",
      "Epoch: 176, Train Loss: 0.016079704376371847, Valid Loss: 0.012839404323312592\n",
      "Epoch: 177, Train Loss: 0.016076272982667863, Valid Loss: 0.012836442203543819\n",
      "Epoch: 178, Train Loss: 0.016072830162682485, Valid Loss: 0.012833471629156481\n",
      "Epoch: 179, Train Loss: 0.016069375857781194, Valid Loss: 0.012830492557963202\n",
      "Epoch: 180, Train Loss: 0.01606591000919324, Valid Loss: 0.012827504947705654\n",
      "Epoch: 181, Train Loss: 0.016062432558011527, Valid Loss: 0.01282450875605467\n",
      "Epoch: 182, Train Loss: 0.016058943445192524, Valid Loss: 0.012821503940610402\n",
      "Epoch: 183, Train Loss: 0.016055442611556156, Valid Loss: 0.012818490458902489\n",
      "Epoch: 184, Train Loss: 0.016051929997785753, Valid Loss: 0.012815468268390215\n",
      "Epoch: 185, Train Loss: 0.016048405544427966, Valid Loss: 0.012812437326462714\n",
      "Epoch: 186, Train Loss: 0.016044869191892738, Valid Loss: 0.012809397590439156\n",
      "Epoch: 187, Train Loss: 0.016041320880453253, Valid Loss: 0.01280634901756895\n",
      "Epoch: 188, Train Loss: 0.016037760550245913, Valid Loss: 0.012803291565031967\n",
      "Epoch: 189, Train Loss: 0.016034188141270323, Valid Loss: 0.012800225189938777\n",
      "Epoch: 190, Train Loss: 0.016030603593389297, Valid Loss: 0.012797149849330855\n",
      "Epoch: 191, Train Loss: 0.016027006846328865, Valid Loss: 0.012794065500180885\n",
      "Epoch: 192, Train Loss: 0.016023397839678318, Valid Loss: 0.012790972099392986\n",
      "Epoch: 193, Train Loss: 0.016019776512890216, Valid Loss: 0.012787869603802996\n",
      "Epoch: 194, Train Loss: 0.016016142805280468, Valid Loss: 0.012784757970178764\n",
      "Epoch: 195, Train Loss: 0.016012496656028403, Valid Loss: 0.012781637155220455\n",
      "Epoch: 196, Train Loss: 0.016008838004176826, Valid Loss: 0.012778507115560833\n",
      "Epoch: 197, Train Loss: 0.016005166788632137, Valid Loss: 0.012775367807765633\n",
      "Epoch: 198, Train Loss: 0.016001482948164426, Valid Loss: 0.012772219188333852\n",
      "Epoch: 199, Train Loss: 0.015997786421407614, Valid Loss: 0.01276906121369812\n",
      "Epoch: 200, Train Loss: 0.01599407714685958, Valid Loss: 0.01276589384022507\n",
      "Epoch: 201, Train Loss: 0.015990355062882305, Valid Loss: 0.012762717024215676\n",
      "Epoch: 202, Train Loss: 0.015986620107702073, Valid Loss: 0.012759530721905695\n",
      "Epoch: 203, Train Loss: 0.015982872219409628, Valid Loss: 0.012756334889466018\n",
      "Epoch: 204, Train Loss: 0.015979111335960375, Valid Loss: 0.012753129483003112\n",
      "Epoch: 205, Train Loss: 0.015975337395174607, Valid Loss: 0.012749914458559436\n",
      "Epoch: 206, Train Loss: 0.015971550334737735, Valid Loss: 0.01274668977211389\n",
      "Epoch: 207, Train Loss: 0.015967750092200517, Valid Loss: 0.01274345537958226\n",
      "Epoch: 208, Train Loss: 0.015963936604979342, Valid Loss: 0.01274021123681769\n",
      "Epoch: 209, Train Loss: 0.015960109810356497, Valid Loss: 0.012736957299611175\n",
      "Epoch: 210, Train Loss: 0.01595626964548046, Valid Loss: 0.01273369352369203\n",
      "Epoch: 211, Train Loss: 0.015952416047366233, Valid Loss: 0.012730419864728436\n",
      "Epoch: 212, Train Loss: 0.01594854895289563, Valid Loss: 0.012727136278327939\n",
      "Epoch: 213, Train Loss: 0.01594466829881767, Valid Loss: 0.012723842720038\n",
      "Epoch: 214, Train Loss: 0.0159407740217489, Valid Loss: 0.012720539145346543\n",
      "Epoch: 215, Train Loss: 0.015936866058173807, Valid Loss: 0.012717225509682522\n",
      "Epoch: 216, Train Loss: 0.01593294434444519, Valid Loss: 0.012713901768416526\n",
      "Epoch: 217, Train Loss: 0.015929008816784596, Valid Loss: 0.012710567876861348\n",
      "Epoch: 218, Train Loss: 0.015925059411282735, Valid Loss: 0.01270722379027262\n",
      "Epoch: 219, Train Loss: 0.01592109606389996, Valid Loss: 0.012703869463849436\n",
      "Epoch: 220, Train Loss: 0.015917118710466693, Valid Loss: 0.01270050485273499\n",
      "Epoch: 221, Train Loss: 0.015913127286683967, Valid Loss: 0.012697129912017257\n",
      "Epoch: 222, Train Loss: 0.015909121728123896, Valid Loss: 0.01269374459672964\n",
      "Epoch: 223, Train Loss: 0.01590510197023021, Valid Loss: 0.012690348861851705\n",
      "Epoch: 224, Train Loss: 0.01590106794831881, Valid Loss: 0.012686942662309833\n",
      "Epoch: 225, Train Loss: 0.01589701959757833, Valid Loss: 0.012683525952978003\n",
      "Epoch: 226, Train Loss: 0.015892956853070708, Valid Loss: 0.01268009868867849\n",
      "Epoch: 227, Train Loss: 0.015888879649731822, Valid Loss: 0.01267666082418265\n",
      "Epoch: 228, Train Loss: 0.015884787922372086, Valid Loss: 0.012673212314211688\n",
      "Epoch: 229, Train Loss: 0.015880681605677113, Valid Loss: 0.012669753113437444\n",
      "Epoch: 230, Train Loss: 0.015876560634208375, Valid Loss: 0.012666283176483209\n",
      "Epoch: 231, Train Loss: 0.01587242494240388, Valid Loss: 0.012662802457924541\n",
      "Epoch: 232, Train Loss: 0.0158682744645789, Valid Loss: 0.012659310912290144\n",
      "Epoch: 233, Train Loss: 0.0158641091349267, Valid Loss: 0.012655808494062665\n",
      "Epoch: 234, Train Loss: 0.01585992888751926, Valid Loss: 0.012652295157679641\n",
      "Epoch: 235, Train Loss: 0.01585573365630807, Valid Loss: 0.012648770857534365\n",
      "Epoch: 236, Train Loss: 0.01585152337512494, Valid Loss: 0.012645235547976785\n",
      "Epoch: 237, Train Loss: 0.01584729797768278, Valid Loss: 0.012641689183314472\n",
      "Epoch: 238, Train Loss: 0.015843057397576462, Valid Loss: 0.01263813171781356\n",
      "Epoch: 239, Train Loss: 0.015838801568283673, Valid Loss: 0.012634563105699707\n",
      "Epoch: 240, Train Loss: 0.015834530423165814, Valid Loss: 0.012630983301159094\n",
      "Epoch: 241, Train Loss: 0.015830243895468873, Valid Loss: 0.012627392258339427\n",
      "Epoch: 242, Train Loss: 0.015825941918324402, Valid Loss: 0.012623789931350984\n",
      "Epoch: 243, Train Loss: 0.01582162442475045, Valid Loss: 0.012620176274267621\n",
      "Epoch: 244, Train Loss: 0.015817291347652508, Valid Loss: 0.0126165512411279\n",
      "Epoch: 245, Train Loss: 0.015812942619824574, Valid Loss: 0.012612914785936109\n",
      "Epoch: 246, Train Loss: 0.015808578173950132, Valid Loss: 0.012609266862663412\n",
      "Epoch: 247, Train Loss: 0.015804197942603234, Valid Loss: 0.012605607425248971\n",
      "Epoch: 248, Train Loss: 0.01579980185824954, Valid Loss: 0.012601936427601072\n",
      "Epoch: 249, Train Loss: 0.015795389853247445, Valid Loss: 0.012598253823598303\n",
      "Epoch: 250, Train Loss: 0.015790961859849215, Valid Loss: 0.012594559567090746\n",
      "Epoch: 251, Train Loss: 0.015786517810202103, Valid Loss: 0.012590853611901189\n",
      "Epoch: 252, Train Loss: 0.015782057636349562, Valid Loss: 0.012587135911826317\n",
      "Epoch: 253, Train Loss: 0.015777581270232422, Valid Loss: 0.012583406420638031\n",
      "Epoch: 254, Train Loss: 0.015773088643690137, Valid Loss: 0.01257966509208465\n",
      "Epoch: 255, Train Loss: 0.015768579688462025, Valid Loss: 0.012575911879892229\n",
      "Epoch: 256, Train Loss: 0.015764054336188577, Valid Loss: 0.012572146737765896\n",
      "Epoch: 257, Train Loss: 0.015759512518412736, Valid Loss: 0.01256836961939115\n",
      "Epoch: 258, Train Loss: 0.01575495416658126, Valid Loss: 0.012564580478435249\n",
      "Epoch: 259, Train Loss: 0.015750379212046067, Valid Loss: 0.012560779268548561\n",
      "Epoch: 260, Train Loss: 0.01574578758606564, Valid Loss: 0.012556965943366005\n",
      "Epoch: 261, Train Loss: 0.015741179219806455, Valid Loss: 0.012553140456508424\n",
      "Epoch: 262, Train Loss: 0.015736554044344406, Valid Loss: 0.01254930276158408\n",
      "Epoch: 263, Train Loss: 0.0157319119906663, Valid Loss: 0.012545452812190093\n",
      "Epoch: 264, Train Loss: 0.015727252989671366, Valid Loss: 0.012541590561913956\n",
      "Epoch: 265, Train Loss: 0.01572257697217279, Valid Loss: 0.012537715964335035\n",
      "Epoch: 266, Train Loss: 0.01571788386889926, Valid Loss: 0.012533828973026106\n",
      "Epoch: 267, Train Loss: 0.01571317361049659, Valid Loss: 0.01252992954155494\n",
      "Epoch: 268, Train Loss: 0.01570844612752933, Valid Loss: 0.012526017623485862\n",
      "Epoch: 269, Train Loss: 0.015703701350482414, Valid Loss: 0.01252209317238139\n",
      "Epoch: 270, Train Loss: 0.01569893920976287, Valid Loss: 0.01251815614180384\n",
      "Epoch: 271, Train Loss: 0.015694159635701505, Valid Loss: 0.012514206485317014\n",
      "Epoch: 272, Train Loss: 0.01568936255855468, Valid Loss: 0.012510244156487866\n",
      "Epoch: 273, Train Loss: 0.01568454790850607, Valid Loss: 0.012506269108888204\n",
      "Epoch: 274, Train Loss: 0.015679715615668482, Valid Loss: 0.012502281296096448\n",
      "Epoch: 275, Train Loss: 0.0156748656100857, Valid Loss: 0.012498280671699369\n",
      "Epoch: 276, Train Loss: 0.01566999782173435, Valid Loss: 0.01249426718929387\n",
      "Epoch: 277, Train Loss: 0.015665112180525815, Valid Loss: 0.012490240802488811\n",
      "Epoch: 278, Train Loss: 0.015660208616308166, Valid Loss: 0.01248620146490683\n",
      "Epoch: 279, Train Loss: 0.015655287058868147, Valid Loss: 0.012482149130186198\n",
      "Epoch: 280, Train Loss: 0.01565034743793316, Valid Loss: 0.012478083751982729\n",
      "Epoch: 281, Train Loss: 0.015645389683173333, Valid Loss: 0.012474005283971664\n",
      "Epoch: 282, Train Loss: 0.015640413724203554, Valid Loss: 0.012469913679849622\n",
      "Epoch: 283, Train Loss: 0.015635419490585615, Valid Loss: 0.012465808893336566\n",
      "Epoch: 284, Train Loss: 0.01563040691183033, Valid Loss: 0.012461690878177797\n",
      "Epoch: 285, Train Loss: 0.015625375917399712, Valid Loss: 0.012457559588145949\n",
      "Epoch: 286, Train Loss: 0.015620326436709195, Valid Loss: 0.012453414977043067\n",
      "Epoch: 287, Train Loss: 0.015615258399129866, Valid Loss: 0.012449256998702663\n",
      "Epoch: 288, Train Loss: 0.015610171733990754, Valid Loss: 0.012445085606991806\n",
      "Epoch: 289, Train Loss: 0.015605066370581145, Valid Loss: 0.012440900755813264\n",
      "Epoch: 290, Train Loss: 0.015599942238152928, Valid Loss: 0.012436702399107649\n",
      "Epoch: 291, Train Loss: 0.01559479926592299, Valid Loss: 0.012432490490855605\n",
      "Epoch: 292, Train Loss: 0.015589637383075635, Valid Loss: 0.012428264985080019\n",
      "Epoch: 293, Train Loss: 0.01558445651876506, Valid Loss: 0.01242402583584825\n",
      "Epoch: 294, Train Loss: 0.015579256602117822, Valid Loss: 0.012419772997274403\n",
      "Epoch: 295, Train Loss: 0.015574037562235417, Valid Loss: 0.012415506423521622\n",
      "Epoch: 296, Train Loss: 0.015568799328196813, Valid Loss: 0.012411226068804423\n",
      "Epoch: 297, Train Loss: 0.01556354182906109, Valid Loss: 0.012406931887391025\n",
      "Epoch: 298, Train Loss: 0.015558264993870067, Valid Loss: 0.012402623833605754\n",
      "Epoch: 299, Train Loss: 0.015552968751651011, Valid Loss: 0.012398301861831435\n",
      "Epoch: 300, Train Loss: 0.015547653031419343, Valid Loss: 0.012393965926511855\n",
      "Epoch: 301, Train Loss: 0.01554231776218142, Valid Loss: 0.012389615982154207\n",
      "Epoch: 302, Train Loss: 0.015536962872937326, Valid Loss: 0.012385251983331598\n",
      "Epoch: 303, Train Loss: 0.015531588292683718, Valid Loss: 0.012380873884685605\n",
      "Epoch: 304, Train Loss: 0.015526193950416725, Valid Loss: 0.012376481640928772\n",
      "Epoch: 305, Train Loss: 0.015520779775134842, Valid Loss: 0.012372075206847266\n",
      "Epoch: 306, Train Loss: 0.015515345695841919, Valid Loss: 0.012367654537303449\n",
      "Epoch: 307, Train Loss: 0.015509891641550156, Valid Loss: 0.012363219587238553\n",
      "Epoch: 308, Train Loss: 0.015504417541283141, Valid Loss: 0.012358770311675352\n",
      "Epoch: 309, Train Loss: 0.015498923324078944, Valid Loss: 0.012354306665720868\n",
      "Epoch: 310, Train Loss: 0.015493408918993243, Valid Loss: 0.012349828604569105\n",
      "Epoch: 311, Train Loss: 0.015487874255102488, Valid Loss: 0.012345336083503857\n",
      "Epoch: 312, Train Loss: 0.01548231926150711, Valid Loss: 0.012340829057901466\n",
      "Epoch: 313, Train Loss: 0.015476743867334775, Valid Loss: 0.012336307483233687\n",
      "Epoch: 314, Train Loss: 0.015471148001743687, Valid Loss: 0.012331771315070536\n",
      "Epoch: 315, Train Loss: 0.0154655315939259, Valid Loss: 0.012327220509083211\n",
      "Epoch: 316, Train Loss: 0.015459894573110726, Valid Loss: 0.01232265502104698\n",
      "Epoch: 317, Train Loss: 0.01545423686856813, Valid Loss: 0.012318074806844196\n",
      "Epoch: 318, Train Loss: 0.015448558409612222, Valid Loss: 0.01231347982246724\n",
      "Epoch: 319, Train Loss: 0.015442859125604743, Valid Loss: 0.012308870024021569\n",
      "Epoch: 320, Train Loss: 0.015437138945958625, Valid Loss: 0.01230424536772877\n",
      "Epoch: 321, Train Loss: 0.015431397800141591, Valid Loss: 0.012299605809929656\n",
      "Epoch: 322, Train Loss: 0.015425635617679795, Valid Loss: 0.012294951307087368\n",
      "Epoch: 323, Train Loss: 0.015419852328161496, Valid Loss: 0.012290281815790545\n",
      "Epoch: 324, Train Loss: 0.015414047861240785, Valid Loss: 0.0122855972927565\n",
      "Epoch: 325, Train Loss: 0.015408222146641387, Valid Loss: 0.012280897694834448\n",
      "Epoch: 326, Train Loss: 0.01540237511416045, Valid Loss: 0.012276182979008751\n",
      "Epoch: 327, Train Loss: 0.01539650669367241, Valid Loss: 0.012271453102402193\n",
      "Epoch: 328, Train Loss: 0.015390616815132915, Valid Loss: 0.012266708022279318\n",
      "Epoch: 329, Train Loss: 0.01538470540858277, Valid Loss: 0.012261947696049769\n",
      "Epoch: 330, Train Loss: 0.015378772404151942, Valid Loss: 0.012257172081271658\n",
      "Epoch: 331, Train Loss: 0.015372817732063601, Valid Loss: 0.012252381135655008\n",
      "Epoch: 332, Train Loss: 0.015366841322638205, Valid Loss: 0.012247574817065177\n",
      "Epoch: 333, Train Loss: 0.015360843106297657, Valid Loss: 0.012242753083526361\n",
      "Epoch: 334, Train Loss: 0.015354823013569484, Valid Loss: 0.012237915893225093\n",
      "Epoch: 335, Train Loss: 0.015348780975091058, Valid Loss: 0.012233063204513811\n",
      "Epoch: 336, Train Loss: 0.01534271692161388, Valid Loss: 0.012228194975914417\n",
      "Epoch: 337, Train Loss: 0.015336630784007916, Valid Loss: 0.01222331116612191\n",
      "Epoch: 338, Train Loss: 0.01533052249326595, Valid Loss: 0.012218411734008039\n",
      "Epoch: 339, Train Loss: 0.015324391980508027, Valid Loss: 0.012213496638624963\n",
      "Epoch: 340, Train Loss: 0.015318239176985896, Valid Loss: 0.012208565839208999\n",
      "Epoch: 341, Train Loss: 0.015312064014087542, Valid Loss: 0.012203619295184357\n",
      "Epoch: 342, Train Loss: 0.015305866423341752, Valid Loss: 0.012198656966166913\n",
      "Epoch: 343, Train Loss: 0.015299646336422704, Valid Loss: 0.012193678811968048\n",
      "Epoch: 344, Train Loss: 0.015293403685154652, Valid Loss: 0.01218868479259849\n",
      "Epoch: 345, Train Loss: 0.015287138401516619, Valid Loss: 0.012183674868272196\n",
      "Epoch: 346, Train Loss: 0.015280850417647146, Valid Loss: 0.012178648999410279\n",
      "Epoch: 347, Train Loss: 0.015274539665849116, Valid Loss: 0.012173607146644963\n",
      "Epoch: 348, Train Loss: 0.015268206078594587, Valid Loss: 0.012168549270823554\n",
      "Epoch: 349, Train Loss: 0.0152618495885297, Valid Loss: 0.012163475333012487\n",
      "Epoch: 350, Train Loss: 0.015255470128479642, Valid Loss: 0.012158385294501342\n",
      "Epoch: 351, Train Loss: 0.015249067631453608, Valid Loss: 0.01215327911680699\n",
      "Epoch: 352, Train Loss: 0.015242642030649895, Valid Loss: 0.012148156761677645\n",
      "Epoch: 353, Train Loss: 0.015236193259460967, Valid Loss: 0.012143018191097069\n",
      "Epoch: 354, Train Loss: 0.015229721251478603, Valid Loss: 0.012137863367288759\n",
      "Epoch: 355, Train Loss: 0.015223225940499102, Valid Loss: 0.012132692252720142\n",
      "Epoch: 356, Train Loss: 0.015216707260528527, Valid Loss: 0.012127504810106849\n",
      "Epoch: 357, Train Loss: 0.015210165145787989, Valid Loss: 0.012122301002417013\n",
      "Epoch: 358, Train Loss: 0.015203599530718986, Valid Loss: 0.012117080792875582\n",
      "Epoch: 359, Train Loss: 0.015197010349988818, Valid Loss: 0.012111844144968659\n",
      "Epoch: 360, Train Loss: 0.015190397538495992, Valid Loss: 0.012106591022447932\n",
      "Epoch: 361, Train Loss: 0.015183761031375744, Valid Loss: 0.012101321389335057\n",
      "Epoch: 362, Train Loss: 0.015177100764005566, Valid Loss: 0.012096035209926144\n",
      "Epoch: 363, Train Loss: 0.015170416672010792, Valid Loss: 0.012090732448796227\n",
      "Epoch: 364, Train Loss: 0.015163708691270232, Valid Loss: 0.012085413070803791\n",
      "Epoch: 365, Train Loss: 0.015156976757921879, Valid Loss: 0.012080077041095344\n",
      "Epoch: 366, Train Loss: 0.015150220808368623, Valid Loss: 0.012074724325109967\n",
      "Epoch: 367, Train Loss: 0.015143440779284055, Valid Loss: 0.012069354888583976\n",
      "Epoch: 368, Train Loss: 0.015136636607618293, Valid Loss: 0.012063968697555544\n",
      "Epoch: 369, Train Loss: 0.015129808230603859, Valid Loss: 0.012058565718369413\n",
      "Epoch: 370, Train Loss: 0.015122955585761636, Valid Loss: 0.012053145917681569\n",
      "Epoch: 371, Train Loss: 0.015116078610906823, Valid Loss: 0.012047709262464035\n",
      "Epoch: 372, Train Loss: 0.01510917724415499, Valid Loss: 0.012042255720009637\n",
      "Epoch: 373, Train Loss: 0.01510225142392814, Valid Loss: 0.012036785257936798\n",
      "Epoch: 374, Train Loss: 0.015095301088960853, Valid Loss: 0.012031297844194414\n",
      "Epoch: 375, Train Loss: 0.015088326178306452, Valid Loss: 0.012025793447066701\n",
      "Epoch: 376, Train Loss: 0.015081326631343242, Valid Loss: 0.012020272035178107\n",
      "Epoch: 377, Train Loss: 0.015074302387780776, Valid Loss: 0.012014733577498266\n",
      "Epoch: 378, Train Loss: 0.015067253387666166, Valid Loss: 0.012009178043346948\n",
      "Epoch: 379, Train Loss: 0.015060179571390492, Valid Loss: 0.012003605402399057\n",
      "Epoch: 380, Train Loss: 0.015053080879695186, Valid Loss: 0.01199801562468967\n",
      "Epoch: 381, Train Loss: 0.015045957253678507, Valid Loss: 0.011992408680619078\n",
      "Epoch: 382, Train Loss: 0.015038808634802066, Valid Loss: 0.011986784540957895\n",
      "Epoch: 383, Train Loss: 0.015031634964897378, Valid Loss: 0.01198114317685216\n",
      "Epoch: 384, Train Loss: 0.015024436186172477, Valid Loss: 0.011975484559828478\n",
      "Epoch: 385, Train Loss: 0.015017212241218568, Valid Loss: 0.01196980866179922\n",
      "Epoch: 386, Train Loss: 0.015009963073016738, Valid Loss: 0.011964115455067688\n",
      "Epoch: 387, Train Loss: 0.015002688624944693, Valid Loss: 0.011958404912333374\n",
      "Epoch: 388, Train Loss: 0.014995388840783568, Valid Loss: 0.01195267700669722\n",
      "Epoch: 389, Train Loss: 0.014988063664724752, Valid Loss: 0.011946931711666893\n",
      "Epoch: 390, Train Loss: 0.014980713041376797, Valid Loss: 0.0119411690011621\n",
      "Epoch: 391, Train Loss: 0.014973336915772328, Valid Loss: 0.01193538884951993\n",
      "Epoch: 392, Train Loss: 0.014965935233375041, Valid Loss: 0.01192959123150023\n",
      "Epoch: 393, Train Loss: 0.014958507940086707, Valid Loss: 0.011923776122290985\n",
      "Epoch: 394, Train Loss: 0.01495105498225426, Valid Loss: 0.011917943497513748\n",
      "Epoch: 395, Train Loss: 0.014943576306676892, Valid Loss: 0.011912093333229087\n",
      "Epoch: 396, Train Loss: 0.014936071860613213, Valid Loss: 0.011906225605942034\n",
      "Epoch: 397, Train Loss: 0.014928541591788453, Valid Loss: 0.011900340292607598\n",
      "Epoch: 398, Train Loss: 0.014920985448401702, Valid Loss: 0.011894437370636285\n",
      "Epoch: 399, Train Loss: 0.014913403379133184, Valid Loss: 0.011888516817899632\n",
      "Epoch: 400, Train Loss: 0.014905795333151605, Valid Loss: 0.011882578612735775\n",
      "Epoch: 401, Train Loss: 0.014898161260121496, Valid Loss: 0.011876622733955034\n",
      "Epoch: 402, Train Loss: 0.014890501110210647, Valid Loss: 0.01187064916084554\n",
      "Epoch: 403, Train Loss: 0.014882814834097527, Valid Loss: 0.011864657873178827\n",
      "Epoch: 404, Train Loss: 0.014875102382978808, Valid Loss: 0.011858648851215537\n",
      "Epoch: 405, Train Loss: 0.014867363708576872, Valid Loss: 0.011852622075711064\n",
      "Epoch: 406, Train Loss: 0.014859598763147392, Valid Loss: 0.011846577527921261\n",
      "Epoch: 407, Train Loss: 0.014851807499486933, Valid Loss: 0.011840515189608143\n",
      "Epoch: 408, Train Loss: 0.014843989870940594, Valid Loss: 0.011834435043045632\n",
      "Epoch: 409, Train Loss: 0.014836145831409723, Valid Loss: 0.01182833707102531\n",
      "Epoch: 410, Train Loss: 0.014828275335359598, Valid Loss: 0.011822221256862183\n",
      "Epoch: 411, Train Loss: 0.014820378337827211, Valid Loss: 0.011816087584400484\n",
      "Epoch: 412, Train Loss: 0.014812454794429051, Valid Loss: 0.011809936038019461\n",
      "Epoch: 413, Train Loss: 0.014804504661368949, Valid Loss: 0.01180376660263921\n",
      "Epoch: 414, Train Loss: 0.014796527895445923, Valid Loss: 0.011797579263726515\n",
      "Epoch: 415, Train Loss: 0.01478852445406209, Valid Loss: 0.011791374007300709\n",
      "Epoch: 416, Train Loss: 0.014780494295230595, Valid Loss: 0.011785150819939513\n",
      "Epoch: 417, Train Loss: 0.01477243737758357, Valid Loss: 0.011778909688784955\n",
      "Epoch: 418, Train Loss: 0.014764353660380149, Valid Loss: 0.011772650601549242\n",
      "Epoch: 419, Train Loss: 0.014756243103514475, Valid Loss: 0.011766373546520667\n",
      "Epoch: 420, Train Loss: 0.014748105667523765, Valid Loss: 0.011760078512569562\n",
      "Epoch: 421, Train Loss: 0.014739941313596419, Valid Loss: 0.01175376548915418\n",
      "Epoch: 422, Train Loss: 0.014731750003580102, Valid Loss: 0.011747434466326673\n",
      "Epoch: 423, Train Loss: 0.014723531699989925, Valid Loss: 0.011741085434739035\n",
      "Epoch: 424, Train Loss: 0.014715286366016605, Valid Loss: 0.011734718385649061\n",
      "Epoch: 425, Train Loss: 0.014707013965534657, Valid Loss: 0.011728333310926311\n",
      "Epoch: 426, Train Loss: 0.01469871446311064, Valid Loss: 0.01172193020305809\n",
      "Epoch: 427, Train Loss: 0.014690387824011395, Valid Loss: 0.01171550905515545\n",
      "Epoch: 428, Train Loss: 0.014682034014212331, Valid Loss: 0.011709069860959155\n",
      "Epoch: 429, Train Loss: 0.014673653000405712, Valid Loss: 0.011702612614845677\n",
      "Epoch: 430, Train Loss: 0.014665244750008995, Valid Loss: 0.011696137311833226\n",
      "Epoch: 431, Train Loss: 0.014656809231173159, Valid Loss: 0.011689643947587708\n",
      "Epoch: 432, Train Loss: 0.01464834641279108, Valid Loss: 0.01168313251842877\n",
      "Epoch: 433, Train Loss: 0.014639856264505915, Valid Loss: 0.01167660302133578\n",
      "Epoch: 434, Train Loss: 0.014631338756719488, Valid Loss: 0.011670055453953852\n",
      "Epoch: 435, Train Loss: 0.014622793860600738, Valid Loss: 0.011663489814599859\n",
      "Epoch: 436, Train Loss: 0.014614221548094128, Valid Loss: 0.011656906102268424\n",
      "Epoch: 437, Train Loss: 0.014605621791928125, Valid Loss: 0.011650304316637937\n",
      "Epoch: 438, Train Loss: 0.014596994565623635, Valid Loss: 0.011643684458076555\n",
      "Epoch: 439, Train Loss: 0.014588339843502518, Valid Loss: 0.011637046527648215\n",
      "Epoch: 440, Train Loss: 0.014579657600696063, Valid Loss: 0.011630390527118612\n",
      "Epoch: 441, Train Loss: 0.014570947813153485, Valid Loss: 0.011623716458961207\n",
      "Epoch: 442, Train Loss: 0.014562210457650453, Valid Loss: 0.011617024326363199\n",
      "Epoch: 443, Train Loss: 0.014553445511797623, Valid Loss: 0.011610314133231504\n",
      "Epoch: 444, Train Loss: 0.014544652954049145, Valid Loss: 0.011603585884198733\n",
      "Epoch: 445, Train Loss: 0.014535832763711218, Valid Loss: 0.011596839584629147\n",
      "Epoch: 446, Train Loss: 0.014526984920950633, Valid Loss: 0.011590075240624597\n",
      "Epoch: 447, Train Loss: 0.014518109406803321, Valid Loss: 0.01158329285903049\n",
      "Epoch: 448, Train Loss: 0.014509206203182906, Valid Loss: 0.01157649244744167\n",
      "Epoch: 449, Train Loss: 0.014500275292889248, Valid Loss: 0.011569674014208381\n",
      "Epoch: 450, Train Loss: 0.014491316659617023, Valid Loss: 0.011562837568442128\n",
      "Epoch: 451, Train Loss: 0.01448233028796425, Valid Loss: 0.01155598312002158\n",
      "Epoch: 452, Train Loss: 0.01447331616344086, Valid Loss: 0.01154911067959842\n",
      "Epoch: 453, Train Loss: 0.01446427427247724, Valid Loss: 0.011542220258603209\n",
      "Epoch: 454, Train Loss: 0.014455204602432783, Valid Loss: 0.011535311869251205\n",
      "Epoch: 455, Train Loss: 0.014446107141604414, Valid Loss: 0.011528385524548178\n",
      "Epoch: 456, Train Loss: 0.01443698187923513, Valid Loss: 0.011521441238296189\n",
      "Epoch: 457, Train Loss: 0.014427828805522536, Valid Loss: 0.011514479025099375\n",
      "Epoch: 458, Train Loss: 0.014418647911627336, Valid Loss: 0.011507498900369678\n",
      "Epoch: 459, Train Loss: 0.014409439189681836, Valid Loss: 0.011500500880332547\n",
      "Epoch: 460, Train Loss: 0.014400202632798459, Valid Loss: 0.011493484982032677\n",
      "Epoch: 461, Train Loss: 0.014390938235078187, Valid Loss: 0.011486451223339626\n",
      "Epoch: 462, Train Loss: 0.014381645991619047, Valid Loss: 0.011479399622953482\n",
      "Epoch: 463, Train Loss: 0.014372325898524529, Valid Loss: 0.011472330200410462\n",
      "Epoch: 464, Train Loss: 0.014362977952912028, Valid Loss: 0.011465242976088481\n",
      "Epoch: 465, Train Loss: 0.01435360215292124, Valid Loss: 0.011458137971212728\n",
      "Epoch: 466, Train Loss: 0.014344198497722541, Valid Loss: 0.011451015207861133\n",
      "Epoch: 467, Train Loss: 0.014334766987525343, Valid Loss: 0.011443874708969884\n",
      "Epoch: 468, Train Loss: 0.01432530762358644, Valid Loss: 0.011436716498338858\n",
      "Epoch: 469, Train Loss: 0.014315820408218294, Valid Loss: 0.011429540600637014\n",
      "Epoch: 470, Train Loss: 0.014306305344797333, Valid Loss: 0.011422347041407798\n",
      "Epoch: 471, Train Loss: 0.01429676243777219, Valid Loss: 0.01141513584707441\n",
      "Epoch: 472, Train Loss: 0.014287191692671916, Valid Loss: 0.011407907044945167\n",
      "Epoch: 473, Train Loss: 0.014277593116114184, Valid Loss: 0.011400660663218693\n",
      "Epoch: 474, Train Loss: 0.014267966715813417, Valid Loss: 0.01139339673098915\n",
      "Epoch: 475, Train Loss: 0.014258312500588914, Valid Loss: 0.011386115278251369\n",
      "Epoch: 476, Train Loss: 0.014248630480372929, Valid Loss: 0.011378816335906011\n",
      "Epoch: 477, Train Loss: 0.014238920666218688, Valid Loss: 0.011371499935764591\n",
      "Epoch: 478, Train Loss: 0.014229183070308425, Valid Loss: 0.0113641661105545\n",
      "Epoch: 479, Train Loss: 0.014219417705961288, Valid Loss: 0.011356814893923997\n",
      "Epoch: 480, Train Loss: 0.014209624587641278, Valid Loss: 0.011349446320447099\n",
      "Epoch: 481, Train Loss: 0.014199803730965093, Valid Loss: 0.01134206042562845\n",
      "Epoch: 482, Train Loss: 0.014189955152709962, Valid Loss: 0.011334657245908148\n",
      "Epoch: 483, Train Loss: 0.014180078870821386, Valid Loss: 0.011327236818666472\n",
      "Epoch: 484, Train Loss: 0.01417017490442086, Valid Loss: 0.011319799182228604\n",
      "Epoch: 485, Train Loss: 0.014160243273813536, Valid Loss: 0.011312344375869246\n",
      "Epoch: 486, Train Loss: 0.01415028400049581, Valid Loss: 0.011304872439817225\n",
      "Epoch: 487, Train Loss: 0.014140297107162894, Valid Loss: 0.011297383415259992\n",
      "Epoch: 488, Train Loss: 0.014130282617716275, Valid Loss: 0.011289877344348087\n",
      "Epoch: 489, Train Loss: 0.014120240557271154, Valid Loss: 0.011282354270199529\n",
      "Epoch: 490, Train Loss: 0.014110170952163818, Valid Loss: 0.01127481423690415\n",
      "Epoch: 491, Train Loss: 0.014100073829958924, Valid Loss: 0.01126725728952785\n",
      "Epoch: 492, Train Loss: 0.014089949219456735, Valid Loss: 0.011259683474116803\n",
      "Epoch: 493, Train Loss: 0.0140797971507003, Valid Loss: 0.011252092837701564\n",
      "Epoch: 494, Train Loss: 0.014069617654982531, Valid Loss: 0.011244485428301124\n",
      "Epoch: 495, Train Loss: 0.014059410764853226, Valid Loss: 0.011236861294926926\n",
      "Epoch: 496, Train Loss: 0.014049176514126035, Valid Loss: 0.01122922048758672\n",
      "Epoch: 497, Train Loss: 0.014038914937885316, Valid Loss: 0.011221563057288449\n",
      "Epoch: 498, Train Loss: 0.014028626072492943, Valid Loss: 0.011213889056043968\n",
      "Epoch: 499, Train Loss: 0.014018309955595018, Valid Loss: 0.011206198536872736\n",
      "Epoch: 500, Train Loss: 0.014007966626128502, Valid Loss: 0.011198491553805432\n",
      "Epoch: 501, Train Loss: 0.01399759612432778, Valid Loss: 0.011190768161887445\n",
      "Epoch: 502, Train Loss: 0.013987198491731113, Valid Loss: 0.011183028417182342\n",
      "Epoch: 503, Train Loss: 0.013976773771187029, Valid Loss: 0.011175272376775208\n",
      "Epoch: 504, Train Loss: 0.013966322006860613, Valid Loss: 0.011167500098775915\n",
      "Epoch: 505, Train Loss: 0.013955843244239693, Valid Loss: 0.011159711642322314\n",
      "Epoch: 506, Train Loss: 0.013945337530140975, Valid Loss: 0.011151907067583318\n",
      "Epoch: 507, Train Loss: 0.013934804912716028, Valid Loss: 0.011144086435761924\n",
      "Epoch: 508, Train Loss: 0.01392424544145722, Valid Loss: 0.011136249809098137\n",
      "Epoch: 509, Train Loss: 0.013913659167203518, Valid Loss: 0.011128397250871759\n",
      "Epoch: 510, Train Loss: 0.013903046142146228, Valid Loss: 0.011120528825405165\n",
      "Epoch: 511, Train Loss: 0.013892406419834592, Valid Loss: 0.011112644598065914\n",
      "Epoch: 512, Train Loss: 0.013881740055181294, Valid Loss: 0.011104744635269309\n",
      "Epoch: 513, Train Loss: 0.013871047104467888, Valid Loss: 0.011096829004480816\n",
      "Epoch: 514, Train Loss: 0.013860327625350069, Valid Loss: 0.011088897774218448\n",
      "Epoch: 515, Train Loss: 0.01384958167686288, Valid Loss: 0.011080951014054976\n",
      "Epoch: 516, Train Loss: 0.013838809319425771, Valid Loss: 0.01107298879462009\n",
      "Epoch: 517, Train Loss: 0.013828010614847558, Valid Loss: 0.011065011187602452\n",
      "Epoch: 518, Train Loss: 0.013817185626331295, Valid Loss: 0.011057018265751617\n",
      "Epoch: 519, Train Loss: 0.013806334418478958, Valid Loss: 0.011049010102879871\n",
      "Epoch: 520, Train Loss: 0.013795457057296089, Valid Loss: 0.011040986773863976\n",
      "Epoch: 521, Train Loss: 0.013784553610196265, Valid Loss: 0.011032948354646757\n",
      "Epoch: 522, Train Loss: 0.013773624146005465, Valid Loss: 0.011024894922238645\n",
      "Epoch: 523, Train Loss: 0.01376266873496631, Valid Loss: 0.011016826554719064\n",
      "Epoch: 524, Train Loss: 0.013751687448742174, Valid Loss: 0.011008743331237705\n",
      "Epoch: 525, Train Loss: 0.013740680360421162, Valid Loss: 0.011000645332015729\n",
      "Epoch: 526, Train Loss: 0.01372964754451996, Valid Loss: 0.010992532638346814\n",
      "Epoch: 527, Train Loss: 0.013718589076987567, Valid Loss: 0.010984405332598096\n",
      "Epoch: 528, Train Loss: 0.013707505035208874, Valid Loss: 0.010976263498211014\n",
      "Epoch: 529, Train Loss: 0.013696395498008102, Valid Loss: 0.010968107219702006\n",
      "Epoch: 530, Train Loss: 0.01368526054565213, Valid Loss: 0.01095993658266312\n",
      "Epoch: 531, Train Loss: 0.013674100259853656, Valid Loss: 0.01095175167376247\n",
      "Epoch: 532, Train Loss: 0.013662914723774238, Valid Loss: 0.010943552580744599\n",
      "Epoch: 533, Train Loss: 0.013651704022027172, Valid Loss: 0.010935339392430707\n",
      "Epoch: 534, Train Loss: 0.013640468240680237, Valid Loss: 0.01092711219871875\n",
      "Epoch: 535, Train Loss: 0.013629207467258299, Valid Loss: 0.010918871090583445\n",
      "Epoch: 536, Train Loss: 0.013617921790745752, Valid Loss: 0.01091061616007608\n",
      "Epoch: 537, Train Loss: 0.013606611301588814, Valid Loss: 0.010902347500324311\n",
      "Epoch: 538, Train Loss: 0.01359527609169768, Valid Loss: 0.010894065205531695\n",
      "Epoch: 539, Train Loss: 0.013583916254448528, Valid Loss: 0.010885769370977212\n",
      "Epoch: 540, Train Loss: 0.013572531884685329, Valid Loss: 0.01087746009301458\n",
      "Epoch: 541, Train Loss: 0.013561123078721557, Valid Loss: 0.010869137469071496\n",
      "Epoch: 542, Train Loss: 0.013549689934341703, Valid Loss: 0.010860801597648679\n",
      "Epoch: 543, Train Loss: 0.013538232550802646, Valid Loss: 0.010852452578318858\n",
      "Epoch: 544, Train Loss: 0.013526751028834853, Valid Loss: 0.010844090511725565\n",
      "Epoch: 545, Train Loss: 0.013515245470643422, Valid Loss: 0.010835715499581821\n",
      "Epoch: 546, Train Loss: 0.013503715979908982, Valid Loss: 0.010827327644668679\n",
      "Epoch: 547, Train Loss: 0.013492162661788367, Valid Loss: 0.01081892705083364\n",
      "Epoch: 548, Train Loss: 0.0134805856229152, Valid Loss: 0.010810513822988919\n",
      "Epoch: 549, Train Loss: 0.013468984971400255, Valid Loss: 0.010802088067109585\n",
      "Epoch: 550, Train Loss: 0.013457360816831678, Valid Loss: 0.010793649890231556\n",
      "Epoch: 551, Train Loss: 0.013445713270274995, Valid Loss: 0.010785199400449466\n",
      "Epoch: 552, Train Loss: 0.01343404244427304, Valid Loss: 0.010776736706914349\n",
      "Epoch: 553, Train Loss: 0.013422348452845574, Valid Loss: 0.010768261919831266\n",
      "Epoch: 554, Train Loss: 0.01341063141148887, Valid Loss: 0.010759775150456697\n",
      "Epoch: 555, Train Loss: 0.01339889143717501, Valid Loss: 0.010751276511095866\n",
      "Epoch: 556, Train Loss: 0.01338712864835108, Valid Loss: 0.010742766115099866\n",
      "Epoch: 557, Train Loss: 0.01337534316493814, Valid Loss: 0.010734244076862692\n",
      "Epoch: 558, Train Loss: 0.01336353510833004, Valid Loss: 0.010725710511818082\n",
      "Epoch: 559, Train Loss: 0.013351704601392058, Valid Loss: 0.010717165536436262\n",
      "Epoch: 560, Train Loss: 0.013339851768459322, Valid Loss: 0.010708609268220494\n",
      "Epoch: 561, Train Loss: 0.013327976735335104, Valid Loss: 0.010700041825703532\n",
      "Epoch: 562, Train Loss: 0.013316079629288874, Valid Loss: 0.0106914633284439\n",
      "Epoch: 563, Train Loss: 0.013304160579054217, Valid Loss: 0.010682873897022022\n",
      "Epoch: 564, Train Loss: 0.01329221971482653, Valid Loss: 0.010674273653036212\n",
      "Epoch: 565, Train Loss: 0.013280257168260557, Valid Loss: 0.010665662719098546\n",
      "Epoch: 566, Train Loss: 0.013268273072467725, Valid Loss: 0.010657041218830534\n",
      "Epoch: 567, Train Loss: 0.013256267562013284, Valid Loss: 0.010648409276858688\n",
      "Epoch: 568, Train Loss: 0.01324424077291328, Valid Loss: 0.010639767018809925\n",
      "Epoch: 569, Train Loss: 0.013232192842631323, Valid Loss: 0.010631114571306798\n",
      "Epoch: 570, Train Loss: 0.01322012391007517, Valid Loss: 0.010622452061962656\n",
      "Epoch: 571, Train Loss: 0.013208034115593112, Valid Loss: 0.010613779619376562\n",
      "Epoch: 572, Train Loss: 0.01319592360097018, Valid Loss: 0.01060509737312812\n",
      "Epoch: 573, Train Loss: 0.013183792509424141, Valid Loss: 0.010596405453772141\n",
      "Epoch: 574, Train Loss: 0.013171640985601335, Valid Loss: 0.010587703992833169\n",
      "Epoch: 575, Train Loss: 0.013159469175572272, Valid Loss: 0.010578993122799826\n",
      "Epoch: 576, Train Loss: 0.013147277226827082, Valid Loss: 0.010570272977119056\n",
      "Epoch: 577, Train Loss: 0.013135065288270737, Valid Loss: 0.010561543690190175\n",
      "Epoch: 578, Train Loss: 0.013122833510218104, Valid Loss: 0.010552805397358825\n",
      "Epoch: 579, Train Loss: 0.01311058204438878, Valid Loss: 0.010544058234910727\n",
      "Epoch: 580, Train Loss: 0.013098311043901753, Valid Loss: 0.01053530234006531\n",
      "Epoch: 581, Train Loss: 0.01308602066326986, Valid Loss: 0.010526537850969202\n",
      "Epoch: 582, Train Loss: 0.013073711058394033, Valid Loss: 0.01051776490668957\n",
      "Epoch: 583, Train Loss: 0.013061382386557387, Valid Loss: 0.01050898364720728\n",
      "Epoch: 584, Train Loss: 0.01304903480641909, Valid Loss: 0.010500194213409968\n",
      "Epoch: 585, Train Loss: 0.013036668478008018, Valid Loss: 0.010491396747084927\n",
      "Epoch: 586, Train Loss: 0.013024283562716269, Valid Loss: 0.010482591390911842\n",
      "Epoch: 587, Train Loss: 0.013011880223292416, Valid Loss: 0.0104737782884554\n",
      "Epoch: 588, Train Loss: 0.012999458623834616, Valid Loss: 0.010464957584157756\n",
      "Epoch: 589, Train Loss: 0.01298701892978351, Valid Loss: 0.010456129423330844\n",
      "Epoch: 590, Train Loss: 0.012974561307914906, Valid Loss: 0.010447293952148542\n",
      "Epoch: 591, Train Loss: 0.012962085926332299, Valid Loss: 0.010438451317638701\n",
      "Epoch: 592, Train Loss: 0.01294959295445918, Valid Loss: 0.010429601667675032\n",
      "Epoch: 593, Train Loss: 0.012937082563031152, Valid Loss: 0.010420745150968838\n",
      "Epoch: 594, Train Loss: 0.012924554924087854, Valid Loss: 0.010411881917060639\n",
      "Epoch: 595, Train Loss: 0.0129120102109647, Valid Loss: 0.010403012116311595\n",
      "Epoch: 596, Train Loss: 0.012899448598284393, Valid Loss: 0.010394135899894873\n",
      "Epoch: 597, Train Loss: 0.012886870261948312, Valid Loss: 0.010385253419786779\n",
      "Epoch: 598, Train Loss: 0.012874275379127623, Valid Loss: 0.010376364828757844\n",
      "Epoch: 599, Train Loss: 0.012861664128254282, Valid Loss: 0.010367470280363706\n",
      "Epoch: 600, Train Loss: 0.012849036689011772, Valid Loss: 0.01035856992893589\n",
      "Epoch: 601, Train Loss: 0.012836393242325722, Valid Loss: 0.01034966392957243\n",
      "Epoch: 602, Train Loss: 0.012823733970354268, Valid Loss: 0.01034075243812839\n",
      "Epoch: 603, Train Loss: 0.012811059056478299, Valid Loss: 0.010331835611206219\n",
      "Epoch: 604, Train Loss: 0.012798368685291434, Valid Loss: 0.010322913606145985\n",
      "Epoch: 605, Train Loss: 0.012785663042589898, Valid Loss: 0.010313986581015478\n",
      "Epoch: 606, Train Loss: 0.012772942315362135, Valid Loss: 0.010305054694600187\n",
      "Epoch: 607, Train Loss: 0.012760206691778303, Valid Loss: 0.010296118106393155\n",
      "Epoch: 608, Train Loss: 0.012747456361179535, Valid Loss: 0.010287176976584676\n",
      "Epoch: 609, Train Loss: 0.012734691514067054, Valid Loss: 0.0102782314660519\n",
      "Epoch: 610, Train Loss: 0.012721912342091074, Valid Loss: 0.010269281736348305\n",
      "Epoch: 611, Train Loss: 0.012709119038039564, Valid Loss: 0.010260327949693024\n",
      "Epoch: 612, Train Loss: 0.012696311795826786, Valid Loss: 0.01025137026896007\n",
      "Epoch: 613, Train Loss: 0.012683490810481701, Valid Loss: 0.010242408857667444\n",
      "Epoch: 614, Train Loss: 0.01267065627813615, Valid Loss: 0.010233443879966112\n",
      "Epoch: 615, Train Loss: 0.012657808396012929, Valid Loss: 0.010224475500628868\n",
      "Epoch: 616, Train Loss: 0.01264494736241361, Valid Loss: 0.010215503885039069\n",
      "Epoch: 617, Train Loss: 0.012632073376706262, Valid Loss: 0.010206529199179274\n",
      "Epoch: 618, Train Loss: 0.012619186639312953, Valid Loss: 0.010197551609619776\n",
      "Epoch: 619, Train Loss: 0.012606287351697115, Valid Loss: 0.010188571283506977\n",
      "Epoch: 620, Train Loss: 0.012593375716350731, Valid Loss: 0.010179588388551713\n",
      "Epoch: 621, Train Loss: 0.012580451936781346, Valid Loss: 0.010170603093017427\n",
      "Epoch: 622, Train Loss: 0.012567516217498938, Valid Loss: 0.01016161556570825\n",
      "Epoch: 623, Train Loss: 0.012554568764002613, Valid Loss: 0.010152625975956979\n",
      "Epoch: 624, Train Loss: 0.012541609782767143, Valid Loss: 0.010143634493612956\n",
      "Epoch: 625, Train Loss: 0.01252863948122934, Valid Loss: 0.010134641289029824\n",
      "Epoch: 626, Train Loss: 0.0125156580677743, Valid Loss: 0.010125646533053222\n",
      "Epoch: 627, Train Loss: 0.012502665751721459, Valid Loss: 0.010116650397008336\n",
      "Epoch: 628, Train Loss: 0.012489662743310518, Valid Loss: 0.010107653052687382\n",
      "Epoch: 629, Train Loss: 0.012476649253687216, Valid Loss: 0.010098654672337013\n",
      "Epoch: 630, Train Loss: 0.012463625494888953, Valid Loss: 0.010089655428645575\n",
      "Epoch: 631, Train Loss: 0.012450591679830267, Valid Loss: 0.010080655494730348\n",
      "Epoch: 632, Train Loss: 0.012437548022288176, Valid Loss: 0.010071655044124623\n",
      "Epoch: 633, Train Loss: 0.012424494736887356, Valid Loss: 0.010062654250764767\n",
      "Epoch: 634, Train Loss: 0.012411432039085221, Valid Loss: 0.010053653288977138\n",
      "Epoch: 635, Train Loss: 0.012398360145156813, Valid Loss: 0.010044652333464967\n",
      "Epoch: 636, Train Loss: 0.012385279272179618, Valid Loss: 0.010035651559295143\n",
      "Epoch: 637, Train Loss: 0.012372189638018194, Valid Loss: 0.010026651141884897\n",
      "Epoch: 638, Train Loss: 0.01235909146130871, Valid Loss: 0.01001765125698847\n",
      "Epoch: 639, Train Loss: 0.012345984961443344, Valid Loss: 0.010008652080683623\n",
      "Epoch: 640, Train Loss: 0.012332870358554538, Valid Loss: 0.009999653789358175\n",
      "Epoch: 641, Train Loss: 0.012319747873499182, Valid Loss: 0.009990656559696382\n",
      "Epoch: 642, Train Loss: 0.012306617727842603, Valid Loss: 0.00998166056866531\n",
      "Epoch: 643, Train Loss: 0.012293480143842522, Valid Loss: 0.009972665993501112\n",
      "Epoch: 644, Train Loss: 0.012280335344432833, Valid Loss: 0.009963673011695262\n",
      "Epoch: 645, Train Loss: 0.012267183553207295, Valid Loss: 0.009954681800980714\n",
      "Epoch: 646, Train Loss: 0.012254024994403112, Valid Loss: 0.00994569253931801\n",
      "Epoch: 647, Train Loss: 0.012240859892884417, Valid Loss: 0.009936705404881346\n",
      "Epoch: 648, Train Loss: 0.012227688474125633, Valid Loss: 0.009927720576044557\n",
      "Epoch: 649, Train Loss: 0.01221451096419475, Valid Loss: 0.00991873823136708\n",
      "Epoch: 650, Train Loss: 0.012201327589736495, Valid Loss: 0.00990975854957985\n",
      "Epoch: 651, Train Loss: 0.012188138577955416, Valid Loss: 0.00990078170957117\n",
      "Epoch: 652, Train Loss: 0.012174944156598857, Valid Loss: 0.009891807890372506\n",
      "Epoch: 653, Train Loss: 0.012161744553939868, Valid Loss: 0.00988283727114428\n",
      "Epoch: 654, Train Loss: 0.012148539998760014, Valid Loss: 0.009873870031161603\n",
      "Epoch: 655, Train Loss: 0.01213533072033208, Valid Loss: 0.009864906349799961\n",
      "Epoch: 656, Train Loss: 0.012122116948402767, Valid Loss: 0.009855946406520906\n",
      "Epoch: 657, Train Loss: 0.0121088989131752, Valid Loss: 0.009846990380857679\n",
      "Epoch: 658, Train Loss: 0.01209567684529147, Valid Loss: 0.009838038452400819\n",
      "Epoch: 659, Train Loss: 0.01208245097581504, Valid Loss: 0.009829090800783754\n",
      "Epoch: 660, Train Loss: 0.012069221536213093, Valid Loss: 0.009820147605668352\n",
      "Epoch: 661, Train Loss: 0.012055988758338841, Valid Loss: 0.009811209046730473\n",
      "Epoch: 662, Train Loss: 0.012042752874413731, Valid Loss: 0.009802275303645478\n",
      "Epoch: 663, Train Loss: 0.01202951411700963, Valid Loss: 0.009793346556073744\n",
      "Epoch: 664, Train Loss: 0.012016272719030921, Valid Loss: 0.009784422983646157\n",
      "Epoch: 665, Train Loss: 0.012003028913696588, Valid Loss: 0.009775504765949588\n",
      "Epoch: 666, Train Loss: 0.01198978293452218, Valid Loss: 0.009766592082512368\n",
      "Epoch: 667, Train Loss: 0.011976535015301824, Valid Loss: 0.009757685112789778\n",
      "Epoch: 668, Train Loss: 0.01196328539009011, Valid Loss: 0.009748784036149483\n",
      "Epoch: 669, Train Loss: 0.011950034293183977, Valid Loss: 0.009739889031857027\n",
      "Epoch: 670, Train Loss: 0.01193678195910456, Valid Loss: 0.009731000279061286\n",
      "Epoch: 671, Train Loss: 0.011923528622578984, Valid Loss: 0.009722117956779944\n",
      "Epoch: 672, Train Loss: 0.011910274518522154, Valid Loss: 0.009713242243884986\n",
      "Epoch: 673, Train Loss: 0.01189701988201849, Valid Loss: 0.00970437331908817\n",
      "Epoch: 674, Train Loss: 0.011883764948303656, Valid Loss: 0.009695511360926546\n",
      "Epoch: 675, Train Loss: 0.011870509952746263, Valid Loss: 0.00968665654774797\n",
      "Epoch: 676, Train Loss: 0.011857255130829544, Valid Loss: 0.009677809057696638\n",
      "Epoch: 677, Train Loss: 0.011844000718133033, Valid Loss: 0.009668969068698645\n",
      "Epoch: 678, Train Loss: 0.01183074695031422, Valid Loss: 0.009660136758447563\n",
      "Epoch: 679, Train Loss: 0.011817494063090178, Valid Loss: 0.00965131230439005\n",
      "Epoch: 680, Train Loss: 0.011804242292219248, Valid Loss: 0.009642495883711475\n",
      "Epoch: 681, Train Loss: 0.011790991873482634, Valid Loss: 0.009633687673321583\n",
      "Epoch: 682, Train Loss: 0.011777743042666072, Valid Loss: 0.009624887849840188\n",
      "Epoch: 683, Train Loss: 0.011764496035541467, Valid Loss: 0.009616096589582913\n",
      "Epoch: 684, Train Loss: 0.011751251087848547, Valid Loss: 0.009607314068546943\n",
      "Epoch: 685, Train Loss: 0.011738008435276524, Valid Loss: 0.009598540462396847\n",
      "Epoch: 686, Train Loss: 0.011724768313445775, Valid Loss: 0.009589775946450416\n",
      "Epoch: 687, Train Loss: 0.011711530957889535, Valid Loss: 0.009581020695664565\n",
      "Epoch: 688, Train Loss: 0.011698296604035605, Valid Loss: 0.009572274884621276\n",
      "Epoch: 689, Train Loss: 0.011685065487188099, Valid Loss: 0.009563538687513591\n",
      "Epoch: 690, Train Loss: 0.011671837842509206, Valid Loss: 0.009554812278131656\n",
      "Epoch: 691, Train Loss: 0.011658613905000968, Valid Loss: 0.009546095829848817\n",
      "Epoch: 692, Train Loss: 0.011645393909487137, Valid Loss: 0.009537389515607772\n",
      "Epoch: 693, Train Loss: 0.011632178090594997, Valid Loss: 0.009528693507906812\n",
      "Epoch: 694, Train Loss: 0.011618966682737297, Valid Loss: 0.00952000797878607\n",
      "Epoch: 695, Train Loss: 0.011605759920094187, Valid Loss: 0.009511333099813874\n",
      "Epoch: 696, Train Loss: 0.011592558036595181, Valid Loss: 0.009502669042073154\n",
      "Epoch: 697, Train Loss: 0.011579361265901228, Valid Loss: 0.009494015976147923\n",
      "Epoch: 698, Train Loss: 0.011566169841386765, Valid Loss: 0.00948537407210981\n",
      "Epoch: 699, Train Loss: 0.011552983996121887, Valid Loss: 0.009476743499504696\n",
      "Epoch: 700, Train Loss: 0.011539803962854514, Valid Loss: 0.009468124427339401\n",
      "Epoch: 701, Train Loss: 0.011526629973992682, Valid Loss: 0.009459517024068456\n",
      "Epoch: 702, Train Loss: 0.011513462261586819, Valid Loss: 0.009450921457580955\n",
      "Epoch: 703, Train Loss: 0.01150030105731218, Valid Loss: 0.009442337895187496\n",
      "Epoch: 704, Train Loss: 0.011487146592451265, Valid Loss: 0.009433766503607189\n",
      "Epoch: 705, Train Loss: 0.011473999097876358, Valid Loss: 0.009425207448954765\n",
      "Epoch: 706, Train Loss: 0.011460858804032128, Valid Loss: 0.009416660896727764\n",
      "Epoch: 707, Train Loss: 0.011447725940918299, Valid Loss: 0.00940812701179382\n",
      "Epoch: 708, Train Loss: 0.011434600738072424, Valid Loss: 0.009399605958378033\n",
      "Epoch: 709, Train Loss: 0.011421483424552707, Valid Loss: 0.009391097900050431\n",
      "Epoch: 710, Train Loss: 0.011408374228920931, Valid Loss: 0.009382602999713545\n",
      "Epoch: 711, Train Loss: 0.011395273379225497, Valid Loss: 0.009374121419590063\n",
      "Epoch: 712, Train Loss: 0.011382181102984494, Valid Loss: 0.009365653321210584\n",
      "Epoch: 713, Train Loss: 0.011369097627168914, Valid Loss: 0.009357198865401503\n",
      "Epoch: 714, Train Loss: 0.01135602317818595, Valid Loss: 0.009348758212272946\n",
      "Epoch: 715, Train Loss: 0.01134295798186239, Valid Loss: 0.009340331521206868\n",
      "Epoch: 716, Train Loss: 0.011329902263428107, Valid Loss: 0.009331918950845217\n",
      "Epoch: 717, Train Loss: 0.011316856247499648, Valid Loss: 0.009323520659078228\n",
      "Epoch: 718, Train Loss: 0.011303820158063966, Valid Loss: 0.00931513680303282\n",
      "Epoch: 719, Train Loss: 0.011290794218462213, Valid Loss: 0.009306767539061105\n",
      "Epoch: 720, Train Loss: 0.01127777865137367, Valid Loss: 0.009298413022729005\n",
      "Epoch: 721, Train Loss: 0.011264773678799786, Valid Loss: 0.00929007340880501\n",
      "Epoch: 722, Train Loss: 0.011251779522048339, Valid Loss: 0.009281748851249015\n",
      "Epoch: 723, Train Loss: 0.011238796401717703, Valid Loss: 0.00927343950320131\n",
      "Epoch: 724, Train Loss: 0.01122582453768124, Valid Loss: 0.009265145516971671\n",
      "Epoch: 725, Train Loss: 0.011212864149071832, Valid Loss: 0.009256867044028574\n",
      "Epoch: 726, Train Loss: 0.011199915454266499, Valid Loss: 0.009248604234988533\n",
      "Epoch: 727, Train Loss: 0.011186978670871187, Valid Loss: 0.009240357239605581\n",
      "Epoch: 728, Train Loss: 0.011174054015705667, Valid Loss: 0.009232126206760847\n",
      "Epoch: 729, Train Loss: 0.011161141704788546, Valid Loss: 0.009223911284452282\n",
      "Epoch: 730, Train Loss: 0.011148241953322457, Valid Loss: 0.0092157126197845\n",
      "Epoch: 731, Train Loss: 0.011135354975679336, Valid Loss: 0.009207530358958757\n",
      "Epoch: 732, Train Loss: 0.011122480985385869, Valid Loss: 0.009199364647263073\n",
      "Epoch: 733, Train Loss: 0.01110962019510907, Valid Loss: 0.009191215629062449\n",
      "Epoch: 734, Train Loss: 0.011096772816641986, Valid Loss: 0.009183083447789264\n",
      "Epoch: 735, Train Loss: 0.011083939060889577, Valid Loss: 0.00917496824593377\n",
      "Epoch: 736, Train Loss: 0.011071119137854704, Valid Loss: 0.009166870165034747\n",
      "Epoch: 737, Train Loss: 0.011058313256624291, Valid Loss: 0.009158789345670283\n",
      "Epoch: 738, Train Loss: 0.011045521625355622, Valid Loss: 0.009150725927448698\n",
      "Epoch: 739, Train Loss: 0.011032744451262793, Valid Loss: 0.009142680048999584\n",
      "Epoch: 740, Train Loss: 0.011019981940603309, Valid Loss: 0.009134651847965032\n",
      "Epoch: 741, Train Loss: 0.011007234298664856, Valid Loss: 0.009126641460990964\n",
      "Epoch: 742, Train Loss: 0.010994501729752195, Valid Loss: 0.009118649023718605\n",
      "Epoch: 743, Train Loss: 0.010981784437174236, Valid Loss: 0.009110674670776123\n",
      "Epoch: 744, Train Loss: 0.010969082623231268, Valid Loss: 0.00910271853577038\n",
      "Epoch: 745, Train Loss: 0.010956396489202332, Valid Loss: 0.00909478075127887\n",
      "Epoch: 746, Train Loss: 0.01094372623533278, Valid Loss: 0.009086861448841748\n",
      "Epoch: 747, Train Loss: 0.010931072060821974, Valid Loss: 0.009078960758954058\n",
      "Epoch: 748, Train Loss: 0.010918434163811165, Valid Loss: 0.009071078811058076\n",
      "Epoch: 749, Train Loss: 0.010905812741371519, Valid Loss: 0.009063215733535806\n",
      "Epoch: 750, Train Loss: 0.010893207989492316, Valid Loss: 0.009055371653701624\n",
      "Epoch: 751, Train Loss: 0.010880620103069338, Valid Loss: 0.009047546697795067\n",
      "Epoch: 752, Train Loss: 0.010868049275893382, Valid Loss: 0.009039740990973792\n",
      "Epoch: 753, Train Loss: 0.01085549570063899, Valid Loss: 0.009031954657306657\n",
      "Epoch: 754, Train Loss: 0.010842959568853292, Valid Loss: 0.00902418781976695\n",
      "Epoch: 755, Train Loss: 0.010830441070945088, Valid Loss: 0.009016440600225821\n",
      "Epoch: 756, Train Loss: 0.010817940396174052, Valid Loss: 0.009008713119445769\n",
      "Epoch: 757, Train Loss: 0.010805457732640114, Valid Loss: 0.009001005497074383\n",
      "Epoch: 758, Train Loss: 0.010792993267273045, Valid Loss: 0.008993317851638158\n",
      "Epoch: 759, Train Loss: 0.010780547185822184, Valid Loss: 0.008985650300536514\n",
      "Epoch: 760, Train Loss: 0.010768119672846363, Valid Loss: 0.008978002960035916\n",
      "Epoch: 761, Train Loss: 0.010755710911704, Valid Loss: 0.008970375945264205\n",
      "Epoch: 762, Train Loss: 0.010743321084543359, Valid Loss: 0.008962769370205018\n",
      "Epoch: 763, Train Loss: 0.010730950372293005, Valid Loss: 0.00895518334769243\n",
      "Epoch: 764, Train Loss: 0.010718598954652422, Valid Loss: 0.008947617989405687\n",
      "Epoch: 765, Train Loss: 0.010706267010082836, Valid Loss: 0.008940073405864108\n",
      "Epoch: 766, Train Loss: 0.01069395471579817, Valid Loss: 0.008932549706422177\n",
      "Epoch: 767, Train Loss: 0.010681662247756222, Valid Loss: 0.00892504699926473\n",
      "Epoch: 768, Train Loss: 0.010669389780650016, Valid Loss: 0.008917565391402343\n",
      "Epoch: 769, Train Loss: 0.010657137487899307, Valid Loss: 0.008910104988666843\n",
      "Epoch: 770, Train Loss: 0.01064490554164229, Valid Loss: 0.008902665895706973\n",
      "Epoch: 771, Train Loss: 0.010632694112727497, Valid Loss: 0.00889524821598424\n",
      "Epoch: 772, Train Loss: 0.010620503370705846, Valid Loss: 0.008887852051768867\n",
      "Epoch: 773, Train Loss: 0.010608333483822903, Valid Loss: 0.008880477504135943\n",
      "Epoch: 774, Train Loss: 0.010596184619011302, Valid Loss: 0.008873124672961691\n",
      "Epoch: 775, Train Loss: 0.01058405694188336, Valid Loss: 0.008865793656919904\n",
      "Epoch: 776, Train Loss: 0.010571950616723872, Valid Loss: 0.008858484553478542\n",
      "Epoch: 777, Train Loss: 0.010559865806483083, Valid Loss: 0.008851197458896442\n",
      "Epoch: 778, Train Loss: 0.010547802672769849, Valid Loss: 0.008843932468220227\n",
      "Epoch: 779, Train Loss: 0.010535761375844966, Valid Loss: 0.00883668967528132\n",
      "Epoch: 780, Train Loss: 0.010523742074614713, Valid Loss: 0.008829469172693158\n",
      "Epoch: 781, Train Loss: 0.01051174492662453, Valid Loss: 0.008822271051848508\n",
      "Epoch: 782, Train Loss: 0.010499770088052923, Valid Loss: 0.00881509540291695\n",
      "Epoch: 783, Train Loss: 0.010487817713705513, Valid Loss: 0.008807942314842523\n",
      "Epoch: 784, Train Loss: 0.010475887957009296, Valid Loss: 0.008800811875341489\n",
      "Epoch: 785, Train Loss: 0.010463980970007078, Valid Loss: 0.00879370417090028\n",
      "Epoch: 786, Train Loss: 0.010452096903352054, Valid Loss: 0.008786619286773567\n",
      "Epoch: 787, Train Loss: 0.010440235906302636, Valid Loss: 0.008779557306982462\n",
      "Epoch: 788, Train Loss: 0.010428398126717397, Valid Loss: 0.008772518314312921\n",
      "Epoch: 789, Train Loss: 0.010416583711050231, Valid Loss: 0.008765502390314227\n",
      "Epoch: 790, Train Loss: 0.010404792804345678, Valid Loss: 0.008758509615297663\n",
      "Epoch: 791, Train Loss: 0.010393025550234435, Valid Loss: 0.008751540068335307\n",
      "Epoch: 792, Train Loss: 0.010381282090929039, Valid Loss: 0.00874459382725897\n",
      "Epoch: 793, Train Loss: 0.01036956256721973, Valid Loss: 0.008737670968659293\n",
      "Epoch: 794, Train Loss: 0.010357867118470499, Valid Loss: 0.008730771567884965\n",
      "Epoch: 795, Train Loss: 0.010346195882615296, Valid Loss: 0.008723895699042106\n",
      "Epoch: 796, Train Loss: 0.010334548996154432, Valid Loss: 0.008717043434993743\n",
      "Epoch: 797, Train Loss: 0.010322926594151136, Valid Loss: 0.00871021484735949\n",
      "Epoch: 798, Train Loss: 0.010311328810228308, Valid Loss: 0.008703410006515326\n",
      "Epoch: 799, Train Loss: 0.010299755776565441, Valid Loss: 0.008696628981593494\n",
      "Epoch: 800, Train Loss: 0.010288207623895698, Valid Loss: 0.008689871840482586\n",
      "Epoch: 801, Train Loss: 0.010276684481503182, Valid Loss: 0.008683138649827735\n",
      "Epoch: 802, Train Loss: 0.010265186477220372, Valid Loss: 0.008676429475030922\n",
      "Epoch: 803, Train Loss: 0.01025371373742572, Valid Loss: 0.008669744380251455\n",
      "Epoch: 804, Train Loss: 0.010242266387041439, Valid Loss: 0.008663083428406578\n",
      "Epoch: 805, Train Loss: 0.010230844549531437, Valid Loss: 0.008656446681172157\n",
      "Epoch: 806, Train Loss: 0.010219448346899427, Valid Loss: 0.008649834198983578\n",
      "Epoch: 807, Train Loss: 0.010208077899687217, Valid Loss: 0.008643246041036706\n",
      "Epoch: 808, Train Loss: 0.01019673332697314, Valid Loss: 0.008636682265289013\n",
      "Epoch: 809, Train Loss: 0.010185414746370684, Valid Loss: 0.008630142928460819\n",
      "Epoch: 810, Train Loss: 0.01017412227402725, Valid Loss: 0.008623628086036651\n",
      "Epoch: 811, Train Loss: 0.010162856024623088, Valid Loss: 0.008617137792266754\n",
      "Epoch: 812, Train Loss: 0.010151616111370413, Valid Loss: 0.00861067210016869\n",
      "Epoch: 813, Train Loss: 0.010140402646012655, Valid Loss: 0.008604231061529091\n",
      "Epoch: 814, Train Loss: 0.010129215738823869, Valid Loss: 0.00859781472690552\n",
      "Epoch: 815, Train Loss: 0.010118055498608334, Valid Loss: 0.008591423145628453\n",
      "Epoch: 816, Train Loss: 0.010106922032700279, Valid Loss: 0.008585056365803376\n",
      "Epoch: 817, Train Loss: 0.01009581544696377, Valid Loss: 0.008578714434313022\n",
      "Epoch: 818, Train Loss: 0.010084735845792774, Valid Loss: 0.008572397396819682\n",
      "Epoch: 819, Train Loss: 0.010073683332111337, Valid Loss: 0.008566105297767688\n",
      "Epoch: 820, Train Loss: 0.010062658007373963, Valid Loss: 0.008559838180385963\n",
      "Epoch: 821, Train Loss: 0.010051659971566105, Valid Loss: 0.00855359608669071\n",
      "Epoch: 822, Train Loss: 0.010040689323204817, Valid Loss: 0.008547379057488206\n",
      "Epoch: 823, Train Loss: 0.010029746159339574, Valid Loss: 0.008541187132377693\n",
      "Epoch: 824, Train Loss: 0.01001883057555321, Valid Loss: 0.008535020349754424\n",
      "Epoch: 825, Train Loss: 0.01000794266596303, Valid Loss: 0.008528878746812749\n",
      "Epoch: 826, Train Loss: 0.00999708252322203, Valid Loss: 0.008522762359549371\n",
      "Epoch: 827, Train Loss: 0.009986250238520315, Valid Loss: 0.008516671222766668\n",
      "Epoch: 828, Train Loss: 0.009975445901586598, Valid Loss: 0.008510605370076139\n",
      "Epoch: 829, Train Loss: 0.009964669600689886, Valid Loss: 0.008504564833901941\n",
      "Epoch: 830, Train Loss: 0.00995392142264129, Valid Loss: 0.00849854964548454\n",
      "Epoch: 831, Train Loss: 0.009943201452795956, Valid Loss: 0.008492559834884453\n",
      "Epoch: 832, Train Loss: 0.009932509775055174, Valid Loss: 0.008486595430986095\n",
      "Epoch: 833, Train Loss: 0.009921846471868563, Valid Loss: 0.00848065646150171\n",
      "Epoch: 834, Train Loss: 0.009911211624236459, Valid Loss: 0.008474742952975423\n",
      "Epoch: 835, Train Loss: 0.00990060531171236, Valid Loss: 0.00846885493078737\n",
      "Epoch: 836, Train Loss: 0.009890027612405582, Valid Loss: 0.008462992419157914\n",
      "Epoch: 837, Train Loss: 0.009879478602983964, Valid Loss: 0.00845715544115198\n",
      "Epoch: 838, Train Loss: 0.009868958358676764, Valid Loss: 0.008451344018683454\n",
      "Epoch: 839, Train Loss: 0.00985846695327765, Valid Loss: 0.008445558172519687\n",
      "Epoch: 840, Train Loss: 0.009848004459147817, Valid Loss: 0.008439797922286081\n",
      "Epoch: 841, Train Loss: 0.00983757094721924, Valid Loss: 0.008434063286470764\n",
      "Epoch: 842, Train Loss: 0.009827166486998036, Valid Loss: 0.008428354282429351\n",
      "Epoch: 843, Train Loss: 0.009816791146567945, Valid Loss: 0.00842267092638979\n",
      "Epoch: 844, Train Loss: 0.009806444992593954, Valid Loss: 0.008417013233457279\n",
      "Epoch: 845, Train Loss: 0.009796128090325998, Valid Loss: 0.008411381217619288\n",
      "Epoch: 846, Train Loss: 0.009785840503602811, Valid Loss: 0.00840577489175063\n",
      "Epoch: 847, Train Loss: 0.009775582294855869, Valid Loss: 0.008400194267618642\n",
      "Epoch: 848, Train Loss: 0.009765353525113466, Valid Loss: 0.008394639355888418\n",
      "Epoch: 849, Train Loss: 0.009755154254004873, Valid Loss: 0.008389110166128139\n",
      "Epoch: 850, Train Loss: 0.009744984539764634, Valid Loss: 0.008383606706814449\n",
      "Epoch: 851, Train Loss: 0.009734844439236947, Valid Loss: 0.008378128985337933\n",
      "Epoch: 852, Train Loss: 0.009724734007880168, Valid Loss: 0.008372677008008644\n",
      "Epoch: 853, Train Loss: 0.009714653299771414, Valid Loss: 0.008367250780061735\n",
      "Epoch: 854, Train Loss: 0.009704602367611266, Valid Loss: 0.008361850305663106\n",
      "Epoch: 855, Train Loss: 0.009694581262728564, Valid Loss: 0.008356475587915156\n",
      "Epoch: 856, Train Loss: 0.00968459003508532, Valid Loss: 0.00835112662886259\n",
      "Epoch: 857, Train Loss: 0.009674628733281733, Valid Loss: 0.00834580342949831\n",
      "Epoch: 858, Train Loss: 0.009664697404561272, Valid Loss: 0.008340505989769329\n",
      "Epoch: 859, Train Loss: 0.009654796094815864, Valid Loss: 0.008335234308582776\n",
      "Epoch: 860, Train Loss: 0.009644924848591205, Valid Loss: 0.008329988383811965\n",
      "Epoch: 861, Train Loss: 0.009635083709092124, Valid Loss: 0.008324768212302497\n",
      "Epoch: 862, Train Loss: 0.009625272718188051, Valid Loss: 0.008319573789878448\n",
      "Epoch: 863, Train Loss: 0.009615491916418582, Valid Loss: 0.008314405111348592\n",
      "Epoch: 864, Train Loss: 0.009605741342999114, Valid Loss: 0.008309262170512687\n",
      "Epoch: 865, Train Loss: 0.00959602103582659, Valid Loss: 0.00830414496016783\n",
      "Epoch: 866, Train Loss: 0.009586331031485292, Valid Loss: 0.008299053472114822\n",
      "Epoch: 867, Train Loss: 0.009576671365252752, Valid Loss: 0.008293987697164636\n",
      "Epoch: 868, Train Loss: 0.009567042071105722, Valid Loss: 0.008288947625144897\n",
      "Epoch: 869, Train Loss: 0.00955744318172623, Valid Loss: 0.008283933244906424\n",
      "Epoch: 870, Train Loss: 0.009547874728507712, Valid Loss: 0.008278944544329819\n",
      "Epoch: 871, Train Loss: 0.009538336741561217, Valid Loss: 0.00827398151033209\n",
      "Epoch: 872, Train Loss: 0.009528829249721699, Valid Loss: 0.008269044128873354\n",
      "Epoch: 873, Train Loss: 0.009519352280554354, Valid Loss: 0.008264132384963525\n",
      "Epoch: 874, Train Loss: 0.009509905860361068, Valid Loss: 0.008259246262669087\n",
      "Epoch: 875, Train Loss: 0.009500490014186895, Valid Loss: 0.008254385745119911\n",
      "Epoch: 876, Train Loss: 0.009491104765826626, Valid Loss: 0.008249550814516072\n",
      "Epoch: 877, Train Loss: 0.009481750137831419, Valid Loss: 0.008244741452134738\n",
      "Epoch: 878, Train Loss: 0.009472426151515502, Valid Loss: 0.008239957638337085\n",
      "Epoch: 879, Train Loss: 0.009463132826962912, Valid Loss: 0.00823519935257525\n",
      "Epoch: 880, Train Loss: 0.00945387018303434, Valid Loss: 0.008230466573399308\n",
      "Epoch: 881, Train Loss: 0.009444638237373982, Valid Loss: 0.008225759278464286\n",
      "Epoch: 882, Train Loss: 0.009435437006416511, Valid Loss: 0.00822107744453721\n",
      "Epoch: 883, Train Loss: 0.009426266505394042, Valid Loss: 0.008216421047504197\n",
      "Epoch: 884, Train Loss: 0.009417126748343213, Valid Loss: 0.00821179006237755\n",
      "Epoch: 885, Train Loss: 0.009408017748112266, Valid Loss: 0.00820718446330289\n",
      "Epoch: 886, Train Loss: 0.009398939516368226, Valid Loss: 0.008202604223566326\n",
      "Epoch: 887, Train Loss: 0.009389892063604103, Valid Loss: 0.008198049315601625\n",
      "Epoch: 888, Train Loss: 0.009380875399146152, Valid Loss: 0.008193519710997446\n",
      "Epoch: 889, Train Loss: 0.009371889531161194, Valid Loss: 0.008189015380504552\n",
      "Epoch: 890, Train Loss: 0.009362934466663959, Valid Loss: 0.008184536294043069\n",
      "Epoch: 891, Train Loss: 0.009354010211524485, Valid Loss: 0.008180082420709776\n",
      "Epoch: 892, Train Loss: 0.009345116770475585, Valid Loss: 0.008175653728785382\n",
      "Epoch: 893, Train Loss: 0.00933625414712032, Valid Loss: 0.008171250185741842\n",
      "Epoch: 894, Train Loss: 0.00932742234393953, Valid Loss: 0.008166871758249695\n",
      "Epoch: 895, Train Loss: 0.009318621362299414, Valid Loss: 0.008162518412185406\n",
      "Epoch: 896, Train Loss: 0.009309851202459123, Valid Loss: 0.008158190112638727\n",
      "Epoch: 897, Train Loss: 0.009301111863578427, Valid Loss: 0.008153886823920075\n",
      "Epoch: 898, Train Loss: 0.009292403343725381, Valid Loss: 0.008149608509567913\n",
      "Epoch: 899, Train Loss: 0.009283725639884043, Valid Loss: 0.008145355132356152\n",
      "Epoch: 900, Train Loss: 0.009275078747962235, Valid Loss: 0.008141126654301575\n",
      "Epoch: 901, Train Loss: 0.009266462662799317, Valid Loss: 0.008136923036671224\n",
      "Epoch: 902, Train Loss: 0.009257877378173988, Valid Loss: 0.008132744239989864\n",
      "Epoch: 903, Train Loss: 0.009249322886812156, Valid Loss: 0.0081285902240474\n",
      "Epoch: 904, Train Loss: 0.009240799180394775, Valid Loss: 0.008124460947906318\n",
      "Epoch: 905, Train Loss: 0.009232306249565758, Valid Loss: 0.008120356369909132\n",
      "Epoch: 906, Train Loss: 0.009223844083939904, Valid Loss: 0.00811627644768585\n",
      "Epoch: 907, Train Loss: 0.00921541267211082, Valid Loss: 0.008112221138161414\n",
      "Epoch: 908, Train Loss: 0.009207012001658915, Valid Loss: 0.00810819039756316\n",
      "Epoch: 909, Train Loss: 0.00919864205915937, Valid Loss: 0.008104184181428283\n",
      "Epoch: 910, Train Loss: 0.009190302830190157, Valid Loss: 0.008100202444611295\n",
      "Epoch: 911, Train Loss: 0.009181994299340067, Valid Loss: 0.008096245141291468\n",
      "Epoch: 912, Train Loss: 0.009173716450216751, Valid Loss: 0.00809231222498033\n",
      "Epoch: 913, Train Loss: 0.009165469265454789, Valid Loss: 0.008088403648529082\n",
      "Epoch: 914, Train Loss: 0.009157252726723769, Valid Loss: 0.00808451936413606\n",
      "Epoch: 915, Train Loss: 0.009149066814736378, Valid Loss: 0.008080659323354202\n",
      "Epoch: 916, Train Loss: 0.009140911509256501, Valid Loss: 0.008076823477098464\n",
      "Epoch: 917, Train Loss: 0.009132786789107358, Valid Loss: 0.008073011775653286\n",
      "Epoch: 918, Train Loss: 0.00912469263217961, Valid Loss: 0.008069224168679988\n",
      "Epoch: 919, Train Loss: 0.009116629015439514, Valid Loss: 0.008065460605224234\n",
      "Epoch: 920, Train Loss: 0.009108595914937071, Valid Loss: 0.008061721033723405\n",
      "Epoch: 921, Train Loss: 0.00910059330581417, Valid Loss: 0.008058005402014042\n",
      "Epoch: 922, Train Loss: 0.009092621162312754, Valid Loss: 0.00805431365733921\n",
      "Epoch: 923, Train Loss: 0.009084679457782997, Valid Loss: 0.008050645746355905\n",
      "Epoch: 924, Train Loss: 0.009076768164691459, Valid Loss: 0.008047001615142414\n",
      "Epoch: 925, Train Loss: 0.009068887254629277, Valid Loss: 0.008043381209205681\n",
      "Epoch: 926, Train Loss: 0.00906103669832032, Valid Loss: 0.00803978447348865\n",
      "Epoch: 927, Train Loss: 0.009053216465629392, Valid Loss: 0.008036211352377608\n",
      "Epoch: 928, Train Loss: 0.0090454265255704, Valid Loss: 0.008032661789709487\n",
      "Epoch: 929, Train Loss: 0.009037666846314523, Valid Loss: 0.008029135728779183\n",
      "Epoch: 930, Train Loss: 0.009029937395198402, Valid Loss: 0.008025633112346829\n",
      "Epoch: 931, Train Loss: 0.009022238138732307, Valid Loss: 0.008022153882645083\n",
      "Epoch: 932, Train Loss: 0.0090145690426083, Valid Loss: 0.008018697981386347\n",
      "Epoch: 933, Train Loss: 0.009006930071708415, Valid Loss: 0.008015265349770057\n",
      "Epoch: 934, Train Loss: 0.008999321190112805, Valid Loss: 0.008011855928489834\n",
      "Epoch: 935, Train Loss: 0.0089917423611079, Valid Loss: 0.008008469657740717\n",
      "Epoch: 936, Train Loss: 0.008984193547194553, Valid Loss: 0.00800510647722634\n",
      "Epoch: 937, Train Loss: 0.008976674710096175, Valid Loss: 0.008001766326166065\n",
      "Epoch: 938, Train Loss: 0.008969185810766866, Valid Loss: 0.00799844914330213\n",
      "Epoch: 939, Train Loss: 0.008961726809399526, Valid Loss: 0.007995154866906754\n",
      "Epoch: 940, Train Loss: 0.008954297665433986, Valid Loss: 0.007991883434789232\n",
      "Epoch: 941, Train Loss: 0.008946898337565066, Valid Loss: 0.007988634784302989\n",
      "Epoch: 942, Train Loss: 0.008939528783750691, Valid Loss: 0.00798540885235262\n",
      "Epoch: 943, Train Loss: 0.00893218896121995, Valid Loss: 0.007982205575400915\n",
      "Epoch: 944, Train Loss: 0.00892487882648115, Valid Loss: 0.007979024889475847\n",
      "Epoch: 945, Train Loss: 0.00891759833532985, Valid Loss: 0.007975866730177522\n",
      "Epoch: 946, Train Loss: 0.008910347442856908, Valid Loss: 0.00797273103268515\n",
      "Epoch: 947, Train Loss: 0.00890312610345647, Valid Loss: 0.007969617731763917\n",
      "Epoch: 948, Train Loss: 0.008895934270833973, Valid Loss: 0.0079665267617719\n",
      "Epoch: 949, Train Loss: 0.00888877189801411, Valid Loss: 0.007963458056666907\n",
      "Epoch: 950, Train Loss: 0.008881638937348795, Valid Loss: 0.007960411550013322\n",
      "Epoch: 951, Train Loss: 0.008874535340525088, Valid Loss: 0.007957387174988888\n",
      "Epoch: 952, Train Loss: 0.008867461058573127, Valid Loss: 0.007954384864391482\n",
      "Epoch: 953, Train Loss: 0.008860416041874009, Valid Loss: 0.007951404550645861\n",
      "Epoch: 954, Train Loss: 0.008853400240167666, Valid Loss: 0.007948446165810365\n",
      "Epoch: 955, Train Loss: 0.00884641360256072, Valid Loss: 0.007945509641583613\n",
      "Epoch: 956, Train Loss: 0.00883945607753431, Valid Loss: 0.007942594909311125\n",
      "Epoch: 957, Train Loss: 0.008832527612951903, Valid Loss: 0.00793970189999197\n",
      "Epoch: 958, Train Loss: 0.00882562815606707, Valid Loss: 0.007936830544285331\n",
      "Epoch: 959, Train Loss: 0.008818757653531241, Valid Loss: 0.007933980772517054\n",
      "Epoch: 960, Train Loss: 0.008811916051401442, Valid Loss: 0.007931152514686199\n",
      "Epoch: 961, Train Loss: 0.008805103295148003, Valid Loss: 0.007928345700471486\n",
      "Epoch: 962, Train Loss: 0.008798319329662225, Valid Loss: 0.007925560259237794\n",
      "Epoch: 963, Train Loss: 0.008791564099264052, Valid Loss: 0.007922796120042536\n",
      "Epoch: 964, Train Loss: 0.008784837547709678, Valid Loss: 0.007920053211642077\n",
      "Epoch: 965, Train Loss: 0.008778139618199156, Valid Loss: 0.00791733146249808\n",
      "Epoch: 966, Train Loss: 0.008771470253383958, Valid Loss: 0.00791463080078381\n",
      "Epoch: 967, Train Loss: 0.008764829395374525, Valid Loss: 0.007911951154390424\n",
      "Epoch: 968, Train Loss: 0.008758216985747767, Valid Loss: 0.007909292450933234\n",
      "Epoch: 969, Train Loss: 0.008751632965554548, Valid Loss: 0.007906654617757879\n",
      "Epoch: 970, Train Loss: 0.008745077275327133, Valid Loss: 0.007904037581946532\n",
      "Epoch: 971, Train Loss: 0.008738549855086606, Valid Loss: 0.00790144127032403\n",
      "Epoch: 972, Train Loss: 0.008732050644350264, Valid Loss: 0.007898865609463969\n",
      "Epoch: 973, Train Loss: 0.00872557958213895, Valid Loss: 0.007896310525694764\n",
      "Epoch: 974, Train Loss: 0.008719136606984411, Valid Loss: 0.0078937759451057\n",
      "Epoch: 975, Train Loss: 0.00871272165693655, Valid Loss: 0.00789126179355289\n",
      "Epoch: 976, Train Loss: 0.008706334669570706, Valid Loss: 0.00788876799666525\n",
      "Epoch: 977, Train Loss: 0.008699975581994864, Valid Loss: 0.007886294479850406\n",
      "Epoch: 978, Train Loss: 0.008693644330856851, Valid Loss: 0.007883841168300572\n",
      "Epoch: 979, Train Loss: 0.008687340852351491, Valid Loss: 0.007881407986998377\n",
      "Epoch: 980, Train Loss: 0.008681065082227714, Valid Loss: 0.007878994860722676\n",
      "Epoch: 981, Train Loss: 0.008674816955795644, Valid Loss: 0.007876601714054313\n",
      "Epoch: 982, Train Loss: 0.008668596407933658, Valid Loss: 0.007874228471381828\n",
      "Epoch: 983, Train Loss: 0.00866240337309537, Valid Loss: 0.007871875056907146\n",
      "Epoch: 984, Train Loss: 0.008656237785316644, Valid Loss: 0.007869541394651227\n",
      "Epoch: 985, Train Loss: 0.008650099578222506, Valid Loss: 0.007867227408459665\n",
      "Epoch: 986, Train Loss: 0.008643988685034052, Valid Loss: 0.007864933022008238\n",
      "Epoch: 987, Train Loss: 0.00863790503857532, Valid Loss: 0.007862658158808456\n",
      "Epoch: 988, Train Loss: 0.008631848571280113, Valid Loss: 0.007860402742213021\n",
      "Epoch: 989, Train Loss: 0.008625819215198782, Valid Loss: 0.007858166695421291\n",
      "Epoch: 990, Train Loss: 0.008619816902004994, Valid Loss: 0.007855949941484674\n",
      "Epoch: 991, Train Loss: 0.008613841563002426, Valid Loss: 0.007853752403311988\n",
      "Epoch: 992, Train Loss: 0.008607893129131452, Valid Loss: 0.007851574003674791\n",
      "Epoch: 993, Train Loss: 0.008601971530975775, Valid Loss: 0.007849414665212662\n",
      "Epoch: 994, Train Loss: 0.008596076698769023, Valid Loss: 0.007847274310438431\n",
      "Epoch: 995, Train Loss: 0.008590208562401303, Valid Loss: 0.007845152861743403\n",
      "Epoch: 996, Train Loss: 0.00858436705142573, Valid Loss: 0.007843050241402494\n",
      "Epoch: 997, Train Loss: 0.008578552095064886, Valid Loss: 0.007840966371579368\n",
      "Epoch: 998, Train Loss: 0.008572763622217273, Valid Loss: 0.0078389011743315\n",
      "Epoch: 999, Train Loss: 0.008567001561463698, Valid Loss: 0.007836854571615226\n",
      "Epoch: 1000, Train Loss: 0.008561265841073647, Valid Loss: 0.007834826485290727\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the neural network\n",
    "model = NN()\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "y_valid = np.reshape(y_valid, (-1, 1))\n",
    "model.train(x_train, y_train, x_valid, y_valid, 1000, 0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.001, Train Loss: 0.017792320488531164, Valid Loss: 0.01463251627809808\n",
      "Learning Rate 0.001008863243070352, Train Loss: 0.01668798968202267, Valid Loss: 0.013877221502054225\n",
      "Learning Rate 0.0010178050432184285, Train Loss: 0.015539926319371426, Valid Loss: 0.012514560367622524\n",
      "Learning Rate 0.0010268260967147027, Train Loss: 0.017205347084217074, Valid Loss: 0.013898850071705096\n",
      "Learning Rate 0.001035927106000866, Train Loss: 0.014345417261981625, Valid Loss: 0.01173747754410343\n",
      "Learning Rate 0.0010451087797445182, Train Loss: 0.017050456642656687, Valid Loss: 0.013697804334593755\n",
      "Learning Rate 0.001054371832894353, Train Loss: 0.014939362624476935, Valid Loss: 0.012106760751184406\n",
      "Learning Rate 0.0010637169867358273, Train Loss: 0.015488421345781189, Valid Loss: 0.012737780264120766\n",
      "Learning Rate 0.0010731449689473295, Train Loss: 0.015313436026400397, Valid Loss: 0.012658302104073706\n",
      "Learning Rate 0.0010826565136568351, Train Loss: 0.017592494877762658, Valid Loss: 0.014430900678216146\n",
      "Learning Rate 0.0010922523614990758, Train Loss: 0.017633966004106046, Valid Loss: 0.01420631126683357\n",
      "Learning Rate 0.001101933259673207, Train Loss: 0.01766023275468415, Valid Loss: 0.014172577586115396\n",
      "Learning Rate 0.0011116999620009963, Train Loss: 0.01659338288245175, Valid Loss: 0.013668812541178474\n",
      "Learning Rate 0.0011215532289855124, Train Loss: 0.017284121852737814, Valid Loss: 0.01365055057030508\n",
      "Learning Rate 0.0011314938278703492, Train Loss: 0.016934373363445932, Valid Loss: 0.013846023147627737\n",
      "Learning Rate 0.0011415225326993662, Train Loss: 0.016451053339636573, Valid Loss: 0.01313826513370711\n",
      "Learning Rate 0.0011516401243769647, Train Loss: 0.017765879005446312, Valid Loss: 0.014002879032456108\n",
      "Learning Rate 0.0011618473907288884, Train Loss: 0.016771019165645926, Valid Loss: 0.013703496610346514\n",
      "Learning Rate 0.0011721451265635729, Train Loss: 0.017495866418168155, Valid Loss: 0.014202968670065083\n",
      "Learning Rate 0.0011825341337340335, Train Loss: 0.016239665570911308, Valid Loss: 0.013365304686279897\n",
      "Learning Rate 0.0011930152212003065, Train Loss: 0.01740616170050234, Valid Loss: 0.014188667552965615\n",
      "Learning Rate 0.0012035892050924347, Train Loss: 0.016333796106652126, Valid Loss: 0.013305998769910987\n",
      "Learning Rate 0.0012142569087740208, Train Loss: 0.01715543825914624, Valid Loss: 0.013595512187045022\n",
      "Learning Rate 0.0012250191629063383, Train Loss: 0.01579388403528208, Valid Loss: 0.012990785120491863\n",
      "Learning Rate 0.0012358768055130164, Train Loss: 0.017610643536566006, Valid Loss: 0.014208092102138553\n",
      "Learning Rate 0.0012468306820452887, Train Loss: 0.019522062889049493, Valid Loss: 0.015604894196858196\n",
      "Learning Rate 0.001257881645447829, Train Loss: 0.015700827817221315, Valid Loss: 0.012918866242362213\n",
      "Learning Rate 0.0012690305562251664, Train Loss: 0.015467880033194376, Valid Loss: 0.012861235199366508\n",
      "Learning Rate 0.0012802782825086943, Train Loss: 0.015696929253505132, Valid Loss: 0.012550363821552113\n",
      "Learning Rate 0.0012916257001242618, Train Loss: 0.01675653184922039, Valid Loss: 0.01341043075462497\n",
      "Learning Rate 0.0013030736926603768, Train Loss: 0.01749652090411172, Valid Loss: 0.01432167497501805\n",
      "Learning Rate 0.0013146231515370071, Train Loss: 0.018136358896406836, Valid Loss: 0.014691797440437004\n",
      "Learning Rate 0.0013262749760749907, Train Loss: 0.019713302754268004, Valid Loss: 0.01626698881560341\n",
      "Learning Rate 0.0013380300735660689, Train Loss: 0.015710495966690465, Valid Loss: 0.012854466395277589\n",
      "Learning Rate 0.0013498893593435262, Train Loss: 0.0161359442847151, Valid Loss: 0.012959751149295512\n",
      "Learning Rate 0.0013618537568534698, Train Loss: 0.016046492918204366, Valid Loss: 0.013035059474228852\n",
      "Learning Rate 0.0013739241977267329, Train Loss: 0.016294159722251168, Valid Loss: 0.012964319847648542\n",
      "Learning Rate 0.0013861016218514235, Train Loss: 0.014898062007328045, Valid Loss: 0.01196239300888593\n",
      "Learning Rate 0.001398386977446102, Train Loss: 0.01542944070521011, Valid Loss: 0.012175232662304983\n",
      "Learning Rate 0.0014107812211336219, Train Loss: 0.015998387160156797, Valid Loss: 0.012613683895312422\n",
      "Learning Rate 0.001423285318015616, Train Loss: 0.019349749014836843, Valid Loss: 0.015909165661952687\n",
      "Learning Rate 0.001435900241747652, Train Loss: 0.01685295646981546, Valid Loss: 0.013346922612272766\n",
      "Learning Rate 0.0014486269746150388, Train Loss: 0.017594505797938587, Valid Loss: 0.014476696349248704\n",
      "Learning Rate 0.0014614665076093207, Train Loss: 0.01656147047524552, Valid Loss: 0.013295641892110903\n",
      "Learning Rate 0.0014744198405054394, Train Loss: 0.015022473853129168, Valid Loss: 0.012165425575944322\n",
      "Learning Rate 0.001487487981939589, Train Loss: 0.01631987581810344, Valid Loss: 0.013078543517371019\n",
      "Learning Rate 0.0015006719494877472, Train Loss: 0.01818165672874329, Valid Loss: 0.014434022180331523\n",
      "Learning Rate 0.0015139727697449164, Train Loss: 0.0168308910132033, Valid Loss: 0.013551888405308812\n",
      "Learning Rate 0.0015273914784050583, Train Loss: 0.016258999693506873, Valid Loss: 0.01296174873858178\n",
      "Learning Rate 0.001540929120341747, Train Loss: 0.017344028682372118, Valid Loss: 0.013634724494592429\n",
      "Learning Rate 0.0015545867496895196, Train Loss: 0.015380974563377251, Valid Loss: 0.012793807483422607\n",
      "Learning Rate 0.0015683654299259665, Train Loss: 0.015341495495586466, Valid Loss: 0.012398538756499275\n",
      "Learning Rate 0.0015822662339545362, Train Loss: 0.015191606089573664, Valid Loss: 0.012284154973657887\n",
      "Learning Rate 0.001596290244188086, Train Loss: 0.017348512470320935, Valid Loss: 0.013695082864665892\n",
      "Learning Rate 0.0016104385526331567, Train Loss: 0.016469314478481867, Valid Loss: 0.013166460339133032\n",
      "Learning Rate 0.0016247122609750106, Train Loss: 0.017141494449235982, Valid Loss: 0.013644929319546249\n",
      "Learning Rate 0.001639112480663412, Train Loss: 0.01630948798466698, Valid Loss: 0.01298559657753034\n",
      "Learning Rate 0.0016536403329991795, Train Loss: 0.015797600852453252, Valid Loss: 0.012689268598037755\n",
      "Learning Rate 0.0016682969492214895, Train Loss: 0.015156129580990814, Valid Loss: 0.012571684609296786\n",
      "Learning Rate 0.0016830834705959664, Train Loss: 0.015983200105829463, Valid Loss: 0.012842877443849052\n",
      "Learning Rate 0.0016980010485035503, Train Loss: 0.017339387518442863, Valid Loss: 0.013930619266002689\n",
      "Learning Rate 0.0017130508445301485, Train Loss: 0.017790443236057985, Valid Loss: 0.014098139726270558\n",
      "Learning Rate 0.0017282340305570913, Train Loss: 0.016931751814288448, Valid Loss: 0.013777618992728972\n",
      "Learning Rate 0.0017435517888523733, Train Loss: 0.01669265290434589, Valid Loss: 0.013761245808387598\n",
      "Learning Rate 0.0017590053121627192, Train Loss: 0.016595067785673417, Valid Loss: 0.013069476246121592\n",
      "Learning Rate 0.0017745958038064562, Train Loss: 0.01544907311818896, Valid Loss: 0.012220277074143642\n",
      "Learning Rate 0.0017903244777672197, Train Loss: 0.016563952157822144, Valid Loss: 0.013642095155972913\n",
      "Learning Rate 0.001806192558788472, Train Loss: 0.017590420064350774, Valid Loss: 0.014314480225826258\n",
      "Learning Rate 0.0018222012824688754, Train Loss: 0.016267380576369117, Valid Loss: 0.012983384761294167\n",
      "Learning Rate 0.0018383518953585026, Train Loss: 0.016354614596695377, Valid Loss: 0.0128864373106305\n",
      "Learning Rate 0.0018546456550559078, Train Loss: 0.01598182516218132, Valid Loss: 0.012708853922288649\n",
      "Learning Rate 0.0018710838303060407, Train Loss: 0.01691494633602095, Valid Loss: 0.013767934514128425\n",
      "Learning Rate 0.0018876677010990488, Train Loss: 0.01687326873628346, Valid Loss: 0.013714804878711462\n",
      "Learning Rate 0.0019043985587699405, Train Loss: 0.015029474744875981, Valid Loss: 0.012154302672587864\n",
      "Learning Rate 0.001921277706099147, Train Loss: 0.01769701735540552, Valid Loss: 0.01428339815710399\n",
      "Learning Rate 0.0019383064574139523, Train Loss: 0.016192802421358923, Valid Loss: 0.013331237394525916\n",
      "Learning Rate 0.0019554861386908455, Train Loss: 0.01646111526953355, Valid Loss: 0.013325962561741221\n",
      "Learning Rate 0.0019728180876587647, Train Loss: 0.017077713745618162, Valid Loss: 0.013451816792216026\n",
      "Learning Rate 0.0019903036539032715, Train Loss: 0.01772143488433404, Valid Loss: 0.014592922459535244\n",
      "Learning Rate 0.0020079441989716263, Train Loss: 0.016627346532462162, Valid Loss: 0.013567138862776629\n",
      "Learning Rate 0.0020257410964788156, Train Loss: 0.017536717193502378, Valid Loss: 0.01409364985027286\n",
      "Learning Rate 0.002043695732214509, Train Loss: 0.017425547005352066, Valid Loss: 0.013830310044894134\n",
      "Learning Rate 0.002061809504250965, Train Loss: 0.01777946344462634, Valid Loss: 0.014003654806061855\n",
      "Learning Rate 0.002080083823051904, Train Loss: 0.01662045168956923, Valid Loss: 0.012989523371269176\n",
      "Learning Rate 0.00209852011158232, Train Loss: 0.015544077116038446, Valid Loss: 0.012768651351926981\n",
      "Learning Rate 0.002117119805419295, Train Loss: 0.015207733008083868, Valid Loss: 0.012208261516057152\n",
      "Learning Rate 0.0021358843528637827, Train Loss: 0.015460505386593007, Valid Loss: 0.012676326934784094\n",
      "Learning Rate 0.002154815215053376, Train Loss: 0.016291179674848732, Valid Loss: 0.012994186991801404\n",
      "Learning Rate 0.0021739138660760876, Train Loss: 0.01685881544103562, Valid Loss: 0.013944510825245235\n",
      "Learning Rate 0.002193181793085129, Train Loss: 0.01599211426484264, Valid Loss: 0.012786116592276473\n",
      "Learning Rate 0.0022126204964147108, Train Loss: 0.016288372247813935, Valid Loss: 0.01290682191887721\n",
      "Learning Rate 0.002232231489696878, Train Loss: 0.015954360575530402, Valid Loss: 0.012722134526287386\n",
      "Learning Rate 0.0022520162999793555, Train Loss: 0.01695471343225059, Valid Loss: 0.013606312281377647\n",
      "Learning Rate 0.002271976467844468, Train Loss: 0.014764850283923827, Valid Loss: 0.011912845808984442\n",
      "Learning Rate 0.002292113547529091, Train Loss: 0.0169043406571635, Valid Loss: 0.013371623938789089\n",
      "Learning Rate 0.0023124291070456887, Train Loss: 0.016549038846367378, Valid Loss: 0.01341616059795859\n",
      "Learning Rate 0.0023329247283043917, Train Loss: 0.014153110642271273, Valid Loss: 0.011908326856345637\n",
      "Learning Rate 0.002353602007236189, Train Loss: 0.014995672272600923, Valid Loss: 0.012305272707477258\n",
      "Learning Rate 0.00237446255391719, Train Loss: 0.016267668312904476, Valid Loss: 0.013246778469790535\n",
      "Learning Rate 0.0023955079926940067, Train Loss: 0.01677110538496965, Valid Loss: 0.013420162600719108\n",
      "Learning Rate 0.002416739962310225, Train Loss: 0.015495902481281206, Valid Loss: 0.012365612991886066\n",
      "Learning Rate 0.0024381601160340144, Train Loss: 0.016567355892052122, Valid Loss: 0.013015763675623506\n",
      "Learning Rate 0.0024597701217868597, Train Loss: 0.0170398291394961, Valid Loss: 0.0135656599880238\n",
      "Learning Rate 0.0024815716622734463, Train Loss: 0.0172990440745425, Valid Loss: 0.014024037255633308\n",
      "Learning Rate 0.002503566435112674, Train Loss: 0.017816086969905703, Valid Loss: 0.014135943028984013\n",
      "Learning Rate 0.002525756152969852, Train Loss: 0.013393401854630699, Valid Loss: 0.010940688768122667\n",
      "Learning Rate 0.002548142543690059, Train Loss: 0.017293303493277474, Valid Loss: 0.013983277019196142\n",
      "Learning Rate 0.0025707273504326895, Train Loss: 0.01606347762511193, Valid Loss: 0.013091225926606267\n",
      "Learning Rate 0.002593512331807177, Train Loss: 0.018429773011003295, Valid Loss: 0.014943738820782265\n",
      "Learning Rate 0.0026164992620099398, Train Loss: 0.014836856418563187, Valid Loss: 0.012426421864956965\n",
      "Learning Rate 0.0026396899309625308, Train Loss: 0.015259229917804354, Valid Loss: 0.012426839512702107\n",
      "Learning Rate 0.00266308614445101, Train Loss: 0.018017053563462466, Valid Loss: 0.014571296813995086\n",
      "Learning Rate 0.0026866897242665663, Train Loss: 0.017081154594230184, Valid Loss: 0.013706513702693851\n",
      "Learning Rate 0.0027105025083473586, Train Loss: 0.015955156365795656, Valid Loss: 0.013064205589695557\n",
      "Learning Rate 0.0027345263509216374, Train Loss: 0.017067525958819194, Valid Loss: 0.013900671239615811\n",
      "Learning Rate 0.0027587631226521393, Train Loss: 0.01605461062656785, Valid Loss: 0.012541737885065315\n",
      "Learning Rate 0.002783214710781729, Train Loss: 0.015196960392723566, Valid Loss: 0.012231164779938658\n",
      "Learning Rate 0.0028078830192803674, Train Loss: 0.015092061639239837, Valid Loss: 0.012328510434048603\n",
      "Learning Rate 0.0028327699689933636, Train Loss: 0.015809738783703526, Valid Loss: 0.013140161920690063\n",
      "Learning Rate 0.0028578774977909426, Train Loss: 0.017063256835665116, Valid Loss: 0.01375823109195331\n",
      "Learning Rate 0.0028832075607191534, Train Loss: 0.01724647197574337, Valid Loss: 0.013989143339192572\n",
      "Learning Rate 0.0029087621301520845, Train Loss: 0.016939931771239407, Valid Loss: 0.013779700715883927\n",
      "Learning Rate 0.0029345431959454577, Train Loss: 0.015593622952827749, Valid Loss: 0.012681620102167656\n",
      "Learning Rate 0.0029605527655915675, Train Loss: 0.015095493520067449, Valid Loss: 0.012320979605593108\n",
      "Learning Rate 0.002986792864375609, Train Loss: 0.015527636449199323, Valid Loss: 0.012622314450615022\n",
      "Learning Rate 0.0030132655355333635, Train Loss: 0.016281947332547755, Valid Loss: 0.01308468264188082\n",
      "Learning Rate 0.0030399728404103105, Train Loss: 0.016471819593650617, Valid Loss: 0.013072283908190235\n",
      "Learning Rate 0.003066916858622133, Train Loss: 0.015888761647137487, Valid Loss: 0.012955609042654434\n",
      "Learning Rate 0.0030940996882166615, Train Loss: 0.01441183523831747, Valid Loss: 0.011744754830787046\n",
      "Learning Rate 0.0031215234458372267, Train Loss: 0.01657766767615727, Valid Loss: 0.013232445968327532\n",
      "Learning Rate 0.0031491902668874853, Train Loss: 0.015231230642480586, Valid Loss: 0.012152392531367268\n",
      "Learning Rate 0.0031771023056976965, Train Loss: 0.015940048187745807, Valid Loss: 0.012700067924497396\n",
      "Learning Rate 0.003205261735692468, Train Loss: 0.015976745330791072, Valid Loss: 0.012521328422788074\n",
      "Learning Rate 0.0032336707495600092, Train Loss: 0.014691130951045761, Valid Loss: 0.011929473008389686\n",
      "Learning Rate 0.0032623315594228477, Train Loss: 0.015340287233349683, Valid Loss: 0.012061329059628721\n",
      "Learning Rate 0.00329124639701009, Train Loss: 0.017482259275513935, Valid Loss: 0.014029477039728627\n",
      "Learning Rate 0.003320417513831211, Train Loss: 0.015496878004341954, Valid Loss: 0.01241474128136303\n",
      "Learning Rate 0.0033498471813513515, Train Loss: 0.0146949008284001, Valid Loss: 0.01175074613649856\n",
      "Learning Rate 0.0033795376911682027, Train Loss: 0.014960615953919468, Valid Loss: 0.012221966779061628\n",
      "Learning Rate 0.003409491355190443, Train Loss: 0.016529206229579152, Valid Loss: 0.013331382586713502\n",
      "Learning Rate 0.003439710505817757, Train Loss: 0.01564242014573815, Valid Loss: 0.01272489922335413\n",
      "Learning Rate 0.003470197496122464, Train Loss: 0.015572069926450391, Valid Loss: 0.01264653786144534\n",
      "Learning Rate 0.0035009547000327246, Train Loss: 0.0163937538623036, Valid Loss: 0.01291927967837495\n",
      "Learning Rate 0.003531984512517403, Train Loss: 0.01616104877435731, Valid Loss: 0.0129346417130926\n",
      "Learning Rate 0.003563289349772564, Train Loss: 0.016931202474056665, Valid Loss: 0.013746860034382103\n",
      "Learning Rate 0.0035948716494095955, Train Loss: 0.014228054599316363, Valid Loss: 0.011528356925638047\n",
      "Learning Rate 0.0036267338706450305, Train Loss: 0.012070508225918403, Valid Loss: 0.00990938803506966\n",
      "Learning Rate 0.0036588784944920363, Train Loss: 0.013698455243116671, Valid Loss: 0.011123916981511441\n",
      "Learning Rate 0.0036913080239536, Train Loss: 0.017446090217146236, Valid Loss: 0.014025409179660782\n",
      "Learning Rate 0.0037240249842174417, Train Loss: 0.015574884260125472, Valid Loss: 0.012626117190960184\n",
      "Learning Rate 0.0037570319228526256, Train Loss: 0.015701296958029336, Valid Loss: 0.012501540872336556\n",
      "Learning Rate 0.003790331410007937, Train Loss: 0.01649998966598897, Valid Loss: 0.013203827153197201\n",
      "Learning Rate 0.0038239260386120277, Train Loss: 0.016071371325129268, Valid Loss: 0.012948402947439505\n",
      "Learning Rate 0.0038578184245752953, Train Loss: 0.013885123319508962, Valid Loss: 0.01107463859012016\n",
      "Learning Rate 0.0038920112069935893, Train Loss: 0.01661770593396385, Valid Loss: 0.013469112926222668\n",
      "Learning Rate 0.003926507048353708, Train Loss: 0.015253380560427132, Valid Loss: 0.01231242318009189\n",
      "Learning Rate 0.003961308634740714, Train Loss: 0.01528496876333109, Valid Loss: 0.012414119928906514\n",
      "Learning Rate 0.003996418676047105, Train Loss: 0.01600704694603051, Valid Loss: 0.012785086524813444\n",
      "Learning Rate 0.0040318399061838065, Train Loss: 0.015744293088855294, Valid Loss: 0.012808795669343126\n",
      "Learning Rate 0.0040675750832930594, Train Loss: 0.01566049034686372, Valid Loss: 0.012658324627866176\n",
      "Learning Rate 0.004103626989963194, Train Loss: 0.016040587529633197, Valid Loss: 0.012908862059326455\n",
      "Learning Rate 0.004139998433445291, Train Loss: 0.01520843162492426, Valid Loss: 0.012463579114933726\n",
      "Learning Rate 0.0041766922458717935, Train Loss: 0.017266057514645102, Valid Loss: 0.01409224457420481\n",
      "Learning Rate 0.00421371128447701, Train Loss: 0.014310422298783487, Valid Loss: 0.011859471674277373\n",
      "Learning Rate 0.004251058431819612, Train Loss: 0.016346805820841238, Valid Loss: 0.01316908372197064\n",
      "Learning Rate 0.004288736596007099, Train Loss: 0.015390750969123165, Valid Loss: 0.012417298626479174\n",
      "Learning Rate 0.004326748710922225, Train Loss: 0.017821717088821118, Valid Loss: 0.014286557885993964\n",
      "Learning Rate 0.004365097736451461, Train Loss: 0.013537989709372353, Valid Loss: 0.011055193210716449\n",
      "Learning Rate 0.004403786658715474, Train Loss: 0.017247613796921333, Valid Loss: 0.013953022005392715\n",
      "Learning Rate 0.004442818490301639, Train Loss: 0.018434846801730426, Valid Loss: 0.014700918419985665\n",
      "Learning Rate 0.004482196270498637, Train Loss: 0.01698093296959759, Valid Loss: 0.013760806804754978\n",
      "Learning Rate 0.004521923065533093, Train Loss: 0.01570986274876124, Valid Loss: 0.012907348344068167\n",
      "Learning Rate 0.00456200196880834, Train Loss: 0.016947429490780503, Valid Loss: 0.013510237187419656\n",
      "Learning Rate 0.004602436101145313, Train Loss: 0.01509366847552207, Valid Loss: 0.011995492762936238\n",
      "Learning Rate 0.004643228611025528, Train Loss: 0.01713209061346008, Valid Loss: 0.014103788416362556\n",
      "Learning Rate 0.0046843826748362615, Train Loss: 0.015472955193329774, Valid Loss: 0.012679703780153392\n",
      "Learning Rate 0.004725901497117882, Train Loss: 0.016955852101918734, Valid Loss: 0.013624715296444953\n",
      "Learning Rate 0.0047677883108133735, Train Loss: 0.01523935324087653, Valid Loss: 0.012138170593835236\n",
      "Learning Rate 0.004810046377520096, Train Loss: 0.012859003013395988, Valid Loss: 0.011095778133673156\n",
      "Learning Rate 0.004852678987743724, Train Loss: 0.016500760704046564, Valid Loss: 0.013223287366413136\n",
      "Learning Rate 0.004895689461154482, Train Loss: 0.01714747009103846, Valid Loss: 0.013954851973017582\n",
      "Learning Rate 0.004939081146845655, Train Loss: 0.011964579855569998, Valid Loss: 0.01015705343424564\n",
      "Learning Rate 0.004982857423594342, Train Loss: 0.016850362167048917, Valid Loss: 0.013649275518956708\n",
      "Learning Rate 0.005027021700124567, Train Loss: 0.014760231291777066, Valid Loss: 0.012235586332617622\n",
      "Learning Rate 0.005071577415372707, Train Loss: 0.016453967291050888, Valid Loss: 0.013388135172181981\n",
      "Learning Rate 0.005116528038755258, Train Loss: 0.014967756840745201, Valid Loss: 0.011975154395829997\n",
      "Learning Rate 0.005161877070439018, Train Loss: 0.015228250849293877, Valid Loss: 0.012422788355934208\n",
      "Learning Rate 0.005207628041613597, Train Loss: 0.017225470034601, Valid Loss: 0.01396126500191107\n",
      "Learning Rate 0.0052537845147664, Train Loss: 0.014916941799320196, Valid Loss: 0.011987984721862572\n",
      "Learning Rate 0.005300350083960027, Train Loss: 0.015603551103063948, Valid Loss: 0.01252039524021567\n",
      "Learning Rate 0.00534732837511212, Train Loss: 0.014828625125793823, Valid Loss: 0.011981606108665313\n",
      "Learning Rate 0.0053947230462777305, Train Loss: 0.017260559290193104, Valid Loss: 0.014261092539966005\n",
      "Learning Rate 0.005442537787934121, Train Loss: 0.015063019490854986, Valid Loss: 0.012327146264434118\n",
      "Learning Rate 0.005490776323268152, Train Loss: 0.015234849735236084, Valid Loss: 0.012158174052119879\n",
      "Learning Rate 0.005539442408466213, Train Loss: 0.01592586303817099, Valid Loss: 0.012645531396570228\n",
      "Learning Rate 0.005588539833006665, Train Loss: 0.017372237354986646, Valid Loss: 0.014112925957792942\n",
      "Learning Rate 0.0056380724199549485, Train Loss: 0.016446150269289823, Valid Loss: 0.013210629763161034\n",
      "Learning Rate 0.005688044026261258, Train Loss: 0.016863098823390977, Valid Loss: 0.013389495416520491\n",
      "Learning Rate 0.00573845854306087, Train Loss: 0.015481971659918325, Valid Loss: 0.012475756993451022\n",
      "Learning Rate 0.005789319895977157, Train Loss: 0.014690549057519165, Valid Loss: 0.0116485592711715\n",
      "Learning Rate 0.005840632045427229, Train Loss: 0.016237135497737455, Valid Loss: 0.012726646751924538\n",
      "Learning Rate 0.005892398986930333, Train Loss: 0.01579999554404711, Valid Loss: 0.013123742683750777\n",
      "Learning Rate 0.005944624751418993, Train Loss: 0.01266047757725817, Valid Loss: 0.01019532358910675\n",
      "Learning Rate 0.0059973134055528515, Train Loss: 0.01672514383784159, Valid Loss: 0.013536483096965044\n",
      "Learning Rate 0.0060504690520353475, Train Loss: 0.01622590693795059, Valid Loss: 0.013195365333742687\n",
      "Learning Rate 0.006104095829933181, Train Loss: 0.01709095805455421, Valid Loss: 0.013711670418782322\n",
      "Learning Rate 0.006158197914998595, Train Loss: 0.016547096960910748, Valid Loss: 0.013022006207193201\n",
      "Learning Rate 0.006212779519994564, Train Loss: 0.01749743726785603, Valid Loss: 0.014020323219059974\n",
      "Learning Rate 0.006267844895022781, Train Loss: 0.01740698925360851, Valid Loss: 0.014138521421242166\n",
      "Learning Rate 0.006323398327854627, Train Loss: 0.015739790458429076, Valid Loss: 0.013197590142969931\n",
      "Learning Rate 0.0063794441442650614, Train Loss: 0.017028129061755895, Valid Loss: 0.013947508009088465\n",
      "Learning Rate 0.006435986708369417, Train Loss: 0.01678275676302385, Valid Loss: 0.0136254427936911\n",
      "Learning Rate 0.0064930304229632516, Train Loss: 0.013385577458836208, Valid Loss: 0.010951586650472904\n",
      "Learning Rate 0.0065505797298651665, Train Loss: 0.015168837952623018, Valid Loss: 0.012184795341893586\n",
      "Learning Rate 0.006608639110262676, Train Loss: 0.011891067167615912, Valid Loss: 0.009954672534333865\n",
      "Learning Rate 0.00666721308506117, Train Loss: 0.016406223899048597, Valid Loss: 0.013198840507323978\n",
      "Learning Rate 0.0067263062152359, Train Loss: 0.013861720590856408, Valid Loss: 0.011420737283592655\n",
      "Learning Rate 0.0067859231021871564, Train Loss: 0.012244707587005, Valid Loss: 0.009950563597827622\n",
      "Learning Rate 0.006846068388098559, Train Loss: 0.015029743873546586, Valid Loss: 0.012169194478181822\n",
      "Learning Rate 0.006906746756298524, Train Loss: 0.011741497141296374, Valid Loss: 0.009727095915231682\n",
      "Learning Rate 0.006967962931624964, Train Loss: 0.01203694997661404, Valid Loss: 0.010219864143484627\n",
      "Learning Rate 0.00702972168079316, Train Loss: 0.015643522809836857, Valid Loss: 0.012809788180155277\n",
      "Learning Rate 0.0070920278127669465, Train Loss: 0.015833182688724304, Valid Loss: 0.012697402595120576\n",
      "Learning Rate 0.007154886179133198, Train Loss: 0.011873924487941348, Valid Loss: 0.009933970716272373\n",
      "Learning Rate 0.007218301674479559, Train Loss: 0.014869830549818048, Valid Loss: 0.012230589841532741\n",
      "Learning Rate 0.007282279236775602, Train Loss: 0.01169812631564405, Valid Loss: 0.009928602742619525\n",
      "Learning Rate 0.007346823847757322, Train Loss: 0.016895577837195266, Valid Loss: 0.013571943892178738\n",
      "Learning Rate 0.007411940533315048, Train Loss: 0.01629940004043814, Valid Loss: 0.01332087298299303\n",
      "Learning Rate 0.007477634363884815, Train Loss: 0.014932217500580552, Valid Loss: 0.012488207288361123\n",
      "Learning Rate 0.007543910454843144, Train Loss: 0.013712831139425175, Valid Loss: 0.010929680988362653\n",
      "Learning Rate 0.007610773966905382, Train Loss: 0.016149079487030416, Valid Loss: 0.012686671392184212\n",
      "Learning Rate 0.007678230106527573, Train Loss: 0.016077324684963347, Valid Loss: 0.012668360398354887\n",
      "Learning Rate 0.007746284126311823, Train Loss: 0.015452040832642072, Valid Loss: 0.012915300969642452\n",
      "Learning Rate 0.007814941325415334, Train Loss: 0.011526577359772035, Valid Loss: 0.00946013747023777\n",
      "Learning Rate 0.007884207049963031, Train Loss: 0.014987062570211651, Valid Loss: 0.011974210519573286\n",
      "Learning Rate 0.007954086693463829, Train Loss: 0.014442630960945344, Valid Loss: 0.011715055220235896\n",
      "Learning Rate 0.008024585697230652, Train Loss: 0.01126566762523351, Valid Loss: 0.009312941885326291\n",
      "Learning Rate 0.008095709550804079, Train Loss: 0.016039301973008225, Valid Loss: 0.01288987040768861\n",
      "Learning Rate 0.00816746379237982, Train Loss: 0.01479697859592848, Valid Loss: 0.012208829929254197\n",
      "Learning Rate 0.008239854009239982, Train Loss: 0.015830164201116024, Valid Loss: 0.012705947047231733\n",
      "Learning Rate 0.008312885838188093, Train Loss: 0.015966815926766725, Valid Loss: 0.012785764710423657\n",
      "Learning Rate 0.00838656496598804, Train Loss: 0.01655199662280096, Valid Loss: 0.013492802244771313\n",
      "Learning Rate 0.008460897129806893, Train Loss: 0.01353853795600563, Valid Loss: 0.011707242714380194\n",
      "Learning Rate 0.008535888117661608, Train Loss: 0.014469237619893346, Valid Loss: 0.011572353260915644\n",
      "Learning Rate 0.008611543768869773, Train Loss: 0.01727463350222057, Valid Loss: 0.013839215242553861\n",
      "Learning Rate 0.008687869974504242, Train Loss: 0.010543312661125752, Valid Loss: 0.009180833300256493\n",
      "Learning Rate 0.008764872677851887, Train Loss: 0.015793866495335544, Valid Loss: 0.01283569408179234\n",
      "Learning Rate 0.008842557874876377, Train Loss: 0.01717191565657332, Valid Loss: 0.013937307820859883\n",
      "Learning Rate 0.008920931614685055, Train Loss: 0.012586976308598355, Valid Loss: 0.010247389592721\n",
      "Learning Rate 0.008999999999999998, Train Loss: 0.013870845366858446, Valid Loss: 0.011003096142789257\n",
      "0.008687869974504242\n"
     ]
    }
   ],
   "source": [
    "rate = findRate(x_train, y_train, x_valid, y_valid, 200)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.09354924063681025, Valid Loss: 0.1001742597392295\n",
      "Epoch: 2, Train Loss: 0.08593001496068087, Valid Loss: 0.09021094012450469\n",
      "Epoch: 3, Train Loss: 0.07712704102070123, Valid Loss: 0.07897611998714975\n",
      "Epoch: 4, Train Loss: 0.06729682856742292, Valid Loss: 0.06692218593058759\n",
      "Epoch: 5, Train Loss: 0.056893132190411144, Valid Loss: 0.05487305413780876\n",
      "Epoch: 6, Train Loss: 0.046692961932697064, Valid Loss: 0.04386175000856485\n",
      "Epoch: 7, Train Loss: 0.03762314987398868, Valid Loss: 0.03475010321972694\n",
      "Epoch: 8, Train Loss: 0.030399924561513192, Valid Loss: 0.027886902416436567\n",
      "Epoch: 9, Train Loss: 0.025236603060539552, Valid Loss: 0.02308823115035481\n",
      "Epoch: 10, Train Loss: 0.021868641491924145, Valid Loss: 0.01988973653339321\n",
      "Epoch: 11, Train Loss: 0.019814859614578795, Valid Loss: 0.017805324793847277\n",
      "Epoch: 12, Train Loss: 0.018615698710197956, Valid Loss: 0.016451503364182572\n",
      "Epoch: 13, Train Loss: 0.017932189203363574, Valid Loss: 0.015564274287589339\n",
      "Epoch: 14, Train Loss: 0.017546217602737006, Valid Loss: 0.014973577470572689\n",
      "Epoch: 15, Train Loss: 0.01732761297286481, Valid Loss: 0.014572842563925678\n",
      "Epoch: 16, Train Loss: 0.017201839110820957, Valid Loss: 0.014295626362110507\n",
      "Epoch: 17, Train Loss: 0.017127167216618704, Valid Loss: 0.014100175706853629\n",
      "Epoch: 18, Train Loss: 0.01708051728077234, Valid Loss: 0.01395985262818343\n",
      "Epoch: 19, Train Loss: 0.017049206104889858, Valid Loss: 0.013857342149985054\n",
      "Epoch: 20, Train Loss: 0.017026287542198554, Valid Loss: 0.013781165478490906\n",
      "Epoch: 21, Train Loss: 0.017007964100388802, Valid Loss: 0.013723566719985624\n",
      "Epoch: 22, Train Loss: 0.016992161456132335, Valid Loss: 0.013679214063128992\n",
      "Epoch: 23, Train Loss: 0.016977746931883735, Valid Loss: 0.013644386748536385\n",
      "Epoch: 24, Train Loss: 0.016964102026540223, Valid Loss: 0.013616455486128429\n",
      "Epoch: 25, Train Loss: 0.016950888885868678, Valid Loss: 0.013593543223484212\n",
      "Epoch: 26, Train Loss: 0.01693792280385746, Valid Loss: 0.013574299017868227\n",
      "Epoch: 27, Train Loss: 0.01692510263636877, Valid Loss: 0.013557744391816779\n",
      "Epoch: 28, Train Loss: 0.016912372829445896, Valid Loss: 0.013543167163544936\n",
      "Epoch: 29, Train Loss: 0.016899702701568247, Valid Loss: 0.013530047024761826\n",
      "Epoch: 30, Train Loss: 0.01688707514090198, Valid Loss: 0.013518002753707787\n",
      "Epoch: 31, Train Loss: 0.01687448043949925, Valid Loss: 0.013506754417571017\n",
      "Epoch: 32, Train Loss: 0.016861912930039243, Valid Loss: 0.013496096105477452\n",
      "Epoch: 33, Train Loss: 0.016849369151411938, Valid Loss: 0.013485876144407058\n",
      "Epoch: 34, Train Loss: 0.016836846848245806, Valid Loss: 0.01347598268108544\n",
      "Epoch: 35, Train Loss: 0.01682434442529025, Valid Loss: 0.013466333139381052\n",
      "Epoch: 36, Train Loss: 0.0168118606498653, Valid Loss: 0.01345686649221109\n",
      "Epoch: 37, Train Loss: 0.01679939448958896, Valid Loss: 0.013447537586036049\n",
      "Epoch: 38, Train Loss: 0.016786945023868235, Valid Loss: 0.013438312967038407\n",
      "Epoch: 39, Train Loss: 0.016774511395608278, Valid Loss: 0.013429167808551343\n",
      "Epoch: 40, Train Loss: 0.01676209278484772, Valid Loss: 0.013420083647507117\n",
      "Epoch: 41, Train Loss: 0.016749688394347123, Valid Loss: 0.013411046715995805\n",
      "Epoch: 42, Train Loss: 0.016737297441693322, Valid Loss: 0.013402046711001649\n",
      "Epoch: 43, Train Loss: 0.016724919154955876, Valid Loss: 0.013393075886992187\n",
      "Epoch: 44, Train Loss: 0.016712552770280026, Valid Loss: 0.01338412838650707\n",
      "Epoch: 45, Train Loss: 0.016700197530535737, Valid Loss: 0.013375199746257485\n",
      "Epoch: 46, Train Loss: 0.016687852684542915, Valid Loss: 0.013366286532686823\n",
      "Epoch: 47, Train Loss: 0.01667551748661141, Valid Loss: 0.013357386073041664\n",
      "Epoch: 48, Train Loss: 0.016663191196253216, Valid Loss: 0.013348496256914158\n",
      "Epoch: 49, Train Loss: 0.01665087307798935, Valid Loss: 0.013339615389784586\n",
      "Epoch: 50, Train Loss: 0.016638562401208996, Valid Loss: 0.013330742084936191\n",
      "Epoch: 51, Train Loss: 0.016626258440057936, Valid Loss: 0.013321875183686412\n",
      "Epoch: 52, Train Loss: 0.01661396047334368, Valid Loss: 0.013313013696514048\n",
      "Epoch: 53, Train Loss: 0.016601667784450422, Valid Loss: 0.013304156759606394\n",
      "Epoch: 54, Train Loss: 0.016589379661260086, Valid Loss: 0.0132953036027852\n",
      "Epoch: 55, Train Loss: 0.016577095396077473, Valid Loss: 0.013286453525829434\n",
      "Epoch: 56, Train Loss: 0.016564814285558286, Valid Loss: 0.01327760588099399\n",
      "Epoch: 57, Train Loss: 0.016552535630639482, Valid Loss: 0.01326876006010049\n",
      "Epoch: 58, Train Loss: 0.01654025873647159, Valid Loss: 0.013259915485001753\n",
      "Epoch: 59, Train Loss: 0.01652798291235281, Valid Loss: 0.013251071600535685\n",
      "Epoch: 60, Train Loss: 0.01651570747166475, Valid Loss: 0.013242227869316106\n",
      "Epoch: 61, Train Loss: 0.016503431731809747, Valid Loss: 0.013233383767879076\n",
      "Epoch: 62, Train Loss: 0.01649115501414974, Valid Loss: 0.01322453878382953\n",
      "Epoch: 63, Train Loss: 0.01647887664394664, Valid Loss: 0.013215692413726082\n",
      "Epoch: 64, Train Loss: 0.01646659595030422, Valid Loss: 0.013206844161510781\n",
      "Epoch: 65, Train Loss: 0.016454312266111437, Valid Loss: 0.013197993537340975\n",
      "Epoch: 66, Train Loss: 0.0164420249279872, Valid Loss: 0.013189140056718248\n",
      "Epoch: 67, Train Loss: 0.016429733276226634, Valid Loss: 0.01318028323983663\n",
      "Epoch: 68, Train Loss: 0.016417436654748697, Valid Loss: 0.013171422611092928\n",
      "Epoch: 69, Train Loss: 0.016405134411045266, Valid Loss: 0.01316255769871684\n",
      "Epoch: 70, Train Loss: 0.016392825896131592, Valid Loss: 0.01315368803448979\n",
      "Epoch: 71, Train Loss: 0.016380510464498167, Valid Loss: 0.013144813153529368\n",
      "Epoch: 72, Train Loss: 0.016368187474063947, Valid Loss: 0.013135932594122518\n",
      "Epoch: 73, Train Loss: 0.01635585628613095, Valid Loss: 0.013127045897594938\n",
      "Epoch: 74, Train Loss: 0.016343516265340242, Valid Loss: 0.013118152608207414\n",
      "Epoch: 75, Train Loss: 0.016331166779629234, Valid Loss: 0.013109252273072363\n",
      "Epoch: 76, Train Loss: 0.016318807200190348, Valid Loss: 0.013100344442085516\n",
      "Epoch: 77, Train Loss: 0.016306436901430993, Valid Loss: 0.013091428667868986\n",
      "Epoch: 78, Train Loss: 0.016294055260934887, Valid Loss: 0.013082504505723127\n",
      "Epoch: 79, Train Loss: 0.016281661659424684, Valid Loss: 0.013073571513584998\n",
      "Epoch: 80, Train Loss: 0.016269255480725928, Valid Loss: 0.01306462925199208\n",
      "Epoch: 81, Train Loss: 0.01625683611173227, Valid Loss: 0.013055677284050054\n",
      "Epoch: 82, Train Loss: 0.01624440294237203, Valid Loss: 0.013046715175403895\n",
      "Epoch: 83, Train Loss: 0.016231955365576027, Valid Loss: 0.013037742494211633\n",
      "Epoch: 84, Train Loss: 0.016219492777246672, Valid Loss: 0.013028758811120325\n",
      "Epoch: 85, Train Loss: 0.01620701457622839, Valid Loss: 0.013019763699244027\n",
      "Epoch: 86, Train Loss: 0.016194520164279268, Valid Loss: 0.013010756734143333\n",
      "Epoch: 87, Train Loss: 0.016182008946043984, Valid Loss: 0.013001737493806467\n",
      "Epoch: 88, Train Loss: 0.016169480329028034, Valid Loss: 0.01299270555863174\n",
      "Epoch: 89, Train Loss: 0.016156933723573158, Valid Loss: 0.012983660511411204\n",
      "Epoch: 90, Train Loss: 0.016144368542834072, Valid Loss: 0.012974601937315531\n",
      "Epoch: 91, Train Loss: 0.01613178420275645, Valid Loss: 0.012965529423880046\n",
      "Epoch: 92, Train Loss: 0.0161191801220561, Valid Loss: 0.012956442560991764\n",
      "Epoch: 93, Train Loss: 0.016106555722199448, Valid Loss: 0.012947340940877553\n",
      "Epoch: 94, Train Loss: 0.016093910427385245, Valid Loss: 0.012938224158093323\n",
      "Epoch: 95, Train Loss: 0.01608124366452749, Valid Loss: 0.012929091809514168\n",
      "Epoch: 96, Train Loss: 0.016068554863239642, Valid Loss: 0.012919943494325578\n",
      "Epoch: 97, Train Loss: 0.01605584345581999, Valid Loss: 0.012910778814015611\n",
      "Epoch: 98, Train Loss: 0.016043108877238338, Valid Loss: 0.012901597372368014\n",
      "Epoch: 99, Train Loss: 0.016030350565123874, Valid Loss: 0.012892398775456379\n",
      "Epoch: 100, Train Loss: 0.01601756795975427, Valid Loss: 0.012883182631639232\n",
      "Epoch: 101, Train Loss: 0.01600476050404603, Valid Loss: 0.01287394855155606\n",
      "Epoch: 102, Train Loss: 0.01599192764354607, Valid Loss: 0.012864696148124369\n",
      "Epoch: 103, Train Loss: 0.015979068826424473, Valid Loss: 0.012855425036537643\n",
      "Epoch: 104, Train Loss: 0.015966183503468543, Valid Loss: 0.012846134834264266\n",
      "Epoch: 105, Train Loss: 0.015953271128078046, Valid Loss: 0.012836825161047427\n",
      "Epoch: 106, Train Loss: 0.015940331156261662, Valid Loss: 0.01282749563890595\n",
      "Epoch: 107, Train Loss: 0.015927363046634706, Valid Loss: 0.012818145892136085\n",
      "Epoch: 108, Train Loss: 0.01591436626041802, Valid Loss: 0.012808775547314253\n",
      "Epoch: 109, Train Loss: 0.01590134026143815, Valid Loss: 0.01279938423330073\n",
      "Epoch: 110, Train Loss: 0.015888284516128687, Valid Loss: 0.012789971581244291\n",
      "Epoch: 111, Train Loss: 0.0158751984935329, Valid Loss: 0.012780537224587794\n",
      "Epoch: 112, Train Loss: 0.015862081665307524, Valid Loss: 0.012771080799074713\n",
      "Epoch: 113, Train Loss: 0.01584893350572783, Valid Loss: 0.012761601942756615\n",
      "Epoch: 114, Train Loss: 0.015835753491693912, Valid Loss: 0.012752100296001587\n",
      "Epoch: 115, Train Loss: 0.01582254110273817, Valid Loss: 0.012742575501503615\n",
      "Epoch: 116, Train Loss: 0.01580929582103407, Valid Loss: 0.012733027204292887\n",
      "Epoch: 117, Train Loss: 0.015796017131406093, Valid Loss: 0.012723455051747068\n",
      "Epoch: 118, Train Loss: 0.015782704521340948, Valid Loss: 0.012713858693603494\n",
      "Epoch: 119, Train Loss: 0.01576935748099999, Valid Loss: 0.012704237781972327\n",
      "Epoch: 120, Train Loss: 0.0157559755032329, Valid Loss: 0.012694591971350658\n",
      "Epoch: 121, Train Loss: 0.015742558083592564, Valid Loss: 0.012684920918637528\n",
      "Epoch: 122, Train Loss: 0.015729104720351206, Valid Loss: 0.012675224283149926\n",
      "Epoch: 123, Train Loss: 0.015715614914517805, Valid Loss: 0.012665501726639697\n",
      "Epoch: 124, Train Loss: 0.015702088169856635, Valid Loss: 0.012655752913311441\n",
      "Epoch: 125, Train Loss: 0.015688523992907173, Valid Loss: 0.012645977509841288\n",
      "Epoch: 126, Train Loss: 0.01567492189300515, Valid Loss: 0.01263617518539665\n",
      "Epoch: 127, Train Loss: 0.01566128138230491, Valid Loss: 0.012626345611656953\n",
      "Epoch: 128, Train Loss: 0.01564760197580296, Valid Loss: 0.012616488462835236\n",
      "Epoch: 129, Train Loss: 0.015633883191362805, Valid Loss: 0.012606603415700727\n",
      "Epoch: 130, Train Loss: 0.015620124549741002, Valid Loss: 0.01259669014960238\n",
      "Epoch: 131, Train Loss: 0.015606325574614466, Valid Loss: 0.012586748346493301\n",
      "Epoch: 132, Train Loss: 0.015592485792609032, Valid Loss: 0.012576777690956156\n",
      "Epoch: 133, Train Loss: 0.015578604733329249, Valid Loss: 0.012566777870229494\n",
      "Epoch: 134, Train Loss: 0.015564681929389432, Valid Loss: 0.012556748574235005\n",
      "Epoch: 135, Train Loss: 0.015550716916445953, Valid Loss: 0.012546689495605714\n",
      "Epoch: 136, Train Loss: 0.015536709233230797, Valid Loss: 0.012536600329715125\n",
      "Epoch: 137, Train Loss: 0.015522658421586344, Valid Loss: 0.012526480774707268\n",
      "Epoch: 138, Train Loss: 0.01550856402650142, Valid Loss: 0.012516330531527694\n",
      "Epoch: 139, Train Loss: 0.015494425596148586, Valid Loss: 0.012506149303955391\n",
      "Epoch: 140, Train Loss: 0.015480242681922675, Valid Loss: 0.012495936798635629\n",
      "Epoch: 141, Train Loss: 0.015466014838480572, Valid Loss: 0.012485692725113717\n",
      "Epoch: 142, Train Loss: 0.015451741623782269, Valid Loss: 0.012475416795869712\n",
      "Epoch: 143, Train Loss: 0.015437422599133119, Valid Loss: 0.012465108726353985\n",
      "Epoch: 144, Train Loss: 0.015423057329227371, Valid Loss: 0.012454768235023778\n",
      "Epoch: 145, Train Loss: 0.015408645382192936, Valid Loss: 0.012444395043380607\n",
      "Epoch: 146, Train Loss: 0.015394186329637405, Valid Loss: 0.012433988876008615\n",
      "Epoch: 147, Train Loss: 0.01537967974669527, Valid Loss: 0.01242354946061381\n",
      "Epoch: 148, Train Loss: 0.015365125212076442, Valid Loss: 0.012413076528064192\n",
      "Epoch: 149, Train Loss: 0.015350522308115941, Valid Loss: 0.012402569812430814\n",
      "Epoch: 150, Train Loss: 0.015335870620824865, Valid Loss: 0.012392029051029695\n",
      "Epoch: 151, Train Loss: 0.015321169739942554, Valid Loss: 0.012381453984464654\n",
      "Epoch: 152, Train Loss: 0.015306419258990005, Valid Loss: 0.012370844356670971\n",
      "Epoch: 153, Train Loss: 0.015291618775324483, Valid Loss: 0.012360199914959997\n",
      "Epoch: 154, Train Loss: 0.01527676789019537, Valid Loss: 0.012349520410064568\n",
      "Epoch: 155, Train Loss: 0.015261866208801206, Valid Loss: 0.012338805596185332\n",
      "Epoch: 156, Train Loss: 0.015246913340347945, Valid Loss: 0.012328055231037882\n",
      "Epoch: 157, Train Loss: 0.015231908898108404, Valid Loss: 0.012317269075900791\n",
      "Epoch: 158, Train Loss: 0.015216852499482932, Valid Loss: 0.012306446895664456\n",
      "Epoch: 159, Train Loss: 0.01520174376606122, Valid Loss: 0.012295588458880768\n",
      "Epoch: 160, Train Loss: 0.015186582323685327, Valid Loss: 0.012284693537813654\n",
      "Epoch: 161, Train Loss: 0.01517136780251388, Valid Loss: 0.012273761908490388\n",
      "Epoch: 162, Train Loss: 0.015156099837087392, Valid Loss: 0.012262793350753717\n",
      "Epoch: 163, Train Loss: 0.015140778066394805, Valid Loss: 0.012251787648314832\n",
      "Epoch: 164, Train Loss: 0.01512540213394112, Valid Loss: 0.012240744588807057\n",
      "Epoch: 165, Train Loss: 0.015109971687816212, Valid Loss: 0.012229663963840365\n",
      "Epoch: 166, Train Loss: 0.015094486380764707, Valid Loss: 0.012218545569056641\n",
      "Epoch: 167, Train Loss: 0.015078945870257038, Valid Loss: 0.012207389204185721\n",
      "Epoch: 168, Train Loss: 0.015063349818561597, Valid Loss: 0.012196194673102121\n",
      "Epoch: 169, Train Loss: 0.01504769789281791, Valid Loss: 0.012184961783882592\n",
      "Epoch: 170, Train Loss: 0.015031989765110993, Valid Loss: 0.012173690348864277\n",
      "Epoch: 171, Train Loss: 0.015016225112546688, Valid Loss: 0.012162380184703649\n",
      "Epoch: 172, Train Loss: 0.015000403617328094, Valid Loss: 0.012151031112436128\n",
      "Epoch: 173, Train Loss: 0.014984524966833022, Valid Loss: 0.012139642957536353\n",
      "Epoch: 174, Train Loss: 0.014968588853692467, Valid Loss: 0.012128215549979109\n",
      "Epoch: 175, Train Loss: 0.014952594975870091, Valid Loss: 0.01211674872430093\n",
      "Epoch: 176, Train Loss: 0.014936543036742682, Valid Loss: 0.012105242319662297\n",
      "Epoch: 177, Train Loss: 0.0149204327451816, Valid Loss: 0.01209369617991045\n",
      "Epoch: 178, Train Loss: 0.014904263815635142, Valid Loss: 0.012082110153642805\n",
      "Epoch: 179, Train Loss: 0.014888035968211881, Valid Loss: 0.01207048409427093\n",
      "Epoch: 180, Train Loss: 0.01487174892876487, Valid Loss: 0.012058817860085077\n",
      "Epoch: 181, Train Loss: 0.014855402428976776, Valid Loss: 0.012047111314319259\n",
      "Epoch: 182, Train Loss: 0.014838996206445845, Valid Loss: 0.01203536432521681\n",
      "Epoch: 183, Train Loss: 0.014822530004772733, Valid Loss: 0.012023576766096467\n",
      "Epoch: 184, Train Loss: 0.014806003573648174, Valid Loss: 0.012011748515418919\n",
      "Epoch: 185, Train Loss: 0.014789416668941393, Valid Loss: 0.01199987945685378\n",
      "Epoch: 186, Train Loss: 0.014772769052789346, Valid Loss: 0.011987969479347\n",
      "Epoch: 187, Train Loss: 0.014756060493686678, Valid Loss: 0.011976018477188684\n",
      "Epoch: 188, Train Loss: 0.0147392907665764, Valid Loss: 0.01196402635008128\n",
      "Epoch: 189, Train Loss: 0.014722459652941255, Valid Loss: 0.011951993003208101\n",
      "Epoch: 190, Train Loss: 0.014705566940895748, Valid Loss: 0.011939918347302179\n",
      "Epoch: 191, Train Loss: 0.014688612425278825, Valid Loss: 0.011927802298715429\n",
      "Epoch: 192, Train Loss: 0.01467159590774711, Valid Loss: 0.011915644779488088\n",
      "Epoch: 193, Train Loss: 0.014654517196868751, Valid Loss: 0.011903445717418333\n",
      "Epoch: 194, Train Loss: 0.014637376108217788, Valid Loss: 0.011891205046132185\n",
      "Epoch: 195, Train Loss: 0.014620172464468992, Valid Loss: 0.011878922705153555\n",
      "Epoch: 196, Train Loss: 0.014602906095493232, Valid Loss: 0.01186659863997445\n",
      "Epoch: 197, Train Loss: 0.014585576838453226, Valid Loss: 0.01185423280212527\n",
      "Epoch: 198, Train Loss: 0.014568184537899683, Valid Loss: 0.011841825149245248\n",
      "Epoch: 199, Train Loss: 0.01455072904586785, Valid Loss: 0.01182937564515289\n",
      "Epoch: 200, Train Loss: 0.0145332102219743, Valid Loss: 0.01181688425991645\n",
      "Epoch: 201, Train Loss: 0.014515627933514082, Valid Loss: 0.011804350969924417\n",
      "Epoch: 202, Train Loss: 0.014497982055558042, Valid Loss: 0.011791775757955895\n",
      "Epoch: 203, Train Loss: 0.01448027247105036, Valid Loss: 0.011779158613250948\n",
      "Epoch: 204, Train Loss: 0.014462499070906258, Valid Loss: 0.011766499531580802\n",
      "Epoch: 205, Train Loss: 0.014444661754109786, Valid Loss: 0.011753798515317876\n",
      "Epoch: 206, Train Loss: 0.014426760427811679, Valid Loss: 0.011741055573505627\n",
      "Epoch: 207, Train Loss: 0.014408795007427247, Valid Loss: 0.011728270721928146\n",
      "Epoch: 208, Train Loss: 0.014390765416734222, Valid Loss: 0.011715443983179483\n",
      "Epoch: 209, Train Loss: 0.014372671587970504, Valid Loss: 0.011702575386732647\n",
      "Epoch: 210, Train Loss: 0.01435451346193184, Valid Loss: 0.011689664969008256\n",
      "Epoch: 211, Train Loss: 0.014336290988069253, Valid Loss: 0.011676712773442751\n",
      "Epoch: 212, Train Loss: 0.014318004124586295, Valid Loss: 0.011663718850556205\n",
      "Epoch: 213, Train Loss: 0.014299652838536006, Valid Loss: 0.011650683258019628\n",
      "Epoch: 214, Train Loss: 0.014281237105917513, Valid Loss: 0.011637606060721728\n",
      "Epoch: 215, Train Loss: 0.014262756911772296, Valid Loss: 0.011624487330835093\n",
      "Epoch: 216, Train Loss: 0.014244212250279943, Valid Loss: 0.011611327147881767\n",
      "Epoch: 217, Train Loss: 0.014225603124853473, Valid Loss: 0.01159812559879815\n",
      "Epoch: 218, Train Loss: 0.014206929548234043, Valid Loss: 0.01158488277799915\n",
      "Epoch: 219, Train Loss: 0.014188191542585113, Valid Loss: 0.011571598787441633\n",
      "Epoch: 220, Train Loss: 0.014169389139585856, Valid Loss: 0.011558273736686988\n",
      "Epoch: 221, Train Loss: 0.014150522380523903, Valid Loss: 0.011544907742962891\n",
      "Epoch: 222, Train Loss: 0.014131591316387271, Valid Loss: 0.011531500931224126\n",
      "Epoch: 223, Train Loss: 0.014112596007955435, Valid Loss: 0.011518053434212453\n",
      "Epoch: 224, Train Loss: 0.014093536525889497, Valid Loss: 0.011504565392515464\n",
      "Epoch: 225, Train Loss: 0.01407441295082136, Valid Loss: 0.011491036954624395\n",
      "Epoch: 226, Train Loss: 0.014055225373441895, Valid Loss: 0.011477468276990801\n",
      "Epoch: 227, Train Loss: 0.014035973894587961, Valid Loss: 0.011463859524082076\n",
      "Epoch: 228, Train Loss: 0.014016658625328283, Valid Loss: 0.011450210868435779\n",
      "Epoch: 229, Train Loss: 0.013997279687048086, Valid Loss: 0.011436522490712643\n",
      "Epoch: 230, Train Loss: 0.013977837211532425, Valid Loss: 0.011422794579748338\n",
      "Epoch: 231, Train Loss: 0.01395833134104816, Valid Loss: 0.011409027332603778\n",
      "Epoch: 232, Train Loss: 0.013938762228424467, Valid Loss: 0.011395220954614066\n",
      "Epoch: 233, Train Loss: 0.013919130037131888, Valid Loss: 0.011381375659435922\n",
      "Epoch: 234, Train Loss: 0.013899434941359748, Valid Loss: 0.011367491669093593\n",
      "Epoch: 235, Train Loss: 0.013879677126092, Valid Loss: 0.011353569214023184\n",
      "Epoch: 236, Train Loss: 0.013859856787181305, Valid Loss: 0.011339608533115305\n",
      "Epoch: 237, Train Loss: 0.013839974131421367, Valid Loss: 0.011325609873756104\n",
      "Epoch: 238, Train Loss: 0.013820029376617388, Valid Loss: 0.01131157349186645\n",
      "Epoch: 239, Train Loss: 0.013800022751654638, Valid Loss: 0.01129749965193938\n",
      "Epoch: 240, Train Loss: 0.013779954496564994, Valid Loss: 0.011283388627075694\n",
      "Epoch: 241, Train Loss: 0.013759824862591455, Valid Loss: 0.011269240699017566\n",
      "Epoch: 242, Train Loss: 0.01373963411225051, Valid Loss: 0.011255056158180293\n",
      "Epoch: 243, Train Loss: 0.01371938251939229, Valid Loss: 0.011240835303681923\n",
      "Epoch: 244, Train Loss: 0.013699070369258472, Valid Loss: 0.011226578443370884\n",
      "Epoch: 245, Train Loss: 0.01367869795853782, Valid Loss: 0.011212285893851454\n",
      "Epoch: 246, Train Loss: 0.013658265595419314, Valid Loss: 0.011197957980507052\n",
      "Epoch: 247, Train Loss: 0.013637773599642819, Valid Loss: 0.011183595037521296\n",
      "Epoch: 248, Train Loss: 0.01361722230254714, Valid Loss: 0.011169197407896805\n",
      "Epoch: 249, Train Loss: 0.013596612047115533, Valid Loss: 0.011154765443471618\n",
      "Epoch: 250, Train Loss: 0.013575943188018432, Valid Loss: 0.011140299504933275\n",
      "Epoch: 251, Train Loss: 0.013555216091653501, Valid Loss: 0.011125799961830432\n",
      "Epoch: 252, Train Loss: 0.013534431136182768, Valid Loss: 0.011111267192581967\n",
      "Epoch: 253, Train Loss: 0.013513588711566929, Valid Loss: 0.011096701584483615\n",
      "Epoch: 254, Train Loss: 0.013492689219596628, Valid Loss: 0.011082103533711961\n",
      "Epoch: 255, Train Loss: 0.013471733073920753, Valid Loss: 0.011067473445325821\n",
      "Epoch: 256, Train Loss: 0.013450720700071582, Valid Loss: 0.01105281173326493\n",
      "Epoch: 257, Train Loss: 0.01342965253548678, Valid Loss: 0.011038118820345923\n",
      "Epoch: 258, Train Loss: 0.0134085290295282, Valid Loss: 0.011023395138255536\n",
      "Epoch: 259, Train Loss: 0.013387350643497309, Valid Loss: 0.011008641127540977\n",
      "Epoch: 260, Train Loss: 0.013366117850647336, Valid Loss: 0.010993857237597479\n",
      "Epoch: 261, Train Loss: 0.013344831136191964, Valid Loss: 0.0109790439266529\n",
      "Epoch: 262, Train Loss: 0.013323490997310533, Valid Loss: 0.010964201661749412\n",
      "Epoch: 263, Train Loss: 0.013302097943149719, Valid Loss: 0.010949330918722211\n",
      "Epoch: 264, Train Loss: 0.01328065249482164, Valid Loss: 0.010934432182175206\n",
      "Epoch: 265, Train Loss: 0.013259155185398247, Valid Loss: 0.010919505945453633\n",
      "Epoch: 266, Train Loss: 0.013237606559902073, Valid Loss: 0.010904552710613621\n",
      "Epoch: 267, Train Loss: 0.013216007175293192, Valid Loss: 0.01088957298838857\n",
      "Epoch: 268, Train Loss: 0.013194357600452344, Valid Loss: 0.01087456729815244\n",
      "Epoch: 269, Train Loss: 0.01317265841616025, Valid Loss: 0.010859536167879802\n",
      "Epoch: 270, Train Loss: 0.01315091021507298, Valid Loss: 0.01084448013410269\n",
      "Epoch: 271, Train Loss: 0.01312911360169334, Valid Loss: 0.01082939974186422\n",
      "Epoch: 272, Train Loss: 0.01310726919233834, Valid Loss: 0.010814295544668909\n",
      "Epoch: 273, Train Loss: 0.013085377615102521, Valid Loss: 0.010799168104429728\n",
      "Epoch: 274, Train Loss: 0.013063439509817268, Valid Loss: 0.01078401799141183\n",
      "Epoch: 275, Train Loss: 0.013041455528005952, Valid Loss: 0.01076884578417292\n",
      "Epoch: 276, Train Loss: 0.013019426332834956, Valid Loss: 0.01075365206950032\n",
      "Epoch: 277, Train Loss: 0.012997352599060465, Valid Loss: 0.010738437442344602\n",
      "Epoch: 278, Train Loss: 0.012975235012971056, Valid Loss: 0.01072320250574988\n",
      "Epoch: 279, Train Loss: 0.012953074272326037, Valid Loss: 0.010707947870780698\n",
      "Epoch: 280, Train Loss: 0.012930871086289477, Valid Loss: 0.01069267415644548\n",
      "Epoch: 281, Train Loss: 0.012908626175359955, Valid Loss: 0.010677381989616609\n",
      "Epoch: 282, Train Loss: 0.012886340271295982, Valid Loss: 0.010662072004947051\n",
      "Epoch: 283, Train Loss: 0.012864014117037045, Valid Loss: 0.010646744844783599\n",
      "Epoch: 284, Train Loss: 0.012841648466620332, Valid Loss: 0.010631401159076603\n",
      "Epoch: 285, Train Loss: 0.012819244085093037, Valid Loss: 0.010616041605286406\n",
      "Epoch: 286, Train Loss: 0.012796801748420314, Valid Loss: 0.01060066684828624\n",
      "Epoch: 287, Train Loss: 0.012774322243388786, Valid Loss: 0.01058527756026178\n",
      "Epoch: 288, Train Loss: 0.012751806367505713, Valid Loss: 0.010569874420607276\n",
      "Epoch: 289, Train Loss: 0.012729254928893707, Valid Loss: 0.01055445811581828\n",
      "Epoch: 290, Train Loss: 0.012706668746181057, Valid Loss: 0.010539029339381006\n",
      "Epoch: 291, Train Loss: 0.012684048648387661, Valid Loss: 0.010523588791658314\n",
      "Epoch: 292, Train Loss: 0.012661395474806561, Valid Loss: 0.010508137179772378\n",
      "Epoch: 293, Train Loss: 0.012638710074881076, Valid Loss: 0.010492675217483973\n",
      "Epoch: 294, Train Loss: 0.012615993308077597, Valid Loss: 0.01047720362506853\n",
      "Epoch: 295, Train Loss: 0.01259324604375399, Valid Loss: 0.010461723129188869\n",
      "Epoch: 296, Train Loss: 0.0125704691610237, Valid Loss: 0.010446234462764693\n",
      "Epoch: 297, Train Loss: 0.0125476635486155, Valid Loss: 0.010430738364838899\n",
      "Epoch: 298, Train Loss: 0.012524830104728997, Valid Loss: 0.010415235580440657\n",
      "Epoch: 299, Train Loss: 0.012501969736885825, Valid Loss: 0.010399726860445409\n",
      "Epoch: 300, Train Loss: 0.01247908336177666, Valid Loss: 0.010384212961431704\n",
      "Epoch: 301, Train Loss: 0.012456171905104016, Valid Loss: 0.01036869464553501\n",
      "Epoch: 302, Train Loss: 0.01243323630142089, Valid Loss: 0.010353172680298487\n",
      "Epoch: 303, Train Loss: 0.012410277493965302, Valid Loss: 0.010337647838520817\n",
      "Epoch: 304, Train Loss: 0.012387296434490746, Valid Loss: 0.010322120898101078\n",
      "Epoch: 305, Train Loss: 0.01236429408309266, Valid Loss: 0.010306592641880769\n",
      "Epoch: 306, Train Loss: 0.012341271408030893, Valid Loss: 0.01029106385748302\n",
      "Epoch: 307, Train Loss: 0.012318229385548272, Valid Loss: 0.01027553533714904\n",
      "Epoch: 308, Train Loss: 0.012295168999685321, Valid Loss: 0.010260007877571871\n",
      "Epoch: 309, Train Loss: 0.01227209124209118, Valid Loss: 0.010244482279727511\n",
      "Epoch: 310, Train Loss: 0.01224899711183077, Valid Loss: 0.010228959348703439\n",
      "Epoch: 311, Train Loss: 0.012225887615188358, Valid Loss: 0.01021343989352468\n",
      "Epoch: 312, Train Loss: 0.012202763765467466, Valid Loss: 0.010197924726977394\n",
      "Epoch: 313, Train Loss: 0.012179626582787281, Valid Loss: 0.01018241466543013\n",
      "Epoch: 314, Train Loss: 0.012156477093875644, Valid Loss: 0.010166910528652767\n",
      "Epoch: 315, Train Loss: 0.012133316331858662, Valid Loss: 0.01015141313963325\n",
      "Epoch: 316, Train Loss: 0.012110145336047028, Valid Loss: 0.010135923324392202\n",
      "Epoch: 317, Train Loss: 0.012086965151719165, Valid Loss: 0.010120441911795461\n",
      "Epoch: 318, Train Loss: 0.012063776829901266, Valid Loss: 0.010104969733364642\n",
      "Epoch: 319, Train Loss: 0.01204058142714428, Valid Loss: 0.010089507623085825\n",
      "Epoch: 320, Train Loss: 0.012017380005298053, Valid Loss: 0.010074056417216428\n",
      "Epoch: 321, Train Loss: 0.011994173631282551, Valid Loss: 0.01005861695409037\n",
      "Epoch: 322, Train Loss: 0.011970963376856434, Valid Loss: 0.010043190073921586\n",
      "Epoch: 323, Train Loss: 0.01194775031838296, Valid Loss: 0.010027776618606042\n",
      "Epoch: 324, Train Loss: 0.011924535536593386, Valid Loss: 0.010012377431522276\n",
      "Epoch: 325, Train Loss: 0.01190132011634794, Valid Loss: 0.009996993357330609\n",
      "Epoch: 326, Train Loss: 0.011878105146394508, Valid Loss: 0.009981625241771095\n",
      "Epoch: 327, Train Loss: 0.011854891719125104, Valid Loss: 0.009966273931460322\n",
      "Epoch: 328, Train Loss: 0.011831680930330263, Valid Loss: 0.009950940273687143\n",
      "Epoch: 329, Train Loss: 0.011808473878951476, Valid Loss: 0.009935625116207481\n",
      "Epoch: 330, Train Loss: 0.01178527166683175, Valid Loss: 0.009920329307038244\n",
      "Epoch: 331, Train Loss: 0.011762075398464453, Valid Loss: 0.00990505369425051\n",
      "Epoch: 332, Train Loss: 0.011738886180740538, Valid Loss: 0.009889799125762053\n",
      "Epoch: 333, Train Loss: 0.011715705122694263, Valid Loss: 0.009874566449129329\n",
      "Epoch: 334, Train Loss: 0.01169253333524757, Valid Loss: 0.009859356511339012\n",
      "Epoch: 335, Train Loss: 0.0116693719309532, Valid Loss: 0.009844170158599204\n",
      "Epoch: 336, Train Loss: 0.011646222023736658, Valid Loss: 0.009829008236130407\n",
      "Epoch: 337, Train Loss: 0.01162308472863726, Valid Loss: 0.009813871587956383\n",
      "Epoch: 338, Train Loss: 0.01159996116154824, Valid Loss: 0.009798761056694999\n",
      "Epoch: 339, Train Loss: 0.011576852438956176, Valid Loss: 0.00978367748334913\n",
      "Epoch: 340, Train Loss: 0.011553759677679762, Valid Loss: 0.009768621707097821\n",
      "Epoch: 341, Train Loss: 0.011530683994608146, Valid Loss: 0.009753594565087698\n",
      "Epoch: 342, Train Loss: 0.011507626506438903, Valid Loss: 0.009738596892224826\n",
      "Epoch: 343, Train Loss: 0.011484588329415799, Valid Loss: 0.009723629520967093\n",
      "Epoch: 344, Train Loss: 0.01146157057906646, Valid Loss: 0.009708693281117191\n",
      "Epoch: 345, Train Loss: 0.011438574369940118, Valid Loss: 0.009693788999616372\n",
      "Epoch: 346, Train Loss: 0.01141560081534551, Valid Loss: 0.00967891750033902\n",
      "Epoch: 347, Train Loss: 0.01139265102708912, Valid Loss: 0.009664079603888178\n",
      "Epoch: 348, Train Loss: 0.011369726115213844, Valid Loss: 0.009649276127392145\n",
      "Epoch: 349, Train Loss: 0.011346827187738252, Valid Loss: 0.009634507884302236\n",
      "Epoch: 350, Train Loss: 0.011323955350396537, Valid Loss: 0.00961977568419175\n",
      "Epoch: 351, Train Loss: 0.011301111706379326, Valid Loss: 0.009605080332556401\n",
      "Epoch: 352, Train Loss: 0.011278297356075462, Valid Loss: 0.00959042263061613\n",
      "Epoch: 353, Train Loss: 0.011255513396814862, Valid Loss: 0.009575803375118557\n",
      "Epoch: 354, Train Loss: 0.011232760922612639, Valid Loss: 0.009561223358144057\n",
      "Epoch: 355, Train Loss: 0.011210041023914543, Valid Loss: 0.009546683366912632\n",
      "Epoch: 356, Train Loss: 0.01118735478734393, Valid Loss: 0.00953218418359266\n",
      "Epoch: 357, Train Loss: 0.011164703295450286, Valid Loss: 0.009517726585111566\n",
      "Epoch: 358, Train Loss: 0.01114208762645954, Valid Loss: 0.009503311342968617\n",
      "Epoch: 359, Train Loss: 0.011119508854026202, Valid Loss: 0.009488939223049823\n",
      "Epoch: 360, Train Loss: 0.011096968046987463, Valid Loss: 0.009474610985445095\n",
      "Epoch: 361, Train Loss: 0.011074466269119445, Valid Loss: 0.009460327384267745\n",
      "Epoch: 362, Train Loss: 0.01105200457889561, Valid Loss: 0.009446089167476409\n",
      "Epoch: 363, Train Loss: 0.011029584029247539, Valid Loss: 0.00943189707669947\n",
      "Epoch: 364, Train Loss: 0.011007205667328135, Valid Loss: 0.009417751847062087\n",
      "Epoch: 365, Train Loss: 0.010984870534277396, Valid Loss: 0.00940365420701589\n",
      "Epoch: 366, Train Loss: 0.010962579664990849, Valid Loss: 0.00938960487817143\n",
      "Epoch: 367, Train Loss: 0.010940334087890767, Valid Loss: 0.00937560457513348\n",
      "Epoch: 368, Train Loss: 0.010918134824700255, Valid Loss: 0.009361654005339224\n",
      "Epoch: 369, Train Loss: 0.010895982890220342, Valid Loss: 0.009347753868899437\n",
      "Epoch: 370, Train Loss: 0.010873879292110136, Valid Loss: 0.00933390485844274\n",
      "Epoch: 371, Train Loss: 0.010851825030670179, Valid Loss: 0.009320107658962934\n",
      "Epoch: 372, Train Loss: 0.010829821098629075, Valid Loss: 0.009306362947669573\n",
      "Epoch: 373, Train Loss: 0.010807868480933498, Valid Loss: 0.009292671393841758\n",
      "Epoch: 374, Train Loss: 0.010785968154541649, Valid Loss: 0.009279033658685243\n",
      "Epoch: 375, Train Loss: 0.01076412108822028, Valid Loss: 0.009265450395192944\n",
      "Epoch: 376, Train Loss: 0.010742328242345354, Valid Loss: 0.00925192224800886\n",
      "Epoch: 377, Train Loss: 0.010720590568706402, Valid Loss: 0.009238449853295467\n",
      "Epoch: 378, Train Loss: 0.010698909010314691, Valid Loss: 0.009225033838604662\n",
      "Epoch: 379, Train Loss: 0.010677284501215282, Valid Loss: 0.00921167482275229\n",
      "Epoch: 380, Train Loss: 0.010655717966302991, Valid Loss: 0.009198373415696293\n",
      "Epoch: 381, Train Loss: 0.010634210321142402, Valid Loss: 0.00918513021841851\n",
      "Epoch: 382, Train Loss: 0.010612762471791942, Valid Loss: 0.009171945822810246\n",
      "Epoch: 383, Train Loss: 0.010591375314632103, Valid Loss: 0.009158820811561516\n",
      "Epoch: 384, Train Loss: 0.010570049736197877, Valid Loss: 0.009145755758054125\n",
      "Epoch: 385, Train Loss: 0.010548786613015433, Valid Loss: 0.009132751226258545\n",
      "Epoch: 386, Train Loss: 0.01052758681144314, Valid Loss: 0.009119807770634616\n",
      "Epoch: 387, Train Loss: 0.010506451187516919, Valid Loss: 0.009106925936036162\n",
      "Epoch: 388, Train Loss: 0.010485380586800036, Valid Loss: 0.009094106257619444\n",
      "Epoch: 389, Train Loss: 0.010464375844237343, Valid Loss: 0.009081349260755572\n",
      "Epoch: 390, Train Loss: 0.010443437784013998, Valid Loss: 0.00906865546094681\n",
      "Epoch: 391, Train Loss: 0.01042256721941875, Valid Loss: 0.00905602536374687\n",
      "Epoch: 392, Train Loss: 0.010401764952711773, Valid Loss: 0.00904345946468512\n",
      "Epoch: 393, Train Loss: 0.010381031774997091, Valid Loss: 0.009030958249194776\n",
      "Epoch: 394, Train Loss: 0.010360368466099648, Valid Loss: 0.009018522192545094\n",
      "Epoch: 395, Train Loss: 0.010339775794447018, Valid Loss: 0.009006151759777486\n",
      "Epoch: 396, Train Loss: 0.010319254516955775, Valid Loss: 0.008993847405645667\n",
      "Epoch: 397, Train Loss: 0.010298805378922578, Valid Loss: 0.008981609574559759\n",
      "Epoch: 398, Train Loss: 0.010278429113919926, Valid Loss: 0.008969438700534356\n",
      "Epoch: 399, Train Loss: 0.01025812644369665, Valid Loss: 0.008957335207140578\n",
      "Epoch: 400, Train Loss: 0.010237898078083106, Valid Loss: 0.008945299507462078\n",
      "Epoch: 401, Train Loss: 0.010217744714901117, Valid Loss: 0.008933332004054995\n",
      "Epoch: 402, Train Loss: 0.01019766703987862, Valid Loss: 0.008921433088911836\n",
      "Epoch: 403, Train Loss: 0.010177665726569057, Valid Loss: 0.008909603143429288\n",
      "Epoch: 404, Train Loss: 0.010157741436275465, Valid Loss: 0.008897842538379901\n",
      "Epoch: 405, Train Loss: 0.010137894817979299, Valid Loss: 0.008886151633887692\n",
      "Epoch: 406, Train Loss: 0.010118126508273956, Valid Loss: 0.008874530779407558\n",
      "Epoch: 407, Train Loss: 0.010098437131302975, Valid Loss: 0.008862980313708538\n",
      "Epoch: 408, Train Loss: 0.010078827298702924, Valid Loss: 0.00885150056486088\n",
      "Epoch: 409, Train Loss: 0.010059297609550944, Valid Loss: 0.008840091850226875\n",
      "Epoch: 410, Train Loss: 0.010039848650316896, Valid Loss: 0.008828754476455406\n",
      "Epoch: 411, Train Loss: 0.010020480994820169, Valid Loss: 0.008817488739480234\n",
      "Epoch: 412, Train Loss: 0.010001195204191004, Valid Loss: 0.008806294924521946\n",
      "Epoch: 413, Train Loss: 0.009981991826836435, Valid Loss: 0.008795173306093501\n",
      "Epoch: 414, Train Loss: 0.009962871398410693, Valid Loss: 0.00878412414800941\n",
      "Epoch: 415, Train Loss: 0.009943834441790138, Valid Loss: 0.008773147703398425\n",
      "Epoch: 416, Train Loss: 0.009924881467052596, Valid Loss: 0.008762244214719772\n",
      "Epoch: 417, Train Loss: 0.009906012971461143, Valid Loss: 0.008751413913782794\n",
      "Epoch: 418, Train Loss: 0.009887229439452238, Valid Loss: 0.008740657021770066\n",
      "Epoch: 419, Train Loss: 0.009868531342628167, Valid Loss: 0.008729973749263818\n",
      "Epoch: 420, Train Loss: 0.009849919139753784, Valid Loss: 0.0087193642962757\n",
      "Epoch: 421, Train Loss: 0.009831393276757468, Valid Loss: 0.008708828852279828\n",
      "Epoch: 422, Train Loss: 0.009812954186736262, Valid Loss: 0.008698367596249002\n",
      "Epoch: 423, Train Loss: 0.00979460228996513, Valid Loss: 0.00868798069669409\n",
      "Epoch: 424, Train Loss: 0.009776337993910304, Valid Loss: 0.008677668311706565\n",
      "Epoch: 425, Train Loss: 0.00975816169324664, Valid Loss: 0.00866743058900399\n",
      "Epoch: 426, Train Loss: 0.009740073769878914, Valid Loss: 0.008657267665978595\n",
      "Epoch: 427, Train Loss: 0.009722074592967058, Valid Loss: 0.0086471796697487\n",
      "Epoch: 428, Train Loss: 0.009704164518955208, Valid Loss: 0.008637166717213075\n",
      "Epoch: 429, Train Loss: 0.009686343891604532, Valid Loss: 0.00862722891510805\n",
      "Epoch: 430, Train Loss: 0.009668613042029784, Valid Loss: 0.008617366360067413\n",
      "Epoch: 431, Train Loss: 0.00965097228873952, Valid Loss: 0.00860757913868499\n",
      "Epoch: 432, Train Loss: 0.00963342193767987, Valid Loss: 0.008597867327579846\n",
      "Epoch: 433, Train Loss: 0.009615962282281844, Valid Loss: 0.00858823099346402\n",
      "Epoch: 434, Train Loss: 0.009598593603512109, Valid Loss: 0.008578670193212795\n",
      "Epoch: 435, Train Loss: 0.009581316169927091, Valid Loss: 0.0085691849739374\n",
      "Epoch: 436, Train Loss: 0.00956413023773047, Valid Loss: 0.008559775373060036\n",
      "Epoch: 437, Train Loss: 0.00954703605083384, Valid Loss: 0.008550441418391242\n",
      "Epoch: 438, Train Loss: 0.009530033840920585, Valid Loss: 0.008541183128209508\n",
      "Epoch: 439, Train Loss: 0.00951312382751283, Valid Loss: 0.008532000511342999\n",
      "Epoch: 440, Train Loss: 0.009496306218041426, Valid Loss: 0.00852289356725345\n",
      "Epoch: 441, Train Loss: 0.009479581207918883, Valid Loss: 0.008513862286122054\n",
      "Epoch: 442, Train Loss: 0.009462948980615173, Valid Loss: 0.008504906648937343\n",
      "Epoch: 443, Train Loss: 0.00944640970773635, Valid Loss: 0.00849602662758496\n",
      "Epoch: 444, Train Loss: 0.009429963549105878, Valid Loss: 0.008487222184939275\n",
      "Epoch: 445, Train Loss: 0.009413610652848617, Valid Loss: 0.008478493274956764\n",
      "Epoch: 446, Train Loss: 0.009397351155477395, Valid Loss: 0.008469839842771111\n",
      "Epoch: 447, Train Loss: 0.009381185181982063, Valid Loss: 0.008461261824789913\n",
      "Epoch: 448, Train Loss: 0.009365112845920983, Valid Loss: 0.008452759148792973\n",
      "Epoch: 449, Train Loss: 0.009349134249514869, Valid Loss: 0.008444331734032145\n",
      "Epoch: 450, Train Loss: 0.00933324948374288, Valid Loss: 0.008435979491332514\n",
      "Epoch: 451, Train Loss: 0.009317458628440934, Valid Loss: 0.008427702323195044\n",
      "Epoch: 452, Train Loss: 0.00930176175240212, Valid Loss: 0.008419500123900482\n",
      "Epoch: 453, Train Loss: 0.009286158913479177, Valid Loss: 0.008411372779614536\n",
      "Epoch: 454, Train Loss: 0.009270650158688911, Valid Loss: 0.00840332016849421\n",
      "Epoch: 455, Train Loss: 0.009255235524318539, Valid Loss: 0.008395342160795257\n",
      "Epoch: 456, Train Loss: 0.009239915036033818, Valid Loss: 0.008387438618980692\n",
      "Epoch: 457, Train Loss: 0.009224688708988953, Valid Loss: 0.008379609397830293\n",
      "Epoch: 458, Train Loss: 0.009209556547938133, Valid Loss: 0.008371854344551016\n",
      "Epoch: 459, Train Loss: 0.009194518547348709, Valid Loss: 0.008364173298888299\n",
      "Epoch: 460, Train Loss: 0.00917957469151585, Valid Loss: 0.008356566093238142\n",
      "Epoch: 461, Train Loss: 0.009164724954678672, Valid Loss: 0.008349032552759948\n",
      "Epoch: 462, Train Loss: 0.00914996930113776, Valid Loss: 0.00834157249549004\n",
      "Epoch: 463, Train Loss: 0.00913530768537394, Valid Loss: 0.00833418573245582\n",
      "Epoch: 464, Train Loss: 0.009120740052168357, Valid Loss: 0.00832687206779046\n",
      "Epoch: 465, Train Loss: 0.009106266336723663, Valid Loss: 0.008319631298848143\n",
      "Epoch: 466, Train Loss: 0.009091886464786312, Valid Loss: 0.008312463216319734\n",
      "Epoch: 467, Train Loss: 0.009077600352769909, Valid Loss: 0.008305367604348845\n",
      "Epoch: 468, Train Loss: 0.009063407907879482, Valid Loss: 0.00829834424064826\n",
      "Epoch: 469, Train Loss: 0.009049309028236656, Valid Loss: 0.008291392896616635\n",
      "Epoch: 470, Train Loss: 0.009035303603005666, Valid Loss: 0.00828451333745544\n",
      "Epoch: 471, Train Loss: 0.009021391512520105, Valid Loss: 0.008277705322286092\n",
      "Epoch: 472, Train Loss: 0.009007572628410386, Valid Loss: 0.008270968604267183\n",
      "Epoch: 473, Train Loss: 0.008993846813731826, Valid Loss: 0.00826430293071186\n",
      "Epoch: 474, Train Loss: 0.008980213923093304, Valid Loss: 0.008257708043205159\n",
      "Epoch: 475, Train Loss: 0.00896667380278641, Valid Loss: 0.008251183677721388\n",
      "Epoch: 476, Train Loss: 0.008953226290915071, Valid Loss: 0.00824472956474141\n",
      "Epoch: 477, Train Loss: 0.008939871217525526, Valid Loss: 0.008238345429369813\n",
      "Epoch: 478, Train Loss: 0.008926608404736655, Valid Loss: 0.008232030991451972\n",
      "Epoch: 479, Train Loss: 0.00891343766687057, Valid Loss: 0.008225785965690858\n",
      "Epoch: 480, Train Loss: 0.008900358810583422, Valid Loss: 0.00821961006176363\n",
      "Epoch: 481, Train Loss: 0.00888737163499635, Valid Loss: 0.008213502984437937\n",
      "Epoch: 482, Train Loss: 0.008874475931826565, Valid Loss: 0.008207464433687908\n",
      "Epoch: 483, Train Loss: 0.008861671485518459, Valid Loss: 0.00820149410480976\n",
      "Epoch: 484, Train Loss: 0.008848958073374708, Valid Loss: 0.008195591688537002\n",
      "Epoch: 485, Train Loss: 0.00883633546568735, Valid Loss: 0.008189756871155203\n",
      "Epoch: 486, Train Loss: 0.008823803425868736, Valid Loss: 0.008183989334616277\n",
      "Epoch: 487, Train Loss: 0.008811361710582334, Valid Loss: 0.008178288756652248\n",
      "Epoch: 488, Train Loss: 0.008799010069873344, Valid Loss: 0.008172654810888464\n",
      "Epoch: 489, Train Loss: 0.008786748247299048, Valid Loss: 0.008167087166956242\n",
      "Epoch: 490, Train Loss: 0.008774575980058888, Valid Loss: 0.008161585490604853\n",
      "Epoch: 491, Train Loss: 0.008762492999124199, Valid Loss: 0.008156149443812905\n",
      "Epoch: 492, Train Loss: 0.008750499029367559, Valid Loss: 0.008150778684899019\n",
      "Epoch: 493, Train Loss: 0.008738593789691728, Valid Loss: 0.008145472868631787\n",
      "Epoch: 494, Train Loss: 0.008726776993158115, Valid Loss: 0.008140231646339003\n",
      "Epoch: 495, Train Loss: 0.00871504834711476, Valid Loss: 0.008135054666016129\n",
      "Epoch: 496, Train Loss: 0.008703407553323743, Valid Loss: 0.00812994157243394\n",
      "Epoch: 497, Train Loss: 0.008691854308088063, Valid Loss: 0.008124892007245392\n",
      "Epoch: 498, Train Loss: 0.008680388302377853, Valid Loss: 0.008119905609091592\n",
      "Epoch: 499, Train Loss: 0.008669009221955985, Valid Loss: 0.008114982013706933\n",
      "Epoch: 500, Train Loss: 0.008657716747502974, Valid Loss: 0.008110120854023328\n",
      "Epoch: 501, Train Loss: 0.00864651055474116, Valid Loss: 0.008105321760273518\n",
      "Epoch: 502, Train Loss: 0.008635390314558164, Valid Loss: 0.008100584360093472\n",
      "Epoch: 503, Train Loss: 0.008624355693129533, Valid Loss: 0.008095908278623774\n",
      "Epoch: 504, Train Loss: 0.008613406352040609, Valid Loss: 0.008091293138610107\n",
      "Epoch: 505, Train Loss: 0.008602541948407543, Valid Loss: 0.008086738560502679\n",
      "Epoch: 506, Train Loss: 0.008591762134997438, Valid Loss: 0.008082244162554675\n",
      "Epoch: 507, Train Loss: 0.008581066560347623, Valid Loss: 0.008077809560919668\n",
      "Epoch: 508, Train Loss: 0.008570454868883982, Valid Loss: 0.00807343436974799\n",
      "Epoch: 509, Train Loss: 0.00855992670103837, Valid Loss: 0.008069118201282036\n",
      "Epoch: 510, Train Loss: 0.008549481693365038, Valid Loss: 0.0080648606659505\n",
      "Epoch: 511, Train Loss: 0.008539119478656092, Valid Loss: 0.008060661372461532\n",
      "Epoch: 512, Train Loss: 0.008528839686055924, Valid Loss: 0.008056519927894783\n",
      "Epoch: 513, Train Loss: 0.008518641941174639, Valid Loss: 0.008052435937792353\n",
      "Epoch: 514, Train Loss: 0.008508525866200397, Valid Loss: 0.008048409006248607\n",
      "Epoch: 515, Train Loss: 0.008498491080010726, Valid Loss: 0.008044438735998881\n",
      "Epoch: 516, Train Loss: 0.008488537198282728, Valid Loss: 0.008040524728507003\n",
      "Epoch: 517, Train Loss: 0.008478663833602186, Valid Loss: 0.00803666658405173\n",
      "Epoch: 518, Train Loss: 0.008468870595571554, Valid Loss: 0.008032863901811982\n",
      "Epoch: 519, Train Loss: 0.008459157090916821, Valid Loss: 0.008029116279950925\n",
      "Epoch: 520, Train Loss: 0.008449522923593224, Valid Loss: 0.008025423315698887\n",
      "Epoch: 521, Train Loss: 0.008439967694889795, Valid Loss: 0.008021784605435107\n",
      "Epoch: 522, Train Loss: 0.008430491003532757, Valid Loss: 0.008018199744768292\n",
      "Epoch: 523, Train Loss: 0.008421092445787712, Valid Loss: 0.008014668328615991\n",
      "Epoch: 524, Train Loss: 0.008411771615560651, Valid Loss: 0.008011189951282796\n",
      "Epoch: 525, Train Loss: 0.00840252810449775, Valid Loss: 0.008007764206537345\n",
      "Epoch: 526, Train Loss: 0.008393361502083968, Valid Loss: 0.008004390687688113\n",
      "Epoch: 527, Train Loss: 0.008384271395740413, Valid Loss: 0.00800106898765804\n",
      "Epoch: 528, Train Loss: 0.008375257370920479, Valid Loss: 0.007997798699057956\n",
      "Epoch: 529, Train Loss: 0.008366319011204748, Valid Loss: 0.007994579414258782\n",
      "Epoch: 530, Train Loss: 0.00835745589839466, Valid Loss: 0.007991410725462578\n",
      "Epoch: 531, Train Loss: 0.008348667612604933, Valid Loss: 0.007988292224772372\n",
      "Epoch: 532, Train Loss: 0.008339953732354712, Valid Loss: 0.007985223504260777\n",
      "Epoch: 533, Train Loss: 0.008331313834657498, Valid Loss: 0.00798220415603745\n",
      "Epoch: 534, Train Loss: 0.00832274749510978, Valid Loss: 0.007979233772315348\n",
      "Epoch: 535, Train Loss: 0.008314254287978447, Valid Loss: 0.007976311945475786\n",
      "Epoch: 536, Train Loss: 0.00830583378628689, Valid Loss: 0.007973438268132314\n",
      "Epoch: 537, Train Loss: 0.00829748556189988, Valid Loss: 0.007970612333193405\n",
      "Epoch: 538, Train Loss: 0.008289209185607155, Valid Loss: 0.007967833733923997\n",
      "Epoch: 539, Train Loss: 0.00828100422720575, Valid Loss: 0.007965102064005811\n",
      "Epoch: 540, Train Loss: 0.008272870255581065, Valid Loss: 0.007962416917596546\n",
      "Epoch: 541, Train Loss: 0.008264806838786642, Valid Loss: 0.007959777889387875\n",
      "Epoch: 542, Train Loss: 0.008256813544122726, Valid Loss: 0.007957184574662303\n",
      "Epoch: 543, Train Loss: 0.008248889938213514, Valid Loss: 0.007954636569348862\n",
      "Epoch: 544, Train Loss: 0.008241035587083174, Valid Loss: 0.007952133470077673\n",
      "Epoch: 545, Train Loss: 0.008233250056230594, Valid Loss: 0.007949674874233344\n",
      "Epoch: 546, Train Loss: 0.00822553291070289, Valid Loss: 0.007947260380007265\n",
      "Epoch: 547, Train Loss: 0.00821788371516764, Valid Loss: 0.007944889586448733\n",
      "Epoch: 548, Train Loss: 0.008210302033983905, Valid Loss: 0.00794256209351502\n",
      "Epoch: 549, Train Loss: 0.00820278743127197, Valid Loss: 0.007940277502120275\n",
      "Epoch: 550, Train Loss: 0.008195339470981887, Valid Loss: 0.007938035414183333\n",
      "Epoch: 551, Train Loss: 0.008187957716960752, Valid Loss: 0.007935835432674477\n",
      "Epoch: 552, Train Loss: 0.008180641733018783, Valid Loss: 0.007933677161661037\n",
      "Epoch: 553, Train Loss: 0.00817339108299417, Valid Loss: 0.007931560206351967\n",
      "Epoch: 554, Train Loss: 0.008166205330816695, Valid Loss: 0.00792948417314135\n",
      "Epoch: 555, Train Loss: 0.008159084040570176, Valid Loss: 0.007927448669650816\n",
      "Epoch: 556, Train Loss: 0.008152026776553684, Valid Loss: 0.00792545330477093\n",
      "Epoch: 557, Train Loss: 0.008145033103341597, Valid Loss: 0.007923497688701535\n",
      "Epoch: 558, Train Loss: 0.008138102585842437, Valid Loss: 0.007921581432991077\n",
      "Epoch: 559, Train Loss: 0.008131234789356546, Valid Loss: 0.007919704150574889\n",
      "Epoch: 560, Train Loss: 0.008124429279632616, Valid Loss: 0.007917865455812478\n",
      "Epoch: 561, Train Loss: 0.008117685622923016, Valid Loss: 0.0079160649645238\n",
      "Epoch: 562, Train Loss: 0.008111003386038007, Valid Loss: 0.007914302294024579\n",
      "Epoch: 563, Train Loss: 0.008104382136398794, Valid Loss: 0.007912577063160597\n",
      "Epoch: 564, Train Loss: 0.008097821442089445, Valid Loss: 0.007910888892341067\n",
      "Epoch: 565, Train Loss: 0.008091320871907713, Valid Loss: 0.007909237403571\n",
      "Epoch: 566, Train Loss: 0.008084879995414712, Valid Loss: 0.007907622220482677\n",
      "Epoch: 567, Train Loss: 0.008078498382983502, Valid Loss: 0.007906042968366134\n",
      "Epoch: 568, Train Loss: 0.00807217560584659, Valid Loss: 0.007904499274198775\n",
      "Epoch: 569, Train Loss: 0.008065911236142344, Valid Loss: 0.007902990766674027\n",
      "Epoch: 570, Train Loss: 0.008059704846960315, Valid Loss: 0.007901517076229115\n",
      "Epoch: 571, Train Loss: 0.008053556012385528, Valid Loss: 0.007900077835071961\n",
      "Epoch: 572, Train Loss: 0.008047464307541705, Valid Loss: 0.007898672677207176\n",
      "Epoch: 573, Train Loss: 0.008041429308633443, Valid Loss: 0.007897301238461192\n",
      "Epoch: 574, Train Loss: 0.008035450592987367, Valid Loss: 0.007895963156506569\n",
      "Epoch: 575, Train Loss: 0.008029527739092277, Valid Loss: 0.007894658070885406\n",
      "Epoch: 576, Train Loss: 0.008023660326638267, Valid Loss: 0.007893385623031969\n",
      "Epoch: 577, Train Loss: 0.008017847936554854, Valid Loss: 0.007892145456294457\n",
      "Epoch: 578, Train Loss: 0.008012090151048132, Valid Loss: 0.007890937215956009\n",
      "Epoch: 579, Train Loss: 0.008006386553636951, Valid Loss: 0.007889760549254847\n",
      "Epoch: 580, Train Loss: 0.008000736729188116, Valid Loss: 0.007888615105403705\n",
      "Epoch: 581, Train Loss: 0.007995140263950647, Valid Loss: 0.007887500535608424\n",
      "Epoch: 582, Train Loss: 0.007989596745589125, Valid Loss: 0.007886416493085824\n",
      "Epoch: 583, Train Loss: 0.007984105763216055, Valid Loss: 0.007885362633080815\n",
      "Epoch: 584, Train Loss: 0.007978666907423368, Valid Loss: 0.007884338612882751\n",
      "Epoch: 585, Train Loss: 0.007973279770312995, Valid Loss: 0.007883344091841086\n",
      "Epoch: 586, Train Loss: 0.007967943945526544, Valid Loss: 0.007882378731380292\n",
      "Epoch: 587, Train Loss: 0.00796265902827411, Valid Loss: 0.007881442195014092\n",
      "Epoch: 588, Train Loss: 0.007957424615362209, Valid Loss: 0.00788053414835897\n",
      "Epoch: 589, Train Loss: 0.00795224030522086, Valid Loss: 0.007879654259147042\n",
      "Epoch: 590, Train Loss: 0.007947105697929821, Valid Loss: 0.00787880219723821\n",
      "Epoch: 591, Train Loss: 0.00794202039524399, Valid Loss: 0.007877977634631722\n",
      "Epoch: 592, Train Loss: 0.007936984000617982, Valid Loss: 0.007877180245476992\n",
      "Epoch: 593, Train Loss: 0.007931996119229916, Valid Loss: 0.007876409706083888\n",
      "Epoch: 594, Train Loss: 0.00792705635800438, Valid Loss: 0.007875665694932315\n",
      "Epoch: 595, Train Loss: 0.007922164325634614, Valid Loss: 0.007874947892681236\n",
      "Epoch: 596, Train Loss: 0.007917319632603954, Valid Loss: 0.007874255982177053\n",
      "Epoch: 597, Train Loss: 0.007912521891206455, Valid Loss: 0.007873589648461424\n",
      "Epoch: 598, Train Loss: 0.007907770715566816, Valid Loss: 0.007872948578778497\n",
      "Epoch: 599, Train Loss: 0.00790306572165954, Valid Loss: 0.00787233246258156\n",
      "Epoch: 600, Train Loss: 0.007898406527327371, Valid Loss: 0.007871740991539146\n",
      "Epoch: 601, Train Loss: 0.007893792752299027, Valid Loss: 0.007871173859540583\n",
      "Epoch: 602, Train Loss: 0.007889224018206206, Valid Loss: 0.007870630762701019\n",
      "Epoch: 603, Train Loss: 0.00788469994859993, Valid Loss: 0.007870111399365897\n",
      "Epoch: 604, Train Loss: 0.007880220168966175, Valid Loss: 0.007869615470114949\n",
      "Epoch: 605, Train Loss: 0.007875784306740867, Valid Loss: 0.007869142677765647\n",
      "Epoch: 606, Train Loss: 0.007871391991324186, Valid Loss: 0.007868692727376192\n",
      "Epoch: 607, Train Loss: 0.007867042854094244, Valid Loss: 0.007868265326247995\n",
      "Epoch: 608, Train Loss: 0.007862736528420127, Valid Loss: 0.007867860183927692\n",
      "Epoch: 609, Train Loss: 0.00785847264967429, Valid Loss: 0.007867477012208688\n",
      "Epoch: 610, Train Loss: 0.007854250855244377, Valid Loss: 0.00786711552513228\n",
      "Epoch: 611, Train Loss: 0.007850070784544397, Valid Loss: 0.00786677543898827\n",
      "Epoch: 612, Train Loss: 0.00784593207902534, Valid Loss: 0.007866456472315198\n",
      "Epoch: 613, Train Loss: 0.00784183438218519, Valid Loss: 0.007866158345900142\n",
      "Epoch: 614, Train Loss: 0.007837777339578382, Valid Loss: 0.007865880782778065\n",
      "Epoch: 615, Train Loss: 0.007833760598824685, Valid Loss: 0.007865623508230807\n",
      "Epoch: 616, Train Loss: 0.007829783809617552, Valid Loss: 0.007865386249785646\n",
      "Epoch: 617, Train Loss: 0.007825846623731923, Valid Loss: 0.007865168737213464\n",
      "Epoch: 618, Train Loss: 0.007821948695031491, Valid Loss: 0.007864970702526584\n",
      "Epoch: 619, Train Loss: 0.007818089679475459, Valid Loss: 0.007864791879976168\n",
      "Epoch: 620, Train Loss: 0.007814269235124797, Valid Loss: 0.007864632006049302\n",
      "Epoch: 621, Train Loss: 0.007810487022147973, Valid Loss: 0.007864490819465724\n",
      "Epoch: 622, Train Loss: 0.007806742702826234, Valid Loss: 0.007864368061174182\n",
      "Epoch: 623, Train Loss: 0.007803035941558366, Valid Loss: 0.007864263474348489\n",
      "Epoch: 624, Train Loss: 0.007799366404865023, Valid Loss: 0.00786417680438322\n",
      "Epoch: 625, Train Loss: 0.00779573376139257, Valid Loss: 0.007864107798889132\n",
      "Epoch: 626, Train Loss: 0.007792137681916489, Valid Loss: 0.007864056207688224\n",
      "Epoch: 627, Train Loss: 0.007788577839344348, Valid Loss: 0.007864021782808536\n",
      "Epoch: 628, Train Loss: 0.007785053908718326, Valid Loss: 0.007864004278478623\n",
      "Epoch: 629, Train Loss: 0.007781565567217329, Valid Loss: 0.007864003451121777\n",
      "Epoch: 630, Train Loss: 0.007778112494158683, Valid Loss: 0.00786401905934994\n",
      "Epoch: 631, Train Loss: 0.007774694370999427, Valid Loss: 0.00786405086395736\n",
      "Epoch: 632, Train Loss: 0.007771310881337219, Valid Loss: 0.007864098627913972\n",
      "Epoch: 633, Train Loss: 0.007767961710910849, Valid Loss: 0.007864162116358563\n",
      "Epoch: 634, Train Loss: 0.007764646547600364, Valid Loss: 0.007864241096591616\n",
      "Epoch: 635, Train Loss: 0.00776136508142685, Valid Loss: 0.007864335338067996\n",
      "Epoch: 636, Train Loss: 0.007758117004551829, Valid Loss: 0.007864444612389334\n",
      "Epoch: 637, Train Loss: 0.007754902011276317, Valid Loss: 0.00786456869329623\n",
      "Epoch: 638, Train Loss: 0.007751719798039538, Valid Loss: 0.007864707356660207\n",
      "Epoch: 639, Train Loss: 0.0077485700634172955, Valid Loss: 0.007864860380475468\n",
      "Epoch: 640, Train Loss: 0.007745452508120026, Valid Loss: 0.00786502754485043\n",
      "Epoch: 641, Train Loss: 0.007742366834990524, Valid Loss: 0.007865208631999096\n",
      "Epoch: 642, Train Loss: 0.007739312749001359, Valid Loss: 0.007865403426232171\n",
      "Epoch: 643, Train Loss: 0.007736289957251987, Valid Loss: 0.007865611713948055\n",
      "Epoch: 644, Train Loss: 0.007733298168965575, Valid Loss: 0.007865833283623615\n",
      "Epoch: 645, Train Loss: 0.00773033709548552, Valid Loss: 0.007866067925804791\n",
      "Epoch: 646, Train Loss: 0.0077274064502716976, Valid Loss: 0.00786631543309704\n",
      "Epoch: 647, Train Loss: 0.007724505948896436, Valid Loss: 0.00786657560015562\n",
      "Epoch: 648, Train Loss: 0.007721635309040212, Valid Loss: 0.007866848223675693\n",
      "Epoch: 649, Train Loss: 0.007718794250487109, Valid Loss: 0.007867133102382323\n",
      "Epoch: 650, Train Loss: 0.0077159824951199925, Valid Loss: 0.007867430037020257\n",
      "Epoch: 651, Train Loss: 0.007713199766915472, Valid Loss: 0.007867738830343658\n",
      "Epoch: 652, Train Loss: 0.007710445791938583, Valid Loss: 0.00786805928710561\n",
      "Epoch: 653, Train Loss: 0.007707720298337286, Valid Loss: 0.007868391214047574\n",
      "Epoch: 654, Train Loss: 0.007705023016336693, Valid Loss: 0.007868734419888666\n",
      "Epoch: 655, Train Loss: 0.007702353678233099, Valid Loss: 0.007869088715314823\n",
      "Epoch: 656, Train Loss: 0.007699712018387793, Valid Loss: 0.007869453912967901\n",
      "Epoch: 657, Train Loss: 0.007697097773220671, Valid Loss: 0.007869829827434591\n",
      "Epoch: 658, Train Loss: 0.00769451068120362, Valid Loss: 0.007870216275235297\n",
      "Epoch: 659, Train Loss: 0.0076919504828537495, Valid Loss: 0.007870613074812882\n",
      "Epoch: 660, Train Loss: 0.007689416920726398, Valid Loss: 0.007871020046521307\n",
      "Epoch: 661, Train Loss: 0.007686909739407967, Valid Loss: 0.007871437012614226\n",
      "Epoch: 662, Train Loss: 0.007684428685508571, Valid Loss: 0.007871863797233454\n",
      "Epoch: 663, Train Loss: 0.007681973507654552, Valid Loss: 0.007872300226397356\n",
      "Epoch: 664, Train Loss: 0.007679543956480764, Valid Loss: 0.007872746127989196\n",
      "Epoch: 665, Train Loss: 0.007677139784622746, Valid Loss: 0.007873201331745365\n",
      "Epoch: 666, Train Loss: 0.00767476074670873, Valid Loss: 0.007873665669243584\n",
      "Epoch: 667, Train Loss: 0.0076724065993514804, Valid Loss: 0.007874138973890997\n",
      "Epoch: 668, Train Loss: 0.007670077101139993, Valid Loss: 0.007874621080912261\n",
      "Epoch: 669, Train Loss: 0.007667772012631084, Valid Loss: 0.007875111827337524\n",
      "Epoch: 670, Train Loss: 0.0076654910963408, Valid Loss: 0.007875611051990382\n",
      "Epoch: 671, Train Loss: 0.007663234116735716, Valid Loss: 0.007876118595475773\n",
      "Epoch: 672, Train Loss: 0.00766100084022413, Valid Loss: 0.007876634300167851\n",
      "Epoch: 673, Train Loss: 0.007658791035147082, Valid Loss: 0.007877158010197774\n",
      "Epoch: 674, Train Loss: 0.00765660447176932, Valid Loss: 0.007877689571441492\n",
      "Epoch: 675, Train Loss: 0.007654440922270105, Valid Loss: 0.00787822883150749\n",
      "Epoch: 676, Train Loss: 0.007652300160733933, Valid Loss: 0.007878775639724488\n",
      "Epoch: 677, Train Loss: 0.007650181963141153, Valid Loss: 0.007879329847129123\n",
      "Epoch: 678, Train Loss: 0.007648086107358472, Valid Loss: 0.007879891306453604\n",
      "Epoch: 679, Train Loss: 0.007646012373129378, Valid Loss: 0.007880459872113351\n",
      "Epoch: 680, Train Loss: 0.007643960542064472, Valid Loss: 0.007881035400194596\n",
      "Epoch: 681, Train Loss: 0.00764193039763171, Valid Loss: 0.007881617748441998\n",
      "Epoch: 682, Train Loss: 0.007639921725146549, Valid Loss: 0.007882206776246214\n",
      "Epoch: 683, Train Loss: 0.0076379343117620535, Valid Loss: 0.007882802344631469\n",
      "Epoch: 684, Train Loss: 0.007635967946458877, Valid Loss: 0.007883404316243145\n",
      "Epoch: 685, Train Loss: 0.007634022420035212, Valid Loss: 0.007884012555335313\n",
      "Epoch: 686, Train Loss: 0.0076320975250966485, Valid Loss: 0.007884626927758326\n",
      "Epoch: 687, Train Loss: 0.007630193056045981, Valid Loss: 0.007885247300946344\n",
      "Epoch: 688, Train Loss: 0.007628308809072951, Valid Loss: 0.007885873543904928\n",
      "Epoch: 689, Train Loss: 0.007626444582143927, Valid Loss: 0.007886505527198578\n",
      "Epoch: 690, Train Loss: 0.007624600174991544, Valid Loss: 0.007887143122938341\n",
      "Epoch: 691, Train Loss: 0.007622775389104275, Valid Loss: 0.00788778620476936\n",
      "Epoch: 692, Train Loss: 0.007620970027715974, Valid Loss: 0.007888434647858508\n",
      "Epoch: 693, Train Loss: 0.007619183895795356, Valid Loss: 0.007889088328881967\n",
      "Epoch: 694, Train Loss: 0.007617416800035454, Valid Loss: 0.007889747126012878\n",
      "Epoch: 695, Train Loss: 0.007615668548843016, Valid Loss: 0.007890410918908977\n",
      "Epoch: 696, Train Loss: 0.007613938952327893, Valid Loss: 0.007891079588700264\n",
      "Epoch: 697, Train Loss: 0.007612227822292371, Valid Loss: 0.007891753017976698\n",
      "Epoch: 698, Train Loss: 0.007610534972220489, Valid Loss: 0.007892431090775896\n",
      "Epoch: 699, Train Loss: 0.007608860217267318, Valid Loss: 0.007893113692570891\n",
      "Epoch: 700, Train Loss: 0.007607203374248234, Valid Loss: 0.00789380071025789\n",
      "Epoch: 701, Train Loss: 0.007605564261628138, Valid Loss: 0.007894492032144068\n",
      "Epoch: 702, Train Loss: 0.0076039426995106974, Valid Loss: 0.007895187547935409\n",
      "Epoch: 703, Train Loss: 0.007602338509627536, Valid Loss: 0.007895887148724546\n",
      "Epoch: 704, Train Loss: 0.007600751515327427, Valid Loss: 0.007896590726978693\n",
      "Epoch: 705, Train Loss: 0.00759918154156547, Valid Loss: 0.007897298176527545\n",
      "Epoch: 706, Train Loss: 0.007597628414892266, Valid Loss: 0.007898009392551258\n",
      "Epoch: 707, Train Loss: 0.007596091963443065, Valid Loss: 0.007898724271568472\n",
      "Epoch: 708, Train Loss: 0.007594572016926933, Valid Loss: 0.00789944271142434\n",
      "Epoch: 709, Train Loss: 0.007593068406615902, Valid Loss: 0.007900164611278638\n",
      "Epoch: 710, Train Loss: 0.007591580965334116, Valid Loss: 0.007900889871593897\n",
      "Epoch: 711, Train Loss: 0.007590109527446997, Valid Loss: 0.007901618394123565\n",
      "Epoch: 712, Train Loss: 0.007588653928850389, Valid Loss: 0.007902350081900255\n",
      "Epoch: 713, Train Loss: 0.00758721400695972, Valid Loss: 0.007903084839224016\n",
      "Epoch: 714, Train Loss: 0.007585789600699185, Valid Loss: 0.007903822571650636\n",
      "Epoch: 715, Train Loss: 0.007584380550490909, Valid Loss: 0.007904563185980032\n",
      "Epoch: 716, Train Loss: 0.007582986698244135, Valid Loss: 0.007905306590244646\n",
      "Epoch: 717, Train Loss: 0.007581607887344435, Valid Loss: 0.007906052693697952\n",
      "Epoch: 718, Train Loss: 0.007580243962642913, Valid Loss: 0.007906801406802942\n",
      "Epoch: 719, Train Loss: 0.007578894770445445, Valid Loss: 0.00790755264122073\n",
      "Epoch: 720, Train Loss: 0.00757756015850192, Valid Loss: 0.007908306309799166\n",
      "Epoch: 721, Train Loss: 0.0075762399759955095, Valid Loss: 0.007909062326561528\n",
      "Epoch: 722, Train Loss: 0.007574934073531947, Valid Loss: 0.00790982060669527\n",
      "Epoch: 723, Train Loss: 0.007573642303128857, Valid Loss: 0.007910581066540813\n",
      "Epoch: 724, Train Loss: 0.007572364518205058, Valid Loss: 0.0079113436235804\n",
      "Epoch: 725, Train Loss: 0.007571100573569941, Valid Loss: 0.007912108196427015\n",
      "Epoch: 726, Train Loss: 0.007569850325412841, Valid Loss: 0.007912874704813359\n",
      "Epoch: 727, Train Loss: 0.007568613631292453, Valid Loss: 0.007913643069580879\n",
      "Epoch: 728, Train Loss: 0.007567390350126269, Valid Loss: 0.007914413212668852\n",
      "Epoch: 729, Train Loss: 0.0075661803421800435, Valid Loss: 0.007915185057103554\n",
      "Epoch: 730, Train Loss: 0.0075649834690573, Valid Loss: 0.00791595852698748\n",
      "Epoch: 731, Train Loss: 0.007563799593688845, Valid Loss: 0.007916733547488593\n",
      "Epoch: 732, Train Loss: 0.007562628580322359, Valid Loss: 0.007917510044829693\n",
      "Epoch: 733, Train Loss: 0.0075614702945119745, Valid Loss: 0.00791828794627781\n",
      "Epoch: 734, Train Loss: 0.007560324603107918, Valid Loss: 0.007919067180133679\n",
      "Epoch: 735, Train Loss: 0.00755919137424618, Valid Loss: 0.007919847675721257\n",
      "Epoch: 736, Train Loss: 0.007558070477338227, Valid Loss: 0.007920629363377321\n",
      "Epoch: 737, Train Loss: 0.007556961783060745, Valid Loss: 0.00792141217444115\n",
      "Epoch: 738, Train Loss: 0.00755586516334542, Valid Loss: 0.007922196041244221\n",
      "Epoch: 739, Train Loss: 0.0075547804913687795, Valid Loss: 0.007922980897100024\n",
      "Epoch: 740, Train Loss: 0.0075537076415420415, Valid Loss: 0.007923766676293907\n",
      "Epoch: 741, Train Loss: 0.007552646489501033, Valid Loss: 0.007924553314073012\n",
      "Epoch: 742, Train Loss: 0.007551596912096149, Valid Loss: 0.00792534074663625\n",
      "Epoch: 743, Train Loss: 0.007550558787382331, Valid Loss: 0.007926128911124371\n",
      "Epoch: 744, Train Loss: 0.007549531994609113, Valid Loss: 0.007926917745610084\n",
      "Epoch: 745, Train Loss: 0.007548516414210715, Valid Loss: 0.007927707189088258\n",
      "Epoch: 746, Train Loss: 0.007547511927796158, Valid Loss: 0.007928497181466165\n",
      "Epoch: 747, Train Loss: 0.007546518418139448, Valid Loss: 0.007929287663553823\n",
      "Epoch: 748, Train Loss: 0.0075455357691697955, Valid Loss: 0.007930078577054385\n",
      "Epoch: 749, Train Loss: 0.007544563865961885, Valid Loss: 0.007930869864554607\n",
      "Epoch: 750, Train Loss: 0.007543602594726199, Valid Loss: 0.007931661469515376\n",
      "Epoch: 751, Train Loss: 0.007542651842799373, Valid Loss: 0.00793245333626231\n",
      "Epoch: 752, Train Loss: 0.007541711498634624, Valid Loss: 0.007933245409976437\n",
      "Epoch: 753, Train Loss: 0.0075407814517922, Valid Loss: 0.00793403763668491\n",
      "Epoch: 754, Train Loss: 0.007539861592929913, Valid Loss: 0.007934829963251845\n",
      "Epoch: 755, Train Loss: 0.007538951813793686, Valid Loss: 0.007935622337369165\n",
      "Epoch: 756, Train Loss: 0.007538052007208185, Valid Loss: 0.00793641470754757\n",
      "Epoch: 757, Train Loss: 0.00753716206706748, Valid Loss: 0.007937207023107526\n",
      "Epoch: 758, Train Loss: 0.007536281888325759, Valid Loss: 0.007937999234170358\n",
      "Epoch: 759, Train Loss: 0.007535411366988112, Valid Loss: 0.007938791291649401\n",
      "Epoch: 760, Train Loss: 0.007534550400101342, Valid Loss: 0.007939583147241216\n",
      "Epoch: 761, Train Loss: 0.007533698885744854, Valid Loss: 0.007940374753416876\n",
      "Epoch: 762, Train Loss: 0.007532856723021577, Valid Loss: 0.007941166063413321\n",
      "Epoch: 763, Train Loss: 0.007532023812048945, Valid Loss: 0.007941957031224777\n",
      "Epoch: 764, Train Loss: 0.0075312000539499435, Valid Loss: 0.007942747611594268\n",
      "Epoch: 765, Train Loss: 0.007530385350844198, Valid Loss: 0.007943537760005151\n",
      "Epoch: 766, Train Loss: 0.007529579605839107, Valid Loss: 0.007944327432672767\n",
      "Epoch: 767, Train Loss: 0.007528782723021065, Valid Loss: 0.007945116586536119\n",
      "Epoch: 768, Train Loss: 0.007527994607446692, Valid Loss: 0.007945905179249658\n",
      "Epoch: 769, Train Loss: 0.007527215165134156, Valid Loss: 0.007946693169175097\n",
      "Epoch: 770, Train Loss: 0.007526444303054537, Valid Loss: 0.007947480515373332\n",
      "Epoch: 771, Train Loss: 0.0075256819291232456, Valid Loss: 0.007948267177596382\n",
      "Epoch: 772, Train Loss: 0.007524927952191492, Valid Loss: 0.007949053116279447\n",
      "Epoch: 773, Train Loss: 0.00752418228203782, Valid Loss: 0.007949838292533021\n",
      "Epoch: 774, Train Loss: 0.007523444829359697, Valid Loss: 0.007950622668135031\n",
      "Epoch: 775, Train Loss: 0.007522715505765145, Valid Loss: 0.007951406205523091\n",
      "Epoch: 776, Train Loss: 0.007521994223764448, Valid Loss: 0.00795218886778681\n",
      "Epoch: 777, Train Loss: 0.0075212808967618896, Valid Loss: 0.007952970618660161\n",
      "Epoch: 778, Train Loss: 0.007520575439047587, Valid Loss: 0.0079537514225139\n",
      "Epoch: 779, Train Loss: 0.007519877765789329, Valid Loss: 0.007954531244348096\n",
      "Epoch: 780, Train Loss: 0.007519187793024508, Valid Loss: 0.007955310049784682\n",
      "Epoch: 781, Train Loss: 0.007518505437652103, Valid Loss: 0.007956087805060076\n",
      "Epoch: 782, Train Loss: 0.007517830617424698, Valid Loss: 0.007956864477017917\n",
      "Epoch: 783, Train Loss: 0.0075171632509405785, Valid Loss: 0.007957640033101803\n",
      "Epoch: 784, Train Loss: 0.007516503257635881, Valid Loss: 0.007958414441348115\n",
      "Epoch: 785, Train Loss: 0.007515850557776781, Valid Loss: 0.007959187670378925\n",
      "Epoch: 786, Train Loss: 0.007515205072451757, Valid Loss: 0.007959959689394948\n",
      "Epoch: 787, Train Loss: 0.0075145667235639035, Valid Loss: 0.007960730468168566\n",
      "Epoch: 788, Train Loss: 0.007513935433823299, Valid Loss: 0.007961499977036905\n",
      "Epoch: 789, Train Loss: 0.007513311126739422, Valid Loss: 0.00796226818689499\n",
      "Epoch: 790, Train Loss: 0.007512693726613639, Valid Loss: 0.007963035069188962\n",
      "Epoch: 791, Train Loss: 0.007512083158531749, Valid Loss: 0.007963800595909336\n",
      "Epoch: 792, Train Loss: 0.007511479348356543, Valid Loss: 0.00796456473958435\n",
      "Epoch: 793, Train Loss: 0.007510882222720488, Valid Loss: 0.007965327473273364\n",
      "Epoch: 794, Train Loss: 0.007510291709018405, Valid Loss: 0.007966088770560315\n",
      "Epoch: 795, Train Loss: 0.00750970773540023, Valid Loss: 0.007966848605547236\n",
      "Epoch: 796, Train Loss: 0.007509130230763837, Valid Loss: 0.007967606952847853\n",
      "Epoch: 797, Train Loss: 0.0075085591247478845, Valid Loss: 0.007968363787581216\n",
      "Epoch: 798, Train Loss: 0.00750799434772476, Valid Loss: 0.007969119085365413\n",
      "Epoch: 799, Train Loss: 0.0075074358307935475, Valid Loss: 0.00796987282231132\n",
      "Epoch: 800, Train Loss: 0.007506883505773048, Valid Loss: 0.007970624975016443\n",
      "Epoch: 801, Train Loss: 0.007506337305194888, Valid Loss: 0.007971375520558798\n",
      "Epoch: 802, Train Loss: 0.007505797162296637, Valid Loss: 0.007972124436490842\n",
      "Epoch: 803, Train Loss: 0.00750526301101502, Valid Loss: 0.00797287170083349\n",
      "Epoch: 804, Train Loss: 0.007504734785979156, Valid Loss: 0.007973617292070167\n",
      "Epoch: 805, Train Loss: 0.007504212422503857, Valid Loss: 0.00797436118914093\n",
      "Epoch: 806, Train Loss: 0.00750369585658299, Valid Loss: 0.007975103371436641\n",
      "Epoch: 807, Train Loss: 0.00750318502488289, Valid Loss: 0.007975843818793208\n",
      "Epoch: 808, Train Loss: 0.007502679864735806, Valid Loss: 0.00797658251148587\n",
      "Epoch: 809, Train Loss: 0.007502180314133435, Valid Loss: 0.007977319430223541\n",
      "Epoch: 810, Train Loss: 0.007501686311720479, Valid Loss: 0.007978054556143222\n",
      "Epoch: 811, Train Loss: 0.007501197796788266, Valid Loss: 0.00797878787080445\n",
      "Epoch: 812, Train Loss: 0.00750071470926842, Valid Loss: 0.007979519356183835\n",
      "Epoch: 813, Train Loss: 0.007500236989726602, Valid Loss: 0.007980248994669597\n",
      "Epoch: 814, Train Loss: 0.0074997645793562625, Valid Loss: 0.007980976769056227\n",
      "Epoch: 815, Train Loss: 0.00749929741997249, Valid Loss: 0.00798170266253913\n",
      "Epoch: 816, Train Loss: 0.007498835454005883, Valid Loss: 0.007982426658709393\n",
      "Epoch: 817, Train Loss: 0.007498378624496476, Valid Loss: 0.00798314874154856\n",
      "Epoch: 818, Train Loss: 0.007497926875087738, Valid Loss: 0.00798386889542345\n",
      "Epoch: 819, Train Loss: 0.0074974801500205775, Valid Loss: 0.007984587105081096\n",
      "Epoch: 820, Train Loss: 0.007497038394127467, Valid Loss: 0.007985303355643646\n",
      "Epoch: 821, Train Loss: 0.0074966015528265305, Valid Loss: 0.007986017632603391\n",
      "Epoch: 822, Train Loss: 0.0074961695721157615, Valid Loss: 0.007986729921817808\n",
      "Epoch: 823, Train Loss: 0.007495742398567241, Valid Loss: 0.007987440209504657\n",
      "Epoch: 824, Train Loss: 0.007495319979321423, Valid Loss: 0.007988148482237141\n",
      "Epoch: 825, Train Loss: 0.007494902262081468, Valid Loss: 0.007988854726939098\n",
      "Epoch: 826, Train Loss: 0.007494489195107622, Valid Loss: 0.007989558930880266\n",
      "Epoch: 827, Train Loss: 0.007494080727211649, Valid Loss: 0.007990261081671583\n",
      "Epoch: 828, Train Loss: 0.007493676807751308, Valid Loss: 0.007990961167260549\n",
      "Epoch: 829, Train Loss: 0.007493277386624873, Valid Loss: 0.007991659175926598\n",
      "Epoch: 830, Train Loss: 0.007492882414265721, Valid Loss: 0.0079923550962766\n",
      "Epoch: 831, Train Loss: 0.007492491841636938, Valid Loss: 0.007993048917240305\n",
      "Epoch: 832, Train Loss: 0.007492105620226001, Valid Loss: 0.007993740628065944\n",
      "Epoch: 833, Train Loss: 0.007491723702039487, Valid Loss: 0.007994430218315777\n",
      "Epoch: 834, Train Loss: 0.0074913460395978375, Valid Loss: 0.00799511767786177\n",
      "Epoch: 835, Train Loss: 0.007490972585930165, Valid Loss: 0.007995802996881268\n",
      "Epoch: 836, Train Loss: 0.007490603294569118, Valid Loss: 0.007996486165852733\n",
      "Epoch: 837, Train Loss: 0.007490238119545772, Valid Loss: 0.007997167175551536\n",
      "Epoch: 838, Train Loss: 0.007489877015384582, Valid Loss: 0.007997846017045765\n",
      "Epoch: 839, Train Loss: 0.0074895199370983755, Valid Loss: 0.007998522681692126\n",
      "Epoch: 840, Train Loss: 0.007489166840183384, Valid Loss: 0.007999197161131842\n",
      "Epoch: 841, Train Loss: 0.007488817680614335, Valid Loss: 0.007999869447286614\n",
      "Epoch: 842, Train Loss: 0.007488472414839573, Valid Loss: 0.008000539532354642\n",
      "Epoch: 843, Train Loss: 0.00748813099977623, Valid Loss: 0.008001207408806678\n",
      "Epoch: 844, Train Loss: 0.007487793392805443, Valid Loss: 0.008001873069382095\n",
      "Epoch: 845, Train Loss: 0.0074874595517676135, Valid Loss: 0.008002536507085064\n",
      "Epoch: 846, Train Loss: 0.0074871294349577065, Valid Loss: 0.00800319771518071\n",
      "Epoch: 847, Train Loss: 0.007486803001120597, Valid Loss: 0.008003856687191327\n",
      "Epoch: 848, Train Loss: 0.0074864802094464595, Valid Loss: 0.008004513416892666\n",
      "Epoch: 849, Train Loss: 0.007486161019566191, Valid Loss: 0.008005167898310248\n",
      "Epoch: 850, Train Loss: 0.0074858453915469, Valid Loss: 0.008005820125715678\n",
      "Epoch: 851, Train Loss: 0.0074855332858874, Valid Loss: 0.00800647009362306\n",
      "Epoch: 852, Train Loss: 0.007485224663513781, Valid Loss: 0.008007117796785436\n",
      "Epoch: 853, Train Loss: 0.007484919485775, Valid Loss: 0.008007763230191227\n",
      "Epoch: 854, Train Loss: 0.00748461771443852, Valid Loss: 0.008008406389060769\n",
      "Epoch: 855, Train Loss: 0.00748431931168599, Valid Loss: 0.008009047268842854\n",
      "Epoch: 856, Train Loss: 0.007484024240108964, Valid Loss: 0.008009685865211322\n",
      "Epoch: 857, Train Loss: 0.00748373246270466, Valid Loss: 0.008010322174061682\n",
      "Epoch: 858, Train Loss: 0.007483443942871762, Valid Loss: 0.00801095619150779\n",
      "Epoch: 859, Train Loss: 0.007483158644406253, Valid Loss: 0.008011587913878548\n",
      "Epoch: 860, Train Loss: 0.0074828765314973004, Valid Loss: 0.008012217337714646\n",
      "Epoch: 861, Train Loss: 0.007482597568723167, Valid Loss: 0.008012844459765354\n",
      "Epoch: 862, Train Loss: 0.007482321721047171, Valid Loss: 0.008013469276985307\n",
      "Epoch: 863, Train Loss: 0.007482048953813679, Valid Loss: 0.008014091786531412\n",
      "Epoch: 864, Train Loss: 0.007481779232744135, Valid Loss: 0.008014711985759685\n",
      "Epoch: 865, Train Loss: 0.007481512523933136, Valid Loss: 0.008015329872222221\n",
      "Epoch: 866, Train Loss: 0.007481248793844537, Valid Loss: 0.008015945443664128\n",
      "Epoch: 867, Train Loss: 0.00748098800930759, Valid Loss: 0.008016558698020539\n",
      "Epoch: 868, Train Loss: 0.00748073013751314, Valid Loss: 0.008017169633413642\n",
      "Epoch: 869, Train Loss: 0.0074804751460098235, Valid Loss: 0.008017778248149747\n",
      "Epoch: 870, Train Loss: 0.007480223002700349, Valid Loss: 0.008018384540716404\n",
      "Epoch: 871, Train Loss: 0.007479973675837762, Valid Loss: 0.008018988509779503\n",
      "Epoch: 872, Train Loss: 0.007479727134021782, Valid Loss: 0.008019590154180486\n",
      "Epoch: 873, Train Loss: 0.007479483346195172, Valid Loss: 0.008020189472933535\n",
      "Epoch: 874, Train Loss: 0.007479242281640125, Valid Loss: 0.008020786465222795\n",
      "Epoch: 875, Train Loss: 0.007479003909974704, Valid Loss: 0.00802138113039967\n",
      "Epoch: 876, Train Loss: 0.0074787682011493, Valid Loss: 0.00802197346798011\n",
      "Epoch: 877, Train Loss: 0.007478535125443141, Valid Loss: 0.008022563477641942\n",
      "Epoch: 878, Train Loss: 0.00747830465346083, Valid Loss: 0.008023151159222261\n",
      "Epoch: 879, Train Loss: 0.007478076756128902, Valid Loss: 0.008023736512714796\n",
      "Epoch: 880, Train Loss: 0.007477851404692437, Valid Loss: 0.008024319538267368\n",
      "Epoch: 881, Train Loss: 0.007477628570711696, Valid Loss: 0.008024900236179335\n",
      "Epoch: 882, Train Loss: 0.007477408226058785, Valid Loss: 0.008025478606899086\n",
      "Epoch: 883, Train Loss: 0.007477190342914361, Valid Loss: 0.008026054651021573\n",
      "Epoch: 884, Train Loss: 0.007476974893764358, Valid Loss: 0.008026628369285846\n",
      "Epoch: 885, Train Loss: 0.007476761851396771, Valid Loss: 0.008027199762572657\n",
      "Epoch: 886, Train Loss: 0.007476551188898439, Valid Loss: 0.00802776883190204\n",
      "Epoch: 887, Train Loss: 0.0074763428796518734, Valid Loss: 0.008028335578430993\n",
      "Epoch: 888, Train Loss: 0.007476136897332136, Valid Loss: 0.008028900003451108\n",
      "Epoch: 889, Train Loss: 0.007475933215903716, Valid Loss: 0.008029462108386298\n",
      "Epoch: 890, Train Loss: 0.007475731809617456, Valid Loss: 0.008030021894790504\n",
      "Epoch: 891, Train Loss: 0.0074755326530075135, Valid Loss: 0.008030579364345465\n",
      "Epoch: 892, Train Loss: 0.007475335720888344, Valid Loss: 0.008031134518858488\n",
      "Epoch: 893, Train Loss: 0.0074751409883517, Valid Loss: 0.008031687360260265\n",
      "Epoch: 894, Train Loss: 0.007474948430763698, Valid Loss: 0.008032237890602707\n",
      "Epoch: 895, Train Loss: 0.007474758023761873, Valid Loss: 0.008032786112056815\n",
      "Epoch: 896, Train Loss: 0.007474569743252301, Valid Loss: 0.008033332026910558\n",
      "Epoch: 897, Train Loss: 0.007474383565406713, Valid Loss: 0.008033875637566792\n",
      "Epoch: 898, Train Loss: 0.007474199466659662, Valid Loss: 0.008034416946541223\n",
      "Epoch: 899, Train Loss: 0.007474017423705715, Valid Loss: 0.008034955956460347\n",
      "Epoch: 900, Train Loss: 0.0074738374134966715, Valid Loss: 0.00803549267005947\n",
      "Epoch: 901, Train Loss: 0.007473659413238804, Valid Loss: 0.008036027090180706\n",
      "Epoch: 902, Train Loss: 0.00747348340039014, Valid Loss: 0.008036559219771042\n",
      "Epoch: 903, Train Loss: 0.00747330935265775, Valid Loss: 0.00803708906188039\n",
      "Epoch: 904, Train Loss: 0.00747313724799509, Valid Loss: 0.008037616619659693\n",
      "Epoch: 905, Train Loss: 0.007472967064599348, Valid Loss: 0.008038141896359036\n",
      "Epoch: 906, Train Loss: 0.007472798780908829, Valid Loss: 0.008038664895325799\n",
      "Epoch: 907, Train Loss: 0.007472632375600366, Valid Loss: 0.008039185620002809\n",
      "Epoch: 908, Train Loss: 0.007472467827586748, Valid Loss: 0.008039704073926542\n",
      "Epoch: 909, Train Loss: 0.00747230511601419, Valid Loss: 0.008040220260725324\n",
      "Epoch: 910, Train Loss: 0.00747214422025982, Valid Loss: 0.008040734184117588\n",
      "Epoch: 911, Train Loss: 0.0074719851199291825, Valid Loss: 0.008041245847910106\n",
      "Epoch: 912, Train Loss: 0.00747182779485378, Valid Loss: 0.008041755255996288\n",
      "Epoch: 913, Train Loss: 0.007471672225088648, Valid Loss: 0.008042262412354477\n",
      "Epoch: 914, Train Loss: 0.007471518390909926, Valid Loss: 0.008042767321046284\n",
      "Epoch: 915, Train Loss: 0.007471366272812482, Valid Loss: 0.008043269986214928\n",
      "Epoch: 916, Train Loss: 0.007471215851507545, Valid Loss: 0.008043770412083604\n",
      "Epoch: 917, Train Loss: 0.007471067107920369, Valid Loss: 0.008044268602953882\n",
      "Epoch: 918, Train Loss: 0.007470920023187916, Valid Loss: 0.008044764563204103\n",
      "Epoch: 919, Train Loss: 0.007470774578656569, Valid Loss: 0.008045258297287831\n",
      "Epoch: 920, Train Loss: 0.0074706307558798654, Valid Loss: 0.008045749809732293\n",
      "Epoch: 921, Train Loss: 0.007470488536616246, Valid Loss: 0.008046239105136849\n",
      "Epoch: 922, Train Loss: 0.007470347902826846, Valid Loss: 0.008046726188171505\n",
      "Epoch: 923, Train Loss: 0.007470208836673289, Valid Loss: 0.008047211063575402\n",
      "Epoch: 924, Train Loss: 0.007470071320515511, Valid Loss: 0.008047693736155366\n",
      "Epoch: 925, Train Loss: 0.00746993533690962, Valid Loss: 0.00804817421078446\n",
      "Epoch: 926, Train Loss: 0.007469800868605751, Valid Loss: 0.008048652492400544\n",
      "Epoch: 927, Train Loss: 0.007469667898545973, Valid Loss: 0.008049128586004881\n",
      "Epoch: 928, Train Loss: 0.007469536409862189, Valid Loss: 0.00804960249666074\n",
      "Epoch: 929, Train Loss: 0.0074694063858740814, Valid Loss: 0.008050074229492027\n",
      "Epoch: 930, Train Loss: 0.007469277810087066, Valid Loss: 0.008050543789681926\n",
      "Epoch: 931, Train Loss: 0.007469150666190267, Valid Loss: 0.00805101118247158\n",
      "Epoch: 932, Train Loss: 0.007469024938054523, Valid Loss: 0.008051476413158766\n",
      "Epoch: 933, Train Loss: 0.007468900609730408, Valid Loss: 0.008051939487096583\n",
      "Epoch: 934, Train Loss: 0.007468777665446259, Valid Loss: 0.0080524004096922\n",
      "Epoch: 935, Train Loss: 0.007468656089606258, Valid Loss: 0.00805285918640557\n",
      "Epoch: 936, Train Loss: 0.0074685358667884935, Valid Loss: 0.008053315822748196\n",
      "Epoch: 937, Train Loss: 0.007468416981743079, Valid Loss: 0.008053770324281893\n",
      "Epoch: 938, Train Loss: 0.007468299419390263, Valid Loss: 0.008054222696617592\n",
      "Epoch: 939, Train Loss: 0.007468183164818579, Valid Loss: 0.008054672945414123\n",
      "Epoch: 940, Train Loss: 0.0074680682032829985, Valid Loss: 0.008055121076377061\n",
      "Epoch: 941, Train Loss: 0.007467954520203113, Valid Loss: 0.00805556709525754\n",
      "Epoch: 942, Train Loss: 0.007467842101161345, Valid Loss: 0.008056011007851124\n",
      "Epoch: 943, Train Loss: 0.007467730931901145, Valid Loss: 0.008056452819996675\n",
      "Epoch: 944, Train Loss: 0.007467620998325253, Valid Loss: 0.008056892537575232\n",
      "Epoch: 945, Train Loss: 0.007467512286493924, Valid Loss: 0.00805733016650891\n",
      "Epoch: 946, Train Loss: 0.007467404782623237, Valid Loss: 0.008057765712759827\n",
      "Epoch: 947, Train Loss: 0.007467298473083354, Valid Loss: 0.008058199182329041\n",
      "Epoch: 948, Train Loss: 0.007467193344396858, Valid Loss: 0.008058630581255466\n",
      "Epoch: 949, Train Loss: 0.007467089383237063, Valid Loss: 0.00805905991561488\n",
      "Epoch: 950, Train Loss: 0.007466986576426361, Valid Loss: 0.00805948719151886\n",
      "Epoch: 951, Train Loss: 0.007466884910934599, Valid Loss: 0.008059912415113795\n",
      "Epoch: 952, Train Loss: 0.007466784373877444, Valid Loss: 0.008060335592579898\n",
      "Epoch: 953, Train Loss: 0.007466684952514786, Valid Loss: 0.008060756730130202\n",
      "Epoch: 954, Train Loss: 0.007466586634249161, Valid Loss: 0.008061175834009613\n",
      "Epoch: 955, Train Loss: 0.007466489406624165, Valid Loss: 0.008061592910493954\n",
      "Epoch: 956, Train Loss: 0.007466393257322921, Valid Loss: 0.00806200796588902\n",
      "Epoch: 957, Train Loss: 0.007466298174166529, Valid Loss: 0.008062421006529666\n",
      "Epoch: 958, Train Loss: 0.007466204145112561, Valid Loss: 0.008062832038778884\n",
      "Epoch: 959, Train Loss: 0.00746611115825354, Valid Loss: 0.00806324106902691\n",
      "Epoch: 960, Train Loss: 0.007466019201815475, Valid Loss: 0.008063648103690337\n",
      "Epoch: 961, Train Loss: 0.007465928264156367, Valid Loss: 0.00806405314921124\n",
      "Epoch: 962, Train Loss: 0.007465838333764776, Valid Loss: 0.008064456212056337\n",
      "Epoch: 963, Train Loss: 0.007465749399258363, Valid Loss: 0.008064857298716102\n",
      "Epoch: 964, Train Loss: 0.007465661449382478, Valid Loss: 0.008065256415703976\n",
      "Epoch: 965, Train Loss: 0.007465574473008745, Valid Loss: 0.008065653569555511\n",
      "Epoch: 966, Train Loss: 0.0074654884591336705, Valid Loss: 0.008066048766827582\n",
      "Epoch: 967, Train Loss: 0.007465403396877258, Valid Loss: 0.008066442014097576\n",
      "Epoch: 968, Train Loss: 0.0074653192754816555, Valid Loss: 0.008066833317962615\n",
      "Epoch: 969, Train Loss: 0.007465236084309793, Valid Loss: 0.008067222685038776\n",
      "Epoch: 970, Train Loss: 0.007465153812844062, Valid Loss: 0.008067610121960339\n",
      "Epoch: 971, Train Loss: 0.007465072450684974, Valid Loss: 0.008067995635379013\n",
      "Epoch: 972, Train Loss: 0.007464991987549875, Valid Loss: 0.008068379231963232\n",
      "Epoch: 973, Train Loss: 0.007464912413271639, Valid Loss: 0.008068760918397396\n",
      "Epoch: 974, Train Loss: 0.007464833717797394, Valid Loss: 0.008069140701381169\n",
      "Epoch: 975, Train Loss: 0.007464755891187255, Valid Loss: 0.00806951858762877\n",
      "Epoch: 976, Train Loss: 0.007464678923613077, Valid Loss: 0.008069894583868269\n",
      "Epoch: 977, Train Loss: 0.007464602805357212, Valid Loss: 0.008070268696840922\n",
      "Epoch: 978, Train Loss: 0.007464527526811285, Valid Loss: 0.008070640933300484\n",
      "Epoch: 979, Train Loss: 0.007464453078474989, Valid Loss: 0.00807101130001254\n",
      "Epoch: 980, Train Loss: 0.007464379450954872, Valid Loss: 0.00807137980375386\n",
      "Epoch: 981, Train Loss: 0.007464306634963169, Valid Loss: 0.008071746451311758\n",
      "Epoch: 982, Train Loss: 0.007464234621316619, Valid Loss: 0.008072111249483462\n",
      "Epoch: 983, Train Loss: 0.007464163400935302, Valid Loss: 0.008072474205075468\n",
      "Epoch: 984, Train Loss: 0.007464092964841508, Valid Loss: 0.008072835324902949\n",
      "Epoch: 985, Train Loss: 0.007464023304158578, Valid Loss: 0.008073194615789156\n",
      "Epoch: 986, Train Loss: 0.007463954410109802, Valid Loss: 0.008073552084564799\n",
      "Epoch: 987, Train Loss: 0.007463886274017297, Valid Loss: 0.008073907738067479\n",
      "Epoch: 988, Train Loss: 0.00746381888730091, Valid Loss: 0.008074261583141116\n",
      "Epoch: 989, Train Loss: 0.007463752241477141, Valid Loss: 0.008074613626635373\n",
      "Epoch: 990, Train Loss: 0.007463686328158049, Valid Loss: 0.008074963875405105\n",
      "Epoch: 991, Train Loss: 0.007463621139050208, Valid Loss: 0.008075312336309806\n",
      "Epoch: 992, Train Loss: 0.007463556665953643, Valid Loss: 0.008075659016213077\n",
      "Epoch: 993, Train Loss: 0.007463492900760795, Valid Loss: 0.008076003921982084\n",
      "Epoch: 994, Train Loss: 0.007463429835455493, Valid Loss: 0.008076347060487047\n",
      "Epoch: 995, Train Loss: 0.007463367462111928, Valid Loss: 0.00807668843860073\n",
      "Epoch: 996, Train Loss: 0.00746330577289366, Valid Loss: 0.00807702806319792\n",
      "Epoch: 997, Train Loss: 0.007463244760052611, Valid Loss: 0.00807736594115495\n",
      "Epoch: 998, Train Loss: 0.007463184415928079, Valid Loss: 0.008077702079349191\n",
      "Epoch: 999, Train Loss: 0.007463124732945779, Valid Loss: 0.00807803648465859\n",
      "Epoch: 1000, Train Loss: 0.007463065703616863, Valid Loss: 0.008078369163961182\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = NN()\n",
    "new.train(x_train, y_train, x_valid, y_valid, 1000, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yPred = new.forward(x_test)\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, yPred, color='blue', alpha=0.5, label='Predicted Values')\n",
    "plt.scatter(y_test, y_test, color='red', alpha=0.5, label='True Values')\n",
    "plt.title('True Values vs. Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
